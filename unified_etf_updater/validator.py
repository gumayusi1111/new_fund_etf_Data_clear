#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å‘¨æ›´ä¸æ—¥æ›´æ•°æ®åŒæ­¥æ ¡éªŒå™¨
é›†æˆåˆ°unified_etf_updateræ¶æ„ä¸­
"""

import os
import pandas as pd
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Set, Optional, Tuple
from pathlib import Path


class WeeklyDailyValidator:
    """å‘¨æ›´ä¸æ—¥æ›´æ•°æ®åŒæ­¥æ ¡éªŒå™¨"""
    
    def __init__(self, config: dict, logger: logging.Logger, project_root: Path):
        """
        åˆå§‹åŒ–æ ¡éªŒå™¨
        
        Args:
            config: é…ç½®
            logger: æ—¥å¿—è®°å½•å™¨
            project_root: é¡¹ç›®æ ¹ç›®å½•
        """
        self.config = config
        self.logger = logger
        self.project_root = project_root
        
        # è®¾ç½®ç›®å½•
        self.weekly_dir = project_root / "ETFå‘¨æ›´"
        self.daily_dir = project_root / "ETFæ—¥æ›´"
        self.categories = ["0_ETFæ—¥K(å‰å¤æƒ)", "0_ETFæ—¥K(åå¤æƒ)", "0_ETFæ—¥K(é™¤æƒ)"]
        
        # æ ¡éªŒé…ç½®
        validator_config = config.get('weekly_daily_validator', {})
        self.enabled = validator_config.get('enabled', True)
        self.auto_fix = validator_config.get('auto_fix', False)
        self.tolerance = validator_config.get('tolerance', 0.0001)  # 0.01%ç²¾åº¦å®¹å·®
        
    def is_enabled(self) -> bool:
        """æ£€æŸ¥æ ¡éªŒå™¨æ˜¯å¦å¯ç”¨"""
        return self.enabled
    
    def get_latest_date_from_etf_files(self, base_dir: Path) -> Optional[str]:
        """
        ä»ETFæ–‡ä»¶ä¸­è·å–æœ€æ–°çš„æ•°æ®æ—¥æœŸ
        
        Args:
            base_dir: åŸºç¡€ç›®å½•è·¯å¾„
            
        Returns:
            æœ€æ–°æ—¥æœŸå­—ç¬¦ä¸² YYYYMMDDï¼Œå¦‚æœæ²¡æœ‰æ‰¾åˆ°åˆ™è¿”å›None
        """
        sample_files = ["159001.csv", "159003.csv", "159005.csv"]
        latest_date = None
        
        for category in self.categories:
            category_dir = base_dir / category
            if not category_dir.exists():
                continue
                
            for sample_file in sample_files:
                file_path = category_dir / sample_file
                if file_path.exists():
                    try:
                        df = pd.read_csv(file_path, encoding='utf-8')
                        if not df.empty and 'æ—¥æœŸ' in df.columns:
                            # è·å–æœ€æ–°æ—¥æœŸï¼ˆç¬¬ä¸€è¡Œï¼Œå› ä¸ºæ•°æ®æŒ‰æ—¥æœŸé™åºæ’åˆ—ï¼‰
                            file_latest = df.iloc[0]['æ—¥æœŸ']
                            if latest_date is None or file_latest > latest_date:
                                latest_date = file_latest
                    except Exception as e:
                        self.logger.warning(f"è¯»å–æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
                        continue
                    break  # æ‰¾åˆ°ä¸€ä¸ªæœ‰æ•ˆæ–‡ä»¶å°±å¤Ÿäº†
        
        return str(latest_date) if latest_date else None
    
    def get_date_range(self, start_date: str, end_date: str) -> List[str]:
        """
        è·å–æŒ‡å®šæ—¥æœŸèŒƒå›´å†…çš„æ‰€æœ‰æ—¥æœŸ
        
        Args:
            start_date: å¼€å§‹æ—¥æœŸ YYYYMMDD
            end_date: ç»“æŸæ—¥æœŸ YYYYMMDD
            
        Returns:
            æ—¥æœŸåˆ—è¡¨
        """
        start = datetime.strptime(start_date, '%Y%m%d')
        end = datetime.strptime(end_date, '%Y%m%d')
        
        dates = []
        current = start
        while current <= end:
            dates.append(current.strftime('%Y%m%d'))
            current += timedelta(days=1)
        
        return dates
    
    def load_etf_data_for_date(self, base_dir: Path, etf_code: str, target_date: str) -> Dict:
        """
        åŠ è½½æŒ‡å®šETFåœ¨æŒ‡å®šæ—¥æœŸçš„æ•°æ®
        
        Args:
            base_dir: åŸºç¡€ç›®å½•
            etf_code: ETFä»£ç ï¼ˆå¦‚159001ï¼‰
            target_date: ç›®æ ‡æ—¥æœŸ YYYYMMDD
            
        Returns:
            æ•°æ®å­—å…¸ï¼ŒåŒ…å«ä¸‰ç§å¤æƒç±»å‹çš„æ•°æ®
        """
        result = {}
        
        for category in self.categories:
            file_path = base_dir / category / f"{etf_code}.csv"
            
            if not file_path.exists():
                result[category] = None
                continue
                
            try:
                df = pd.read_csv(file_path, encoding='utf-8')
                # è½¬æ¢ç›®æ ‡æ—¥æœŸä¸ºæ•´æ•°è¿›è¡ŒåŒ¹é…
                target_date_int = int(target_date)
                date_data = df[df['æ—¥æœŸ'] == target_date_int]
                
                if not date_data.empty:
                    # è½¬æ¢ä¸ºå­—å…¸ï¼Œä¾¿äºæ¯”è¾ƒ
                    row_data = date_data.iloc[0].to_dict()
                    result[category] = row_data
                else:
                    result[category] = None
                    
            except Exception as e:
                self.logger.warning(f"è¯»å–æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
                result[category] = None
        
        return result
    
    def compare_etf_data(self, weekly_data: Dict, daily_data: Dict) -> bool:
        """
        æ¯”è¾ƒå‘¨æ›´å’Œæ—¥æ›´çš„ETFæ•°æ®æ˜¯å¦ä¸€è‡´
        
        Args:
            weekly_data: å‘¨æ›´æ•°æ®
            daily_data: æ—¥æ›´æ•°æ®
            
        Returns:
            Trueè¡¨ç¤ºä¸€è‡´ï¼ŒFalseè¡¨ç¤ºä¸ä¸€è‡´
        """
        if not weekly_data or not daily_data:
            return False
        
        # æ¯”è¾ƒæ‰€æœ‰å¤æƒç±»å‹
        for category in self.categories:
            weekly_row = weekly_data.get(category)
            daily_row = daily_data.get(category)
            
            if weekly_row is None and daily_row is None:
                continue
            if weekly_row is None or daily_row is None:
                return False
                
            # æ¯”è¾ƒå…³é”®å­—æ®µï¼ˆå¿½ç•¥å¯èƒ½çš„ç²¾åº¦å·®å¼‚ï¼‰
            key_fields = ['å¼€ç›˜ä»·', 'æœ€é«˜ä»·', 'æœ€ä½ä»·', 'æ”¶ç›˜ä»·', 'æˆäº¤é‡(æ‰‹æ•°)', 'æˆäº¤é¢(åƒå…ƒ)']
            
            for field in key_fields:
                if field in weekly_row and field in daily_row:
                    try:
                        weekly_val = float(weekly_row[field])
                        daily_val = float(daily_row[field])
                        
                        # å…è®¸å°çš„ç²¾åº¦å·®å¼‚
                        if abs(weekly_val - daily_val) / max(abs(weekly_val), abs(daily_val), 1e-10) > self.tolerance:
                            return False
                    except (ValueError, TypeError):
                        if str(weekly_row[field]) != str(daily_row[field]):
                            return False
        
        return True
    
    def _compare_single_category(self, weekly_row: Dict, daily_row: Dict) -> bool:
        """
        æ¯”è¾ƒå•ä¸ªå¤æƒç±»å‹çš„æ•°æ®æ˜¯å¦ä¸€è‡´
        
        Args:
            weekly_row: å‘¨æ›´æ•°æ®è¡Œ
            daily_row: æ—¥æ›´æ•°æ®è¡Œ
            
        Returns:
            Trueè¡¨ç¤ºä¸€è‡´ï¼ŒFalseè¡¨ç¤ºä¸ä¸€è‡´
        """
        if weekly_row is None or daily_row is None:
            return False
            
        # æ¯”è¾ƒå…³é”®å­—æ®µï¼ˆå¿½ç•¥å¯èƒ½çš„ç²¾åº¦å·®å¼‚ï¼‰
        key_fields = ['å¼€ç›˜ä»·', 'æœ€é«˜ä»·', 'æœ€ä½ä»·', 'æ”¶ç›˜ä»·', 'æˆäº¤é‡(æ‰‹æ•°)', 'æˆäº¤é¢(åƒå…ƒ)']
        
        for field in key_fields:
            if field in weekly_row and field in daily_row:
                try:
                    weekly_val = float(weekly_row[field])
                    daily_val = float(daily_row[field])
                    
                    # å…è®¸å°çš„ç²¾åº¦å·®å¼‚
                    if abs(weekly_val - daily_val) / max(abs(weekly_val), abs(daily_val), 1e-10) > self.tolerance:
                        return False
                except (ValueError, TypeError):
                    if str(weekly_row[field]) != str(daily_row[field]):
                        return False
        
        return True
    
    def copy_date_data_from_weekly_to_daily(self, etf_code: str, target_date: str) -> bool:
        """
        å°†æŒ‡å®šæ—¥æœŸçš„æ•°æ®ä»å‘¨æ›´å¤åˆ¶åˆ°æ—¥æ›´
        
        Args:
            etf_code: ETFä»£ç 
            target_date: ç›®æ ‡æ—¥æœŸ
            
        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        success_count = 0
        
        for category in self.categories:
            weekly_file = self.weekly_dir / category / f"{etf_code}.csv"
            daily_file = self.daily_dir / category / f"{etf_code}.csv"
            
            if not weekly_file.exists() or not daily_file.exists():
                continue
                
            try:
                # è¯»å–å‘¨æ›´æ•°æ®
                weekly_df = pd.read_csv(weekly_file, encoding='utf-8')
                target_date_int = int(target_date)
                weekly_target = weekly_df[weekly_df['æ—¥æœŸ'] == target_date_int]
                
                if weekly_target.empty:
                    continue
                    
                # è¯»å–æ—¥æ›´æ•°æ®
                daily_df = pd.read_csv(daily_file, encoding='utf-8')
                
                # åˆ é™¤æ—¥æ›´ä¸­çš„ç›®æ ‡æ—¥æœŸæ•°æ®
                daily_df = daily_df[daily_df['æ—¥æœŸ'] != target_date_int]
                
                # æ·»åŠ å‘¨æ›´çš„ç›®æ ‡æ—¥æœŸæ•°æ®
                daily_df = pd.concat([weekly_target, daily_df], ignore_index=True)
                
                # æŒ‰æ—¥æœŸé™åºæ’åº
                daily_df['æ—¥æœŸ'] = daily_df['æ—¥æœŸ'].astype(str)
                daily_df = daily_df.sort_values('æ—¥æœŸ', ascending=False)
                
                # ä¿å­˜å›æ—¥æ›´æ–‡ä»¶
                daily_df.to_csv(daily_file, index=False, encoding='utf-8-sig')
                success_count += 1
                
            except Exception as e:
                self.logger.error(f"å¤åˆ¶æ•°æ®å¤±è´¥ {category}/{etf_code}.csv: {e}")
        
        return success_count == len(self.categories)
    
    def validate_overlap_period(self) -> Tuple[bool, Dict]:
        """
        æ ¡éªŒé‡å æœŸé—´çš„æ•°æ®ä¸€è‡´æ€§
        
        Returns:
            Tuple[æ˜¯å¦æœ‰ä¸ä¸€è‡´, è¯¦ç»†ç»“æœ]
        """
        self.logger.info("ğŸ” å¼€å§‹å‘¨æ›´ä¸æ—¥æ›´æ•°æ®åŒæ­¥æ ¡éªŒ...")
        
        # 1. è·å–å‘¨æ›´å’Œæ—¥æ›´çš„æœ€æ–°æ—¥æœŸ
        weekly_latest = self.get_latest_date_from_etf_files(self.weekly_dir)
        daily_latest = self.get_latest_date_from_etf_files(self.daily_dir)
        
        if not weekly_latest or not daily_latest:
            self.logger.error("âŒ æ— æ³•è·å–æ•°æ®æ—¥æœŸï¼Œè¯·æ£€æŸ¥æ–‡ä»¶ç»“æ„")
            return False, {"error": "æ— æ³•è·å–æ•°æ®æ—¥æœŸ"}
        
        self.logger.info(f"ğŸ“… å‘¨æ›´æœ€æ–°æ—¥æœŸ: {weekly_latest}")
        self.logger.info(f"ğŸ“… æ—¥æ›´æœ€æ–°æ—¥æœŸ: {daily_latest}")
        
        # 2. ç¡®å®šé‡å æœŸé—´
        if weekly_latest >= daily_latest:
            self.logger.info("âœ… å‘¨æ›´æ•°æ®å·²æ˜¯æœ€æ–°ï¼Œæ— éœ€æ ¡éªŒ")
            return False, {"status": "å‘¨æ›´å·²æ˜¯æœ€æ–°"}
        
        overlap_dates = self.get_date_range(weekly_latest, daily_latest)
        self.logger.info(f"ğŸ” é‡å æœŸé—´: {weekly_latest} åˆ° {daily_latest} ({len(overlap_dates)} å¤©)")
        
        # 3. è·å–éœ€è¦æ ¡éªŒçš„ETFåˆ—è¡¨ï¼ˆä½¿ç”¨æ ·æœ¬ï¼‰
        sample_etfs = ["159001", "159003", "159005", "159201", "159301"]
        inconsistent_dates = set()
        total_comparisons = 0
        inconsistent_comparisons = 0
        inconsistent_details = {}
        
        # 4. é€æ—¥æ¯”è¾ƒæ•°æ®
        for date in overlap_dates:
            self.logger.info(f"ğŸ“Š æ£€æŸ¥ {date}...")
            date_has_inconsistency = False
            
            for etf_code in sample_etfs:
                weekly_data = self.load_etf_data_for_date(self.weekly_dir, etf_code, date)
                daily_data = self.load_etf_data_for_date(self.daily_dir, etf_code, date)
                
                # ç»Ÿè®¡æ¯ç§å¤æƒç±»å‹çš„æ¯”è¾ƒæ¬¡æ•°
                etf_comparison_count = 0
                etf_inconsistency_count = 0
                category_results = {}
                
                # é€ä¸ªå¤æƒç±»å‹è¿›è¡Œè¯¦ç»†æ¯”è¾ƒ
                for category in self.categories:
                    weekly_row = weekly_data.get(category)
                    daily_row = daily_data.get(category)
                    
                    if weekly_row is not None and daily_row is not None:
                        etf_comparison_count += 1
                        total_comparisons += 1
                        
                        # å•ç‹¬æ¯”è¾ƒè¿™ä¸ªå¤æƒç±»å‹
                        category_consistent = self._compare_single_category(weekly_row, daily_row)
                        category_results[category] = category_consistent
                        
                        if not category_consistent:
                            etf_inconsistency_count += 1
                            inconsistent_comparisons += 1
                
                # è®°å½•ETFçº§åˆ«çš„ç»“æœ
                etf_consistent = etf_inconsistency_count == 0
                if etf_consistent:
                    self.logger.debug(f"  âœ… {etf_code} æ‰€æœ‰å¤æƒç±»å‹æ•°æ®ä¸€è‡´ ({etf_comparison_count}ä¸ª)")
                else:
                    self.logger.warning(f"  âš ï¸ {etf_code} æœ‰{etf_inconsistency_count}ä¸ªå¤æƒç±»å‹æ•°æ®ä¸ä¸€è‡´")
                    for category, is_consistent in category_results.items():
                        if not is_consistent:
                            self.logger.warning(f"    - {category}: ä¸ä¸€è‡´")
                    
                    date_has_inconsistency = True
                    
                    # è®°å½•ä¸ä¸€è‡´è¯¦æƒ…
                    if date not in inconsistent_details:
                        inconsistent_details[date] = []
                    inconsistent_details[date].append({
                        'etf_code': etf_code,
                        'inconsistent_categories': [cat for cat, consistent in category_results.items() if not consistent]
                    })
            
            if date_has_inconsistency:
                inconsistent_dates.add(date)
        
        # 5. æŠ¥å‘Šç»“æœ
        result = {
            "weekly_latest": weekly_latest,
            "daily_latest": daily_latest,
            "overlap_dates": overlap_dates,
            "total_comparisons": total_comparisons,
            "inconsistent_comparisons": inconsistent_comparisons,
            "inconsistent_dates": sorted(list(inconsistent_dates)),
            "inconsistent_details": inconsistent_details
        }
        
        self.logger.info(f"ğŸ“Š æ ¡éªŒç»“æœ:")
        self.logger.info(f"   æ£€æŸ¥å¤©æ•°: {len(overlap_dates)} å¤©")
        self.logger.info(f"   æ£€æŸ¥ETFæ•°: {len(sample_etfs)} ä¸ª")
        self.logger.info(f"   å¤æƒç±»å‹: {len(self.categories)} ç§ (å‰å¤æƒã€åå¤æƒã€é™¤æƒ)")
        self.logger.info(f"   æ€»æ¯”è¾ƒæ¬¡æ•°: {total_comparisons} (å¤©Ã—ETFÃ—å¤æƒç±»å‹)")
        self.logger.info(f"   ä¸ä¸€è‡´æ¬¡æ•°: {inconsistent_comparisons}")
        self.logger.info(f"   ä¸ä¸€è‡´æ—¥æœŸ: {len(inconsistent_dates)} å¤©")
        
        if inconsistent_dates:
            self.logger.warning(f"âš ï¸ å‘ç°æ•°æ®ä¸ä¸€è‡´æ—¥æœŸ: {sorted(inconsistent_dates)}")
            return True, result
        else:
            self.logger.info("ğŸ‰ æ‰€æœ‰æ•°æ®ä¸€è‡´ï¼Œæ— éœ€ä¿®æ­£ï¼")
            return False, result
    
    def auto_fix_inconsistent_data(self, inconsistent_dates: List[str]) -> bool:
        """
        è‡ªåŠ¨ä¿®æ­£ä¸ä¸€è‡´çš„æ•°æ®
        
        Args:
            inconsistent_dates: ä¸ä¸€è‡´çš„æ—¥æœŸåˆ—è¡¨
            
        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        if not inconsistent_dates:
            return True
        
        self.logger.info(f"ğŸ”„ å¼€å§‹è‡ªåŠ¨ä¿®æ­£ {len(inconsistent_dates)} ä¸ªä¸ä¸€è‡´æ—¥æœŸ...")
        
        # è·å–æ‰€æœ‰ETFæ–‡ä»¶åˆ—è¡¨
        weekly_category_dir = self.weekly_dir / self.categories[0]
        if not weekly_category_dir.exists():
            self.logger.error("âŒ æ‰¾ä¸åˆ°å‘¨æ›´æ•°æ®ç›®å½•")
            return False
        
        etf_files = [f for f in weekly_category_dir.iterdir() if f.suffix == '.csv']
        etf_codes = [f.stem for f in etf_files]
        
        success_dates = 0
        for date in sorted(inconsistent_dates):
            self.logger.info(f"  ä¿®æ­£ {date}...")
            date_success = 0
            
            for etf_code in etf_codes:
                if self.copy_date_data_from_weekly_to_daily(etf_code, date):
                    date_success += 1
            
            if date_success > 0:
                success_dates += 1
                self.logger.info(f"  âœ… {date} ä¿®æ­£å®Œæˆ ({date_success}/{len(etf_codes)} ä¸ªETF)")
            else:
                self.logger.error(f"  âŒ {date} ä¿®æ­£å¤±è´¥")
        
        if success_dates == len(inconsistent_dates):
            self.logger.info("âœ… æ‰€æœ‰ä¸ä¸€è‡´æ•°æ®ä¿®æ­£å®Œæˆï¼")
            return True
        else:
            self.logger.warning(f"âš ï¸ éƒ¨åˆ†æ•°æ®ä¿®æ­£å®Œæˆ ({success_dates}/{len(inconsistent_dates)})")
            return False
    
    def run_validation_after_weekly_update(self) -> Tuple[bool, str]:
        """
        åœ¨å‘¨æ›´å®Œæˆåè¿è¡Œæ ¡éªŒ
        
        Returns:
            Tuple[æ˜¯å¦éœ€è¦ç”¨æˆ·æ³¨æ„, æè¿°ä¿¡æ¯]
        """
        if not self.enabled:
            self.logger.debug("ğŸ“‹ å‘¨æ›´æ—¥æ›´æ ¡éªŒå·²ç¦ç”¨")
            return False, "æ ¡éªŒå·²ç¦ç”¨"
        
        # æ‰§è¡Œæ ¡éªŒ
        has_inconsistency, result = self.validate_overlap_period()
        
        if "error" in result:
            return False, f"æ ¡éªŒå¤±è´¥: {result['error']}"
        
        if "status" in result:
            return False, result['status']
        
        if not has_inconsistency:
            return False, "æ•°æ®ä¸€è‡´"
        
        inconsistent_dates = result.get('inconsistent_dates', [])
        
        # å¦‚æœå¯ç”¨äº†è‡ªåŠ¨ä¿®æ­£
        if self.auto_fix and inconsistent_dates:
            self.logger.info("ğŸ”„ å·²å¯ç”¨è‡ªåŠ¨ä¿®æ­£ï¼Œå¼€å§‹ä¿®æ­£æ•°æ®...")
            if self.auto_fix_inconsistent_data(inconsistent_dates):
                return False, "è‡ªåŠ¨ä¿®æ­£å®Œæˆ"
            else:
                return True, f"è‡ªåŠ¨ä¿®æ­£éƒ¨åˆ†å¤±è´¥ï¼Œéœ€è¦äººå·¥æ£€æŸ¥: {inconsistent_dates}"
        
        # éœ€è¦ç”¨æˆ·æ³¨æ„
        return True, f"å‘ç°æ•°æ®ä¸ä¸€è‡´ï¼Œéœ€è¦äººå·¥å¤„ç†: {inconsistent_dates}" 