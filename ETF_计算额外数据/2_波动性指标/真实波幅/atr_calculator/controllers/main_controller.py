#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ATRä¸»æ§åˆ¶å™¨
===========

åè°ƒæ‰€æœ‰ATRè®¡ç®—ç»„ä»¶ï¼Œæä¾›ç»Ÿä¸€çš„å¯¹å¤–æ¥å£ï¼š
- æ‰¹é‡è®¡ç®—ç®¡ç†
- é—¨æ§›ç­›é€‰å¤„ç†
- ç¼“å­˜ç­–ç•¥æ§åˆ¶
- ç»“æœè¾“å‡ºç®¡ç†
- æ€§èƒ½ç›‘æ§

æ”¯æŒçš„ä¸»è¦åŠŸèƒ½ï¼š
- å•ä¸ªETFå¿«é€Ÿåˆ†æ
- æ‰¹é‡é—¨æ§›è®¡ç®—
- å¢é‡æ›´æ–°å¤„ç†
- ç³»ç»ŸçŠ¶æ€ç›‘æ§
"""

import time
import pandas as pd
from pathlib import Path
from typing import Dict, List, Optional, Any, Tuple
import logging
from datetime import datetime

from ..engines.atr_engine import ATREngine
from ..infrastructure.config import ATRConfig
from ..infrastructure.cache_manager import ATRCacheManager
from ..infrastructure.data_reader import ATRDataReader
from ..infrastructure.utils import setup_logger, timer, format_processing_results
from ..outputs.csv_handler import ATRCSVHandler


class ATRMainController:
    """ATRä¸»æ§åˆ¶å™¨"""
    
    def __init__(self, config: ATRConfig = None, enable_cache: bool = True, 
                 performance_mode: bool = True):
        """åˆå§‹åŒ–ä¸»æ§åˆ¶å™¨"""
        # é…ç½®ç®¡ç†
        self.config = config or ATRConfig()
        self.enable_cache = enable_cache
        self.performance_mode = performance_mode
        
        # è®¾ç½®æ—¥å¿—
        self.logger = setup_logger(__name__, "INFO" if performance_mode else "DEBUG")
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.atr_engine = ATREngine(self.config)
        self.cache_manager = ATRCacheManager(self.config) if enable_cache else None
        self.data_reader = ATRDataReader(self.config)
        self.csv_handler = ATRCSVHandler(self.config)
        
        # ç¡®ä¿ç›®å½•ç»“æ„å­˜åœ¨
        self.config.ensure_directories_exist()
        
        # æ€§èƒ½ç»Ÿè®¡
        self.performance_stats = {
            'total_calculations': 0,
            'cache_hits': 0,
            'cache_misses': 0,
            'total_processing_time': 0,
            'session_start_time': datetime.now()
        }
        
        self.logger.info("ATRä¸»æ§åˆ¶å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def get_system_status(self) -> Dict[str, Any]:
        """è·å–ç³»ç»ŸçŠ¶æ€ä¿¡æ¯"""
        try:
            status = {
                'system_info': self.config.get_system_info(),
                'components': {
                    'ATR Engine': 'æ­£å¸¸',
                    'Cache Manager': 'æ­£å¸¸' if self.cache_manager else 'ç¦ç”¨',
                    'Data Reader': 'æ­£å¸¸',
                    'CSV Handler': 'æ­£å¸¸'
                },
                'data_status': {
                    'etf_data_path': self.config.etf_data_path,
                    'available_etfs_count': 0,
                    'cache_statistics': {}
                },
                'performance': self.performance_stats.copy()
            }
            
            # æ£€æŸ¥æ•°æ®å¯ç”¨æ€§
            try:
                available_etfs = self.data_reader.get_available_etf_files()
                status['data_status']['available_etfs_count'] = len(available_etfs)
            except Exception as e:
                status['data_status']['etf_data_error'] = str(e)
            
            # è·å–ç¼“å­˜ç»Ÿè®¡
            if self.cache_manager:
                try:
                    cache_stats = self.cache_manager.get_cache_statistics()
                    status['data_status']['cache_statistics'] = cache_stats
                except Exception as e:
                    status['data_status']['cache_error'] = str(e)
            
            return status
            
        except Exception as e:
            return {'error': f"è·å–ç³»ç»ŸçŠ¶æ€å¤±è´¥: {str(e)}"}
    
    def get_available_etfs(self) -> List[str]:
        """è·å–å¯ç”¨ETFåˆ—è¡¨"""
        try:
            etf_files = self.data_reader.get_available_etf_files()
            etf_codes = []
            
            for file_path in etf_files:
                etf_code = self.data_reader.extract_etf_code_from_filename(file_path)
                if etf_code:
                    etf_codes.append(etf_code)
            
            return sorted(etf_codes)
            
        except Exception as e:
            self.logger.error(f"è·å–å¯ç”¨ETFåˆ—è¡¨å¤±è´¥: {e}")
            return []
    
    @timer
    def calculate_single_etf(self, etf_code: str, threshold: str) -> Dict[str, Any]:
        """è®¡ç®—å•ä¸ªETFçš„ATRæŒ‡æ ‡"""
        try:
            start_time = time.time()
            
            # æŸ¥æ‰¾ETFæ–‡ä»¶
            etf_files = self.data_reader.get_available_etf_files()
            etf_file = None
            
            for file_path in etf_files:
                file_etf_code = self.data_reader.extract_etf_code_from_filename(file_path)
                if file_etf_code and (file_etf_code == etf_code or file_etf_code.split('.')[0] == etf_code):
                    etf_file = file_path
                    break
            
            if not etf_file:
                return {
                    'success': False,
                    'error': f'æœªæ‰¾åˆ°ETFæ–‡ä»¶: {etf_code}',
                    'etf_code': etf_code,
                    'threshold': threshold
                }
            
            # è¯»å–ETFæ•°æ®
            etf_data = self.data_reader.read_etf_file(etf_file, etf_code)
            if etf_data is None:
                return {
                    'success': False,
                    'error': f'è¯»å–ETFæ•°æ®å¤±è´¥: {etf_code}',
                    'etf_code': etf_code,
                    'threshold': threshold
                }
            
            # è·³è¿‡é—¨æ§›æ¡ä»¶æ£€æŸ¥ - ETFå·²é€šè¿‡åˆç­›éªŒè¯
            # è¿™æ ·å¯ä»¥ç¡®ä¿ä¸å…¶ä»–æ³¢åŠ¨æ€§æŒ‡æ ‡ç³»ç»Ÿçš„æ–‡ä»¶æ•°é‡ä¸€è‡´æ€§
            threshold_info = {'threshold': threshold, 'status': 'passed_initial_screening'}
            
            # å°è¯•å¢é‡æ›´æ–°æˆ–ä»ç¼“å­˜åŠ è½½
            cached_data = None
            calculation_mode = 'full_calculation'
            
            if self.cache_manager:
                cached_data = self.cache_manager.get_cached_data(etf_code, threshold, etf_file)
                
                if cached_data is not None:
                    # å°è¯•å¢é‡æ›´æ–°
                    try:
                        incremental_result = self.atr_engine.calculate_incremental_update(
                            cached_data, etf_data, etf_code
                        )
                        
                        if incremental_result is not None and not incremental_result.empty:
                            # å¢é‡æ›´æ–°æˆåŠŸ
                            atr_data = incremental_result
                            calculation_mode = 'incremental_update'
                            self.performance_stats['cache_hits'] += 1
                            self.logger.debug(f"å¢é‡æ›´æ–°æˆåŠŸ: {etf_code}-{threshold}")
                        else:
                            # å¢é‡æ›´æ–°å¤±è´¥ï¼Œè¿›è¡Œå…¨é‡è®¡ç®—
                            atr_result = self.atr_engine.calculate_full_atr(etf_data)
                            if not atr_result['success']:
                                return {
                                    'success': False,
                                    'error': f'ATRè®¡ç®—å¤±è´¥: {atr_result["error"]}',
                                    'etf_code': etf_code,
                                    'threshold': threshold
                                }
                            atr_data = atr_result['data']
                            calculation_mode = 'full_calculation'
                            self.performance_stats['cache_misses'] += 1
                    except Exception as e:
                        # å¢é‡æ›´æ–°å‡ºé”™ï¼Œè¿›è¡Œå…¨é‡è®¡ç®—
                        self.logger.warning(f"å¢é‡æ›´æ–°å¤±è´¥ï¼Œæ‰§è¡Œå…¨é‡è®¡ç®—: {etf_code}-{threshold}, é”™è¯¯: {e}")
                        atr_result = self.atr_engine.calculate_full_atr(etf_data)
                        if not atr_result['success']:
                            return {
                                'success': False,
                                'error': f'ATRè®¡ç®—å¤±è´¥: {atr_result["error"]}',
                                'etf_code': etf_code,
                                'threshold': threshold
                            }
                        atr_data = atr_result['data']
                        calculation_mode = 'full_calculation'
                        self.performance_stats['cache_misses'] += 1
                else:
                    # æ— ç¼“å­˜æ•°æ®ï¼Œè¿›è¡Œå…¨é‡è®¡ç®—
                    atr_result = self.atr_engine.calculate_full_atr(etf_data)
                    if not atr_result['success']:
                        return {
                            'success': False,
                            'error': f'ATRè®¡ç®—å¤±è´¥: {atr_result["error"]}',
                            'etf_code': etf_code,
                            'threshold': threshold
                        }
                    atr_data = atr_result['data']
                    calculation_mode = 'full_calculation'
                    self.performance_stats['cache_misses'] += 1
            else:
                # æ— ç¼“å­˜ç®¡ç†å™¨ï¼Œç›´æ¥å…¨é‡è®¡ç®—
                atr_result = self.atr_engine.calculate_full_atr(etf_data)
                if not atr_result['success']:
                    return {
                        'success': False,
                        'error': f'ATRè®¡ç®—å¤±è´¥: {atr_result["error"]}',
                        'etf_code': etf_code,
                        'threshold': threshold
                    }
                atr_data = atr_result['data']
                calculation_mode = 'full_calculation'
                self.performance_stats['cache_misses'] += 1
            
            # ä¿å­˜åˆ°ç¼“å­˜
            if self.cache_manager:
                self.cache_manager.save_calculated_data(
                    etf_code, threshold, atr_data, etf_file,
                    {
                        'atr_statistics': atr_result.get('statistics', {}),
                        'threshold_info': threshold_info,
                        'calculation_mode': calculation_mode
                    }
                )
            
            # æ›´æ–°æ€§èƒ½ç»Ÿè®¡
            self.performance_stats['total_calculations'] += 1
            calculation_time = time.time() - start_time
            self.performance_stats['total_processing_time'] += calculation_time
            
            return {
                'success': True,
                'etf_code': etf_code,
                'threshold': threshold,
                'data': atr_data,
                'latest_values': atr_result.get('latest_values', {}),
                'statistics': atr_result.get('statistics', {}),
                'threshold_info': threshold_info,
                'calculation_mode': calculation_mode,
                'from_cache': calculation_mode == 'incremental_update',
                'calculation_time': calculation_time
            }
            
        except Exception as e:
            self.logger.error(f"è®¡ç®—å•ä¸ªETFå¤±è´¥ {etf_code}-{threshold}: {e}")
            return {
                'success': False,
                'error': str(e),
                'etf_code': etf_code,
                'threshold': threshold
            }
    
    def quick_analysis(self, etf_code: str, include_historical: bool = False) -> Optional[Dict[str, Any]]:
        """å¿«é€Ÿåˆ†æå•ä¸ªETFï¼ˆç”¨äºæµ‹è¯•å’ŒéªŒè¯ï¼‰"""
        try:
            # ä½¿ç”¨ç¬¬ä¸€ä¸ªé—¨æ§›è¿›è¡Œå¿«é€Ÿåˆ†æ
            threshold = self.config.thresholds[0]
            result = self.calculate_single_etf(etf_code, threshold)
            
            if not result['success']:
                return None
            
            # æ„å»ºå¿«é€Ÿåˆ†æç»“æœ
            analysis = {
                'etf_code': etf_code,
                'threshold': threshold,
                'latest_values': result.get('latest_values', {}),
                'calculation_time': result.get('calculation_time', 0),
                'from_cache': result.get('from_cache', False)
            }
            
            # æ·»åŠ å†å²åˆ†æ
            if include_historical and 'data' in result:
                data = result['data']
                if not data.empty and 'atr_10' in data.columns:
                    atr_data = data['atr_10'].dropna()
                    analysis['historical_analysis'] = {
                        'total_history_days': len(data),
                        'valid_atr_days': len(atr_data),
                        'avg_atr': atr_data.mean() if len(atr_data) > 0 else None,
                        'max_atr': atr_data.max() if len(atr_data) > 0 else None,
                        'min_atr': atr_data.min() if len(atr_data) > 0 else None
                    }
            
            return analysis
            
        except Exception as e:
            self.logger.error(f"å¿«é€Ÿåˆ†æå¤±è´¥ {etf_code}: {e}")
            return None
    
    def calculate_screening_results(self, thresholds: List[str] = None) -> Dict[str, Any]:
        """æ‰¹é‡è®¡ç®—ç­›é€‰ç»“æœ"""
        if thresholds is None:
            thresholds = self.config.thresholds
        
        start_time = time.time()
        self.logger.info(f"å¼€å§‹æ‰¹é‡ATRè®¡ç®—ï¼Œé—¨æ§›: {thresholds}")
        
        # å¯¼å…¥ç­›é€‰åˆ—è¡¨è¯»å–åŠŸèƒ½
        from ..infrastructure.utils import read_etf_screening_list
        
        # æ‰¹é‡è®¡ç®—ç»“æœ
        batch_results = {}
        threshold_statistics = {}
        
        for threshold in thresholds:
            self.logger.info(f"å¤„ç†é—¨æ§›: {threshold}")
            threshold_start_time = time.time()
            
            # è·å–è¯¥é—¨æ§›çš„ç­›é€‰ETFåˆ—è¡¨
            threshold_etfs = read_etf_screening_list(threshold)
            if not threshold_etfs:
                self.logger.warning(f"é—¨æ§› {threshold} æ²¡æœ‰ç­›é€‰é€šè¿‡çš„ETF")
                threshold_statistics[threshold] = {
                    'total_etfs': 0,
                    'successful_etfs': 0,
                    'failed_etfs': 0,
                    'processing_time': 0
                }
                continue
            
            threshold_results = {}
            successful_count = 0
            failed_count = 0
            
            for i, etf_code in enumerate(threshold_etfs, 1):
                if not self.performance_mode and i % 50 == 0:
                    self.logger.info(f"è¿›åº¦: {i}/{len(threshold_etfs)} ({i/len(threshold_etfs)*100:.1f}%)")
                
                result = self.calculate_single_etf(etf_code, threshold)
                threshold_results[etf_code] = result
                
                if result['success']:
                    successful_count += 1
                else:
                    failed_count += 1
            
            # é—¨æ§›ç»Ÿè®¡
            threshold_time = time.time() - threshold_start_time
            threshold_statistics[threshold] = {
                'total_etfs': len(threshold_etfs),
                'successful_etfs': successful_count,
                'failed_etfs': failed_count,
                'success_rate': successful_count / len(threshold_etfs) * 100 if threshold_etfs else 0,
                'processing_time': threshold_time
            }
            
            # ä¿å­˜ç»“æœåˆ°æ‰¹é‡ç»“æœ
            for etf_code, result in threshold_results.items():
                if etf_code not in batch_results:
                    batch_results[etf_code] = {}
                batch_results[etf_code][threshold] = result
            
            self.logger.info(f"{threshold} å®Œæˆ: {successful_count}/{len(threshold_etfs)} ({successful_count/len(threshold_etfs)*100:.1f}%)")
        
        # ä¿å­˜CSVæ–‡ä»¶
        save_stats = self.csv_handler.save_batch_results(batch_results)
        
        # ç”Ÿæˆç»Ÿä¸€æ ‡å‡†çš„metaæ–‡ä»¶
        if self.cache_manager:
            # ä¸ºæ¯ä¸ªé—¨æ§›ç”Ÿæˆmetaæ–‡ä»¶
            for threshold, stats in threshold_statistics.items():
                self.cache_manager.create_threshold_meta(threshold, stats)
            
            # ç”Ÿæˆç³»ç»Ÿçº§metaæ–‡ä»¶
            self.cache_manager.create_system_meta(threshold_statistics)
            
            self.logger.info("ç»Ÿä¸€metaæ–‡ä»¶ç”Ÿæˆå®Œæˆ")
        
        # æ€»ä½“ç»Ÿè®¡
        total_time = time.time() - start_time
        
        # è®¡ç®—æ€»å¤„ç†çš„ETFæ•°é‡
        total_processed = sum(stats['total_etfs'] for stats in threshold_statistics.values())
        
        final_results = {
            'success': True,
            'total_etfs_processed': total_processed,
            'thresholds_processed': thresholds,
            'threshold_statistics': threshold_statistics,
            'save_statistics': save_stats,
            'processing_time': total_time,
            'performance_stats': self.performance_stats.copy(),
            'cache_hit_rate': (self.performance_stats['cache_hits'] / 
                              (self.performance_stats['cache_hits'] + self.performance_stats['cache_misses']) * 100
                              if self.performance_stats['cache_hits'] + self.performance_stats['cache_misses'] > 0 else 0)
        }
        
        self.logger.info(f"æ‰¹é‡è®¡ç®—å®Œæˆ: {total_time:.2f}ç§’")
        return final_results
    
    def clear_cache(self, etf_code: str = None, threshold: str = None):
        """æ¸…ç†ç¼“å­˜"""
        if self.cache_manager:
            self.cache_manager.clear_cache(etf_code, threshold)
            self.logger.info(f"ç¼“å­˜æ¸…ç†å®Œæˆ: ETF={etf_code}, é—¨æ§›={threshold}")
        else:
            self.logger.warning("ç¼“å­˜ç®¡ç†å™¨æœªå¯ç”¨")
    
    def get_performance_summary(self) -> str:
        """è·å–æ€§èƒ½æ‘˜è¦"""
        stats = self.performance_stats
        
        cache_hit_rate = 0
        if stats['cache_hits'] + stats['cache_misses'] > 0:
            cache_hit_rate = stats['cache_hits'] / (stats['cache_hits'] + stats['cache_misses']) * 100
        
        avg_time = 0
        if stats['total_calculations'] > 0:
            avg_time = stats['total_processing_time'] / stats['total_calculations']
        
        return f"""
ğŸ“Š ATRè®¡ç®—å™¨æ€§èƒ½æ‘˜è¦:
   ğŸ”¢ æ€»è®¡ç®—æ¬¡æ•°: {stats['total_calculations']}
   ğŸ’¾ ç¼“å­˜å‘½ä¸­ç‡: {cache_hit_rate:.1f}%
   â±ï¸ å¹³å‡è®¡ç®—æ—¶é—´: {avg_time:.3f}ç§’
   ğŸ• æ€»å¤„ç†æ—¶é—´: {stats['total_processing_time']:.2f}ç§’
   ğŸš€ ä¼šè¯å¼€å§‹æ—¶é—´: {stats['session_start_time'].strftime('%Y-%m-%d %H:%M:%S')}
        """.strip()