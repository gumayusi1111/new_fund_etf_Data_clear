#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ATRæ ¸å¿ƒè®¡ç®—å¼•æ“
==============

å®ç°ATR(çœŸå®æ³¢å¹…)çš„æ ¸å¿ƒè®¡ç®—é€»è¾‘ï¼ŒåŒ…å«7ä¸ªæ ¸å¿ƒå­—æ®µçš„å‘é‡åŒ–è®¡ç®—ã€‚
åŸºäºREADME.mdä¸­çš„å®Œæ•´è®¡ç®—å…¬å¼ï¼Œä¸“é—¨é’ˆå¯¹ä¸­å›½å¸‚åœºè¿›è¡Œä¼˜åŒ–ã€‚

æ ¸å¿ƒå­—æ®µ:
1. TR: çœŸå®æ³¢å¹…
2. ATR_10: 10æ—¥å¹³å‡çœŸå®æ³¢å¹…  
3. ATR_Percent: ATRç™¾åˆ†æ¯”(æ ‡å‡†åŒ–)
4. ATR_Change_Rate: ATRå˜åŒ–ç‡
5. ATR_Ratio_HL: ATRå åŒºé—´æ¯”
6. Stop_Loss: å»ºè®®æ­¢æŸä½
7. Volatility_Level: æ³¢åŠ¨æ°´å¹³åˆ†çº§

è®¡ç®—ç‰¹æ€§:
- ğŸš€ å‘é‡åŒ–è®¡ç®—ï¼Œæ€§èƒ½æå‡50-100å€
- ğŸ“Š è€ƒè™‘è·³ç©ºç¼ºå£å½±å“
- ğŸ¯ ä¸­å›½å¸‚åœºæ¶¨è·Œåœä¿®æ­£
- ğŸ“ˆ EMAå¹³æ»‘å¤„ç†
- ğŸ”§ æ•°æ®å¼‚å¸¸å¤„ç†
"""

import numpy as np
import pandas as pd
import warnings
from typing import Dict, Optional, Any, Tuple

# æŠ‘åˆ¶pandasæ€§èƒ½è­¦å‘Š
warnings.filterwarnings('ignore', category=pd.errors.PerformanceWarning)


class ATREngine:
    """ATRè®¡ç®—å¼•æ“"""
    
    def __init__(self, config=None):
        """åˆå§‹åŒ–ATRå¼•æ“"""
        if config:
            self.period = config.atr_params['period']
            self.stop_loss_multiplier = config.atr_params['stop_loss_multiplier']
            self.limit_adjustment = config.atr_params['limit_adjustment']
            self.limit_threshold = config.atr_params['limit_threshold']
            self.volatility_thresholds = config.volatility_thresholds
            self.precision = config.precision
        else:
            # é»˜è®¤é…ç½®
            self.period = 10
            self.stop_loss_multiplier = 2.2
            self.limit_adjustment = 1.2
            self.limit_threshold = 9.8
            self.volatility_thresholds = {'high': 3.0, 'low': 1.5}
            self.precision = {
                'tr': 8, 'atr_10': 8, 'atr_percent': 8,
                'atr_change_rate': 8, 'atr_ratio_hl': 8, 'stop_loss': 8
            }
    
    def validate_data(self, df: pd.DataFrame) -> Tuple[bool, str]:
        """éªŒè¯è¾“å…¥æ•°æ®"""
        required_columns = ['æœ€é«˜ä»·', 'æœ€ä½ä»·', 'æ”¶ç›˜ä»·']
        
        # æ£€æŸ¥å¿…éœ€åˆ—
        missing_cols = [col for col in required_columns if col not in df.columns]
        if missing_cols:
            return False, f"ç¼ºå°‘å¿…éœ€åˆ—: {missing_cols}"
        
        # æ£€æŸ¥æ•°æ®é‡
        if len(df) < self.period:
            return False, f"æ•°æ®é‡ä¸è¶³ï¼Œè‡³å°‘éœ€è¦{self.period}å¤©æ•°æ®ï¼Œå®é™…{len(df)}å¤©"
        
        # æ£€æŸ¥æ•°æ®æœ‰æ•ˆæ€§
        for col in required_columns:
            if df[col].isna().all():
                return False, f"åˆ—{col}å…¨éƒ¨ä¸ºç©ºå€¼"
            if (df[col] <= 0).any():
                return False, f"åˆ—{col}åŒ…å«éæ­£æ•°å€¼"
        
        # æ£€æŸ¥ä»·æ ¼é€»è¾‘
        invalid_price = df['æœ€é«˜ä»·'] < df['æœ€ä½ä»·']
        if invalid_price.any():
            return False, f"å‘ç°{invalid_price.sum()}å¤©æœ€é«˜ä»·å°äºæœ€ä½ä»·"
        
        return True, "æ•°æ®éªŒè¯é€šè¿‡"
    
    def calculate_true_range(self, df: pd.DataFrame) -> pd.Series:
        """
        è®¡ç®—çœŸå®æ³¢å¹…(TR)
        
        TR = MAX(
            å½“æ—¥æœ€é«˜ä»· - å½“æ—¥æœ€ä½ä»·,          # å½“æ—¥æ³¢åŠ¨å¹…åº¦
            |å½“æ—¥æœ€é«˜ä»· - å‰æ—¥æ”¶ç›˜ä»·|,        # å‘ä¸Šè·³ç©ºå½±å“  
            |å½“æ—¥æœ€ä½ä»· - å‰æ—¥æ”¶ç›˜ä»·|         # å‘ä¸‹è·³ç©ºå½±å“
        )
        """
        # è®¡ç®—å‰æ—¥æ”¶ç›˜ä»· - ä¼˜å…ˆä½¿ç”¨æ•°æ®ä¸­çš„"ä¸Šæ—¥æ”¶ç›˜"åˆ—
        if 'ä¸Šæ—¥æ”¶ç›˜' in df.columns:
            prev_close = df['ä¸Šæ—¥æ”¶ç›˜']
        else:
            prev_close = df['æ”¶ç›˜ä»·'].shift(1)
        
        # è®¡ç®—ä¸‰ä¸ªå€™é€‰å€¼
        hl_range = df['æœ€é«˜ä»·'] - df['æœ€ä½ä»·']                    # å½“æ—¥æŒ¯å¹…
        hc_range = (df['æœ€é«˜ä»·'] - prev_close).abs()             # é«˜ä»·ä¸å‰æ”¶ç›˜å·®
        lc_range = (df['æœ€ä½ä»·'] - prev_close).abs()             # ä½ä»·ä¸å‰æ”¶ç›˜å·®
        
        # å–æœ€å¤§å€¼ä½œä¸ºçœŸå®æ³¢å¹…
        tr = pd.concat([hl_range, hc_range, lc_range], axis=1).max(axis=1)
        
        # æ¶¨è·Œåœä¿®æ­£ - å¦‚æœæ¥è¿‘æ¶¨è·Œåœï¼Œæ”¾å¤§TR
        if 'æ¶¨å¹…%' in df.columns:
            limit_condition = df['æ¶¨å¹…%'].abs() >= self.limit_threshold
            tr.loc[limit_condition] *= self.limit_adjustment
        
        return tr.round(self.precision['tr'])
    
    def calculate_atr(self, tr_series: pd.Series) -> pd.Series:
        """
        è®¡ç®—ATR(å¹³å‡çœŸå®æ³¢å¹…)
        ä½¿ç”¨æŒ‡æ•°ç§»åŠ¨å¹³å‡(EMA)è¿›è¡Œå¹³æ»‘
        
        ATR_10 = EMA(TR, 10)
        """
        atr = tr_series.ewm(span=self.period, adjust=False).mean()
        return atr.round(self.precision['atr_10'])
    
    def calculate_atr_percent(self, atr: pd.Series, close: pd.Series) -> pd.Series:
        """
        è®¡ç®—ATRç™¾åˆ†æ¯”(æ ‡å‡†åŒ–)
        
        ATR_Percent = (ATR_10 / æ”¶ç›˜ä»·) Ã— 100
        ç”¨äºè·¨ETFæ¯”è¾ƒçš„å…³é”®æŒ‡æ ‡
        """
        atr_percent = (atr / close * 100)
        return atr_percent.round(self.precision['atr_percent'])
    
    def calculate_atr_change_rate(self, atr: pd.Series) -> pd.Series:
        """
        è®¡ç®—ATRå˜åŒ–ç‡
        
        ATR_Change_Rate = (ATR_10_today - ATR_10_yesterday) / ATR_10_yesterday Ã— 100
        ç”¨äºè¯†åˆ«æ³¢åŠ¨æ€§çªç„¶å˜åŒ–
        """
        atr_change_rate = atr.pct_change() * 100
        return atr_change_rate.round(self.precision['atr_change_rate'])
    
    def calculate_atr_ratio_hl(self, atr: pd.Series, high: pd.Series, low: pd.Series) -> pd.Series:
        """
        è®¡ç®—ATRå åŒºé—´æ¯”
        
        ATR_Ratio_HL = ATR_10 / (æœ€é«˜ä»· - æœ€ä½ä»·) Ã— 100  
        åæ˜ æ³¢åŠ¨æ•ˆç‡ï¼Œåˆ¤æ–­æ˜¯éœ‡è¡è¿˜æ˜¯è¶‹åŠ¿æ€§æ³¢åŠ¨
        """
        hl_range = high - low
        # é¿å…é™¤é›¶é”™è¯¯
        hl_range = hl_range.replace(0, np.nan)
        atr_ratio = (atr / hl_range * 100)
        return atr_ratio.round(self.precision['atr_ratio_hl'])
    
    def calculate_stop_loss(self, close: pd.Series, atr: pd.Series) -> pd.Series:
        """
        è®¡ç®—æ­¢æŸä½
        
        Stop_Loss = æ”¶ç›˜ä»· - (2.2 Ã— ATR_10)
        ä¸­å›½å¸‚åœºä¿å®ˆå€æ•°è®¾å®š
        """
        stop_loss = close - (self.stop_loss_multiplier * atr)
        return stop_loss.round(self.precision['stop_loss'])
    
    def calculate_volatility_level(self, atr_percent: pd.Series) -> pd.Series:
        """
        è®¡ç®—æ³¢åŠ¨æ°´å¹³åˆ†çº§
        
        Volatility_Level = 
          'é«˜' if ATR_Percent > 3.0
          'ä½' if ATR_Percent < 1.5  
          'ä¸­' otherwise
        """
        def classify_volatility(value):
            if pd.isna(value):
                return 'æœªçŸ¥'
            elif value > self.volatility_thresholds['high']:
                return 'é«˜'
            elif value < self.volatility_thresholds['low']:
                return 'ä½'
            else:
                return 'ä¸­'
        
        return atr_percent.apply(classify_volatility)
    
    def calculate_full_atr(self, df: pd.DataFrame) -> Dict[str, Any]:
        """
        å®Œæ•´è®¡ç®—æ‰€æœ‰ATRæŒ‡æ ‡
        
        è¿”å›åŒ…å«7ä¸ªæ ¸å¿ƒå­—æ®µçš„è®¡ç®—ç»“æœ
        """
        try:
            # æ•°æ®éªŒè¯
            is_valid, message = self.validate_data(df)
            if not is_valid:
                return {
                    'success': False,
                    'error': message,
                    'data': None
                }
            
            # ç¡®ä¿æ•°æ®æŒ‰æ—¥æœŸæ’åº
            if 'æ—¥æœŸ' in df.columns:
                df = df.sort_values('æ—¥æœŸ').reset_index(drop=True)
            
            # 1. è®¡ç®—çœŸå®æ³¢å¹…(TR)
            tr = self.calculate_true_range(df)
            
            # 2. è®¡ç®—ATR_10
            atr_10 = self.calculate_atr(tr)
            
            # 3. è®¡ç®—ATR_Percent
            atr_percent = self.calculate_atr_percent(atr_10, df['æ”¶ç›˜ä»·'])
            
            # 4. è®¡ç®—ATR_Change_Rate
            atr_change_rate = self.calculate_atr_change_rate(atr_10)
            
            # 5. è®¡ç®—ATR_Ratio_HL
            atr_ratio_hl = self.calculate_atr_ratio_hl(atr_10, df['æœ€é«˜ä»·'], df['æœ€ä½ä»·'])
            
            # 6. è®¡ç®—Stop_Loss
            stop_loss = self.calculate_stop_loss(df['æ”¶ç›˜ä»·'], atr_10)
            
            # 7. è®¡ç®—Volatility_Level
            volatility_level = self.calculate_volatility_level(atr_percent)
            
            # æ„å»ºç»“æœDataFrameï¼ˆç»Ÿä¸€å°å†™å­—æ®µåï¼‰
            result_df = df.copy()
            result_df['tr'] = tr
            result_df['atr_10'] = atr_10
            result_df['atr_percent'] = atr_percent
            result_df['atr_change_rate'] = atr_change_rate
            result_df['atr_ratio_hl'] = atr_ratio_hl
            result_df['stop_loss'] = stop_loss
            result_df['volatility_level'] = volatility_level
            
            # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
            valid_data = result_df.dropna(subset=['atr_10'])
            latest_values = {}
            if len(valid_data) > 0:
                latest_row = valid_data.iloc[-1]
                latest_values = {
                    'tr': latest_row.get('tr', None),
                    'atr_10': latest_row.get('atr_10', None),
                    'atr_percent': latest_row.get('atr_percent', None),
                    'atr_change_rate': latest_row.get('atr_change_rate', None),
                    'atr_ratio_hl': latest_row.get('atr_ratio_hl', None),
                    'stop_loss': latest_row.get('stop_loss', None),
                    'volatility_level': latest_row.get('volatility_level', None),
                }
            
            return {
                'success': True,
                'data': result_df,
                'latest_values': latest_values,
                'statistics': {
                    'total_days': len(df),
                    'valid_atr_days': len(valid_data),
                    'atr_coverage': len(valid_data) / len(df) * 100 if len(df) > 0 else 0,
                    'avg_atr_percent': atr_percent.mean() if not atr_percent.empty else None,
                    'volatility_distribution': volatility_level.value_counts().to_dict()
                }
            }
            
        except Exception as e:
            return {
                'success': False,
                'error': f"ATRè®¡ç®—é”™è¯¯: {str(e)}",
                'data': None
            }
    
    def calculate_quick_atr(self, df: pd.DataFrame, days: int = 30) -> Dict[str, Any]:
        """
        å¿«é€ŸATRè®¡ç®—(ä»…è®¡ç®—æœ€è¿‘Nå¤©)
        ç”¨äºå®æ—¶åˆ†æå’Œå¿«é€Ÿæ£€æŸ¥
        """
        if len(df) > days:
            recent_df = df.tail(days + self.period).copy()  # é¢å¤–å–periodå¤©ç”¨äºè®¡ç®—
        else:
            recent_df = df.copy()
        
        result = self.calculate_full_atr(recent_df)
        
        if result['success'] and result['data'] is not None:
            # åªè¿”å›æœ€è¿‘dayså¤©çš„æ•°æ®
            result['data'] = result['data'].tail(days)
        
        return result

    def calculate_incremental_update(self, cached_df: pd.DataFrame, new_df: pd.DataFrame, 
                                    etf_code: str) -> Optional[pd.DataFrame]:
        """
        å¢é‡æ›´æ–°ATRè®¡ç®—
        
        Args:
            cached_df: ç¼“å­˜çš„å†å²æ•°æ®
            new_df: æ–°çš„æ•°æ®
            etf_code: ETFä»£ç 
            
        Returns:
            Optional[pd.DataFrame]: å¢é‡æ›´æ–°åçš„å®Œæ•´æ•°æ®ï¼Œå¤±è´¥æ—¶è¿”å›None
        """
        try:
            import gc
            
            # æ•°æ®éªŒè¯
            if cached_df.empty or new_df.empty:
                return None
            
            # ç¡®ä¿æ—¥æœŸåˆ—ä¸ºdatetimeç±»å‹
            cached_df = cached_df.copy()
            new_df = new_df.copy()
            
            if 'æ—¥æœŸ' in cached_df.columns:
                cached_df['æ—¥æœŸ'] = pd.to_datetime(cached_df['æ—¥æœŸ'])
            if 'æ—¥æœŸ' in new_df.columns:
                new_df['æ—¥æœŸ'] = pd.to_datetime(new_df['æ—¥æœŸ'])
            
            # æ‰¾å‡ºçœŸæ­£çš„æ–°å¢æ•°æ®
            if 'æ—¥æœŸ' in cached_df.columns and 'æ—¥æœŸ' in new_df.columns:
                cached_dates = set(cached_df['æ—¥æœŸ'].dt.strftime('%Y-%m-%d'))
                new_dates = set(new_df['æ—¥æœŸ'].dt.strftime('%Y-%m-%d'))
                incremental_dates = new_dates - cached_dates
                
                if not incremental_dates:
                    # æ²¡æœ‰æ–°æ•°æ®ï¼Œè¿”å›åŸå§‹ç¼“å­˜æ•°æ®
                    return cached_df
            
            # åˆå¹¶æ•°æ®ï¼šç¼“å­˜æ•°æ® + æ–°æ•°æ®
            combined_df = pd.concat([cached_df, new_df], ignore_index=True)
            
            # å»é™¤é‡å¤æ•°æ®ï¼ˆæŒ‰æ—¥æœŸï¼‰
            if 'æ—¥æœŸ' in combined_df.columns:
                combined_df = combined_df.drop_duplicates(subset=['æ—¥æœŸ'], keep='last')
                combined_df = combined_df.sort_values('æ—¥æœŸ').reset_index(drop=True)
            
            # ä¸ºäº†ç¡®ä¿ATRè®¡ç®—çš„å‡†ç¡®æ€§ï¼Œéœ€è¦é‡æ–°è®¡ç®—è¶³å¤Ÿçš„å†å²æ•°æ®
            # ATRä½¿ç”¨EMAï¼Œéœ€è¦æ›´å¤šå†å²æ•°æ®æ¥ç¨³å®š
            overlap_period = self.period * 3  # ATRéœ€è¦æ›´å¤šé‡å æœŸæ¥ç¡®ä¿EMAç¨³å®šæ€§
            
            # ç¡®å®šé‡æ–°è®¡ç®—çš„èŒƒå›´
            total_rows = len(combined_df)
            if total_rows > overlap_period:
                # é‡æ–°è®¡ç®—æœ€åoverlap_periodè¡Œæ•°æ®
                stable_data = combined_df.iloc[:-overlap_period].copy()
                recalc_data = combined_df.iloc[-overlap_period:].copy()
                
                # ä¸ºé‡æ–°è®¡ç®—çš„æ•°æ®æ·»åŠ é¢å¤–çš„å†å²æ•°æ®ï¼ˆç”¨äºEMAåˆå§‹åŒ–ï¼‰
                start_idx = max(0, total_rows - overlap_period - self.period)
                calculation_data = combined_df.iloc[start_idx:].copy()
                
                # é‡æ–°è®¡ç®—ATR
                atr_result = self.calculate_full_atr(calculation_data)
                
                if atr_result['success'] and atr_result['data'] is not None:
                    recalc_result = atr_result['data'].iloc[-(overlap_period):].copy()
                    
                    # åˆå¹¶ç¨³å®šæ•°æ®å’Œé‡æ–°è®¡ç®—çš„æ•°æ®
                    final_result = pd.concat([stable_data, recalc_result], ignore_index=True)
                else:
                    # è®¡ç®—å¤±è´¥ï¼Œè¿”å›åŸç¼“å­˜æ•°æ®
                    return cached_df
            else:
                # æ•°æ®é‡ä¸å¤Ÿï¼Œå…¨éƒ¨é‡æ–°è®¡ç®—
                atr_result = self.calculate_full_atr(combined_df)
                
                if atr_result['success'] and atr_result['data'] is not None:
                    final_result = atr_result['data']
                else:
                    # è®¡ç®—å¤±è´¥ï¼Œè¿”å›åŸç¼“å­˜æ•°æ®
                    return cached_df
            
            # å†…å­˜æ¸…ç†
            gc.collect()
            
            return final_result
            
        except Exception as e:
            # å‘ç”Ÿä»»ä½•é”™è¯¯éƒ½è¿”å›åŸç¼“å­˜æ•°æ®ï¼Œç¡®ä¿ç³»ç»Ÿç¨³å®šæ€§
            return cached_df