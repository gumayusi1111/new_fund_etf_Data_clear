#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ³¢åŠ¨ç‡å†å²è®¡ç®—å™¨
=============

å®ç°æ³¢åŠ¨ç‡æŒ‡æ ‡çš„å†å²æ•°æ®è®¡ç®—ã€å¢é‡æ›´æ–°å’Œå‘é‡åŒ–æ‰¹é‡å¤„ç†
åŸºäºWMAå†å²è®¡ç®—å™¨æ¶æ„è®¾è®¡
"""

import os
import pandas as pd
import numpy as np
from datetime import datetime
from typing import Dict, List, Optional, Any, Tuple
from ..infrastructure.config import VolatilityConfig
from .volatility_engine import VolatilityEngine


class VolatilityHistoricalCalculator:
    """æ³¢åŠ¨ç‡å†å²è®¡ç®—å™¨"""
    
    def __init__(self, config: VolatilityConfig):
        """
        åˆå§‹åŒ–å†å²è®¡ç®—å™¨
        
        Args:
            config: æ³¢åŠ¨ç‡é…ç½®å¯¹è±¡
        """
        self.config = config
        self.volatility_engine = VolatilityEngine(config)
        
        print("ğŸš€ æ³¢åŠ¨ç‡å†å²è®¡ç®—å™¨åˆå§‹åŒ–å®Œæˆ")
        print("   ğŸ“Š æ”¯æŒå‘é‡åŒ–æ‰¹é‡è®¡ç®—")
        print("   âš¡ æ”¯æŒå¢é‡æ›´æ–°")
        print("   ğŸ—‚ï¸ æ”¯æŒæ™ºèƒ½ç¼“å­˜")
    
    def calculate_full_historical_volatility_optimized(self, df: pd.DataFrame, 
                                                     etf_code: str) -> Optional[pd.DataFrame]:
        """
        è®¡ç®—å®Œæ•´å†å²æ³¢åŠ¨ç‡æ•°æ® - å‘é‡åŒ–ä¼˜åŒ–ç‰ˆæœ¬
        
        Args:
            df: ä»·æ ¼æ•°æ®DataFrame
            etf_code: ETFä»£ç 
            
        Returns:
            pd.DataFrame: åŒ…å«å†å²æ³¢åŠ¨ç‡æ•°æ®çš„DataFrame
        """
        try:
            if df.empty:
                print(f"âŒ {etf_code}: æ•°æ®ä¸ºç©º")
                return None
            
            print(f"ğŸ”¬ {etf_code}: å¼€å§‹å‘é‡åŒ–å†å²æ³¢åŠ¨ç‡è®¡ç®—...")
            
            # å‡†å¤‡ç»“æœDataFrame - æŒ‰ç¬¬ä¸€å¤§ç±»æ ‡å‡†å¤„ç†å­—æ®µå’Œæ’åº
            result_df = df[['æ—¥æœŸ', 'å¼€ç›˜ä»·', 'æœ€é«˜ä»·', 'æœ€ä½ä»·', 'æ”¶ç›˜ä»·', 'æˆäº¤é‡']].copy()
            result_df = result_df.sort_values('æ—¥æœŸ', ascending=True).reset_index(drop=True)  # æŒ‰æ—¶é—´æ­£åº
            
            # å­—æ®µåè½¬æ¢ï¼šä¸­æ–‡ â†’ è‹±æ–‡ï¼ˆæŒ‰ç¬¬ä¸€å¤§ç±»æ ‡å‡†ï¼‰
            result_df = result_df.rename(columns={
                'æ—¥æœŸ': 'date',
                'å¼€ç›˜ä»·': 'open', 
                'æœ€é«˜ä»·': 'high',
                'æœ€ä½ä»·': 'low',
                'æ”¶ç›˜ä»·': 'close',
                'æˆäº¤é‡': 'volume'
            })
            
            # æ—¥æœŸæ ¼å¼æ ‡å‡†åŒ–ï¼šdatetime â†’ YYYY-MM-DDå­—ç¬¦ä¸²
            result_df['date'] = result_df['date'].dt.strftime('%Y-%m-%d')
            
            # æ·»åŠ ETFä»£ç åˆ—ï¼ˆæŒ‰ç¬¬ä¸€å¤§ç±»æ ‡å‡†ï¼‰
            clean_code = etf_code.replace('.SH', '').replace('.SZ', '')
            result_df['code'] = clean_code
            
            # è·å–ä»·æ ¼æ•°æ®ï¼ˆä½¿ç”¨è‹±æ–‡å­—æ®µåï¼‰
            high_prices = result_df['high']
            low_prices = result_df['low']
            close_prices = result_df['close']
            
            # å‘é‡åŒ–è®¡ç®—ä»·æ ¼æŒ¯å¹… - æŒ‰ç¬¬ä¸€å¤§ç±»æ ‡å‡†ä½¿ç”¨è‹±æ–‡å­—æ®µå
            print(f"   ğŸ“Š è®¡ç®—ä»·æ ¼æŒ¯å¹…...")
            prev_close = close_prices.shift(1)
            price_range = ((high_prices - low_prices) / prev_close * 100).fillna(0)
            result_df['PRICE_RANGE'] = price_range
            
            # å‘é‡åŒ–è®¡ç®—æ”¶ç›Šç‡
            returns = np.log(close_prices / close_prices.shift(1))
            
            # å‘é‡åŒ–è®¡ç®—å„å‘¨æœŸå†å²æ³¢åŠ¨ç‡ - æŒ‰ç¬¬ä¸€å¤§ç±»æ ‡å‡†ä½¿ç”¨è‹±æ–‡å­—æ®µå
            for period in self.config.volatility_periods:
                if period <= len(df):
                    print(f"   ğŸ“ˆ è®¡ç®— VOL_{period}...")
                    
                    # è®¡ç®—æ»šåŠ¨æ ‡å‡†å·®
                    rolling_std = returns.rolling(window=period, min_periods=period).std()
                    
                    # å¹´åŒ–å¤„ç†
                    if self.config.annualized:
                        rolling_std = rolling_std * np.sqrt(self.config.trading_days_per_year)
                    
                    result_df[f'VOL_{period}'] = rolling_std
                else:
                    print(f"   âš ï¸ è·³è¿‡ VOL_{period}: æ•°æ®ä¸è¶³")
                    result_df[f'VOL_{period}'] = np.nan
            
            # å‘é‡åŒ–è®¡ç®—æ»šåŠ¨æ³¢åŠ¨ç‡ - æŒ‰ç¬¬ä¸€å¤§ç±»æ ‡å‡†ä½¿ç”¨è‹±æ–‡å­—æ®µå
            for period in [10, 30]:
                if period <= len(df):
                    print(f"   ğŸ“ˆ è®¡ç®— ROLLING_VOL_{period}...")
                    rolling_vol = returns.rolling(window=period, min_periods=period).std()
                    
                    if self.config.annualized:
                        rolling_vol = rolling_vol * np.sqrt(self.config.trading_days_per_year)
                    
                    result_df[f'ROLLING_VOL_{period}'] = rolling_vol
            
            # è®¡ç®—æ³¢åŠ¨ç‡æ¯”ç‡å’ŒçŠ¶æ€ï¼ˆå‘é‡åŒ–ï¼‰
            self._calculate_vectorized_volatility_indicators(result_df)
            
            # æ·»åŠ è®¡ç®—å…ƒæ•°æ® - æŒ‰ç¬¬ä¸€å¤§ç±»æ ‡å‡†
            result_df['calc_time'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            
            print(f"âœ… {etf_code}: å‘é‡åŒ–å†å²è®¡ç®—å®Œæˆ ({len(result_df)}è¡Œ)")
            
            return result_df
            
        except Exception as e:
            print(f"âŒ {etf_code}: å‘é‡åŒ–å†å²è®¡ç®—å¼‚å¸¸: {str(e)}")
            return None
    
    def _calculate_vectorized_volatility_indicators(self, df: pd.DataFrame) -> None:
        """
        å‘é‡åŒ–è®¡ç®—æ³¢åŠ¨ç‡è¡ç”ŸæŒ‡æ ‡
        
        Args:
            df: æ•°æ®æ¡†ï¼ˆä¼šè¢«ä¿®æ”¹ï¼‰
        """
        try:
            # è®¡ç®—æ³¢åŠ¨ç‡æ¯”ç‡ï¼ˆå‘é‡åŒ–ï¼‰- æŒ‰ç¬¬ä¸€å¤§ç±»æ ‡å‡†ä½¿ç”¨è‹±æ–‡å­—æ®µå
            if 'VOL_20' in df.columns and 'VOL_60' in df.columns:
                vol_20 = df['VOL_20']
                vol_60 = df['VOL_60']
                
                # é¿å…é™¤é›¶
                vol_ratio = np.where(vol_60 != 0, vol_20 / vol_60, np.nan)
                df['VOL_RATIO_20_60'] = vol_ratio
                
                # å‘é‡åŒ–æ³¢åŠ¨ç‡çŠ¶æ€åˆ¤æ–­ - ä½¿ç”¨è‹±æ–‡çŠ¶æ€å€¼
                vol_state = np.select(
                    [vol_ratio > 1.5, vol_ratio > 1.2, vol_ratio > 0.8],
                    ['HIGH', 'MEDIUM', 'NORMAL'],
                    default='LOW'
                )
                df['VOL_STATE'] = vol_state
            
            # è®¡ç®—æ³¢åŠ¨ç‡æ°´å¹³ï¼ˆå‘é‡åŒ–ï¼‰- æŒ‰ç¬¬ä¸€å¤§ç±»æ ‡å‡†ä½¿ç”¨è‹±æ–‡å­—æ®µå
            if 'VOL_10' in df.columns:
                vol_10 = df['VOL_10']
                
                if self.config.annualized:
                    vol_level = np.select(
                        [vol_10 > 0.4, vol_10 > 0.25, vol_10 > 0.15],
                        ['EXTREME_HIGH', 'HIGH', 'MEDIUM'],
                        default='LOW'
                    )
                else:
                    vol_level = np.select(
                        [vol_10 > 0.025, vol_10 > 0.016, vol_10 > 0.009],
                        ['EXTREME_HIGH', 'HIGH', 'MEDIUM'],
                        default='LOW'
                    )
                
                df['VOL_LEVEL'] = vol_level
            
        except Exception as e:
            print(f"  âš ï¸ å‘é‡åŒ–æ³¢åŠ¨ç‡æŒ‡æ ‡è®¡ç®—è­¦å‘Š: {str(e)}")
    
    def calculate_incremental_update(self, cached_df: pd.DataFrame, new_df: pd.DataFrame,
                                   etf_code: str) -> Optional[pd.DataFrame]:
        """
        è®¡ç®—å¢é‡æ›´æ–°
        
        Args:
            cached_df: ç¼“å­˜çš„å†å²æ•°æ®
            new_df: æ–°çš„æ•°æ®
            etf_code: ETFä»£ç 
            
        Returns:
            pd.DataFrame: æ›´æ–°åçš„å®Œæ•´æ•°æ®
        """
        try:
            print(f"âš¡ {etf_code}: å¼€å§‹å¢é‡æ›´æ–°è®¡ç®—...")
            
            # ç¡®ä¿æ—¥æœŸåˆ—æ ¼å¼ä¸€è‡´
            if 'date' not in cached_df.columns:
                cached_df = cached_df.rename(columns={'æ—¥æœŸ': 'date'})
            if 'æ—¥æœŸ' in new_df.columns:
                new_df = new_df.rename(columns={'æ—¥æœŸ': 'date'})
            
            cached_df['date'] = pd.to_datetime(cached_df['date'])
            new_df['date'] = pd.to_datetime(new_df['date'])
            
            # æ‰¾å‡ºæ–°å¢çš„æ•°æ®è¡Œ
            cached_dates = set(cached_df['date'])
            new_dates = set(new_df['date'])
            
            # æ–°å¢æ—¥æœŸ
            incremental_dates = new_dates - cached_dates
            
            if not incremental_dates:
                print(f"   ğŸ“Š {etf_code}: æ— æ–°å¢æ•°æ®ï¼Œè¿”å›ç¼“å­˜æ•°æ®")
                return cached_df
            
            print(f"   ğŸ“ˆ {etf_code}: å‘ç° {len(incremental_dates)} ä¸ªæ–°å¢äº¤æ˜“æ—¥")
            
            # åˆå¹¶æ•°æ®ï¼ˆæ–°æ•°æ®åœ¨å‰ï¼‰
            combined_df = pd.concat([
                new_df[new_df['date'].isin(incremental_dates)],
                cached_df
            ], ignore_index=True)
            
            # æŒ‰æ—¥æœŸæ’åºï¼ˆæœ€æ–°åœ¨å‰ï¼‰
            combined_df = combined_df.sort_values('date', ascending=False).reset_index(drop=True)
            
            # é‡æ–°è®¡ç®—æ‰€æœ‰æ³¢åŠ¨ç‡æŒ‡æ ‡ï¼ˆå› ä¸ºæ»šåŠ¨è®¡ç®—éœ€è¦è€ƒè™‘æ–°æ•°æ®ï¼‰
            max_period = max(self.config.volatility_periods) if self.config.volatility_periods else 60
            recalc_rows = min(len(combined_df), max_period * 2)  # é‡ç®—å½±å“èŒƒå›´
            
            print(f"   ğŸ”„ {etf_code}: é‡æ–°è®¡ç®—å‰ {recalc_rows} è¡Œæ•°æ®...")
            
            # åªé‡ç®—å—å½±å“çš„éƒ¨åˆ†
            recalc_df = combined_df.head(recalc_rows).copy()
            unchanged_df = combined_df.iloc[recalc_rows:].copy() if recalc_rows < len(combined_df) else pd.DataFrame()
            
            # é‡æ–°è®¡ç®—æ³¢åŠ¨ç‡æŒ‡æ ‡
            updated_df = self.calculate_full_historical_volatility_optimized(
                recalc_df.rename(columns={'date': 'æ—¥æœŸ'}), etf_code
            )
            
            if updated_df is None:
                print(f"âŒ {etf_code}: å¢é‡è®¡ç®—å¤±è´¥")
                return cached_df
            
            # åˆå¹¶é‡ç®—æ•°æ®å’Œæœªå˜åŒ–æ•°æ®
            if not unchanged_df.empty:
                # ç¡®ä¿åˆ—ç»“æ„ä¸€è‡´
                for col in updated_df.columns:
                    if col not in unchanged_df.columns:
                        unchanged_df[col] = np.nan
                
                final_df = pd.concat([updated_df, unchanged_df], ignore_index=True)
            else:
                final_df = updated_df
            
            print(f"âœ… {etf_code}: å¢é‡æ›´æ–°å®Œæˆ (æ€»è®¡ {len(final_df)} è¡Œ)")
            
            return final_df
            
        except Exception as e:
            print(f"âŒ {etf_code}: å¢é‡æ›´æ–°å¼‚å¸¸: {str(e)}")
            return cached_df  # è¿”å›åŸå§‹ç¼“å­˜æ•°æ®
    
    def batch_calculate_historical_volatility(self, etf_files_dict: Dict[str, str],
                                            etf_codes: List[str]) -> Dict[str, pd.DataFrame]:
        """
        æ‰¹é‡è®¡ç®—å†å²æ³¢åŠ¨ç‡æ•°æ® - è¶…é«˜æ€§èƒ½å‘é‡åŒ–ç‰ˆæœ¬
        
        Args:
            etf_files_dict: ETFä»£ç åˆ°æ–‡ä»¶è·¯å¾„çš„æ˜ å°„
            etf_codes: ETFä»£ç åˆ—è¡¨
            
        Returns:
            Dict[str, pd.DataFrame]: ETFä»£ç åˆ°å†å²æ•°æ®çš„æ˜ å°„
        """
        print(f"ğŸš€ å¼€å§‹æ‰¹é‡å†å²æ³¢åŠ¨ç‡è®¡ç®— ({len(etf_codes)}ä¸ªETF)...")
        results = {}
        
        for i, etf_code in enumerate(etf_codes, 1):
            try:
                file_path = etf_files_dict.get(etf_code)
                if not file_path or not os.path.exists(file_path):
                    print(f"âš ï¸ [{i}/{len(etf_codes)}] {etf_code}: æ–‡ä»¶ä¸å­˜åœ¨")
                    continue
                
                print(f"ğŸ“Š [{i}/{len(etf_codes)}] å¤„ç†: {etf_code}")
                
                # è¯»å–æ•°æ®
                df = pd.read_csv(file_path, encoding='utf-8')
                
                if df.empty:
                    print(f"   âŒ {etf_code}: æ•°æ®ä¸ºç©º")
                    continue
                
                # æ•°æ®é¢„å¤„ç†
                required_columns = ['æ—¥æœŸ', 'å¼€ç›˜ä»·', 'æœ€é«˜ä»·', 'æœ€ä½ä»·', 'æ”¶ç›˜ä»·']
                if not all(col in df.columns for col in required_columns):
                    print(f"   âŒ {etf_code}: ç¼ºå°‘å¿…éœ€å­—æ®µ")
                    continue
                
                # å‘é‡åŒ–è®¡ç®—
                historical_df = self.calculate_full_historical_volatility_optimized(df, etf_code)
                
                if historical_df is not None:
                    results[etf_code] = historical_df
                    print(f"   âœ… {etf_code}: å®Œæˆ ({len(historical_df)}è¡Œ)")
                else:
                    print(f"   âŒ {etf_code}: è®¡ç®—å¤±è´¥")
                
            except Exception as e:
                print(f"   âŒ {etf_code}: æ‰¹é‡è®¡ç®—å¼‚å¸¸: {str(e)}")
                continue
        
        success_rate = (len(results) / len(etf_codes)) * 100
        print(f"\nğŸ‰ æ‰¹é‡å†å²è®¡ç®—å®Œæˆ!")
        print(f"   ğŸ“Š æˆåŠŸ: {len(results)}/{len(etf_codes)} ({success_rate:.1f}%)")
        
        return results
    
    def save_historical_results(self, results: Dict[str, pd.DataFrame], 
                              output_dir: str, threshold: str) -> Dict[str, Any]:
        """
        ä¿å­˜å†å²è®¡ç®—ç»“æœ
        
        Args:
            results: è®¡ç®—ç»“æœ
            output_dir: è¾“å‡ºç›®å½•
            threshold: é—¨æ§›ç±»å‹
            
        Returns:
            Dict: ä¿å­˜ç»Ÿè®¡ä¿¡æ¯
        """
        try:
            # åˆ›å»ºè¾“å‡ºç›®å½•
            threshold_output_dir = os.path.join(output_dir, threshold)
            os.makedirs(threshold_output_dir, exist_ok=True)
            
            saved_count = 0
            total_size = 0
            saved_etfs = []
            
            print(f"ğŸ’¾ ä¿å­˜å†å²æ•°æ®åˆ°: {threshold_output_dir}")
            
            for etf_code, df in results.items():
                try:
                    clean_code = etf_code.replace('.SH', '').replace('.SZ', '')
                    output_file = os.path.join(threshold_output_dir, f"{clean_code}.csv")
                    
                    # ä¿å­˜æ–‡ä»¶
                    df.to_csv(output_file, index=False, encoding='utf-8')
                    
                    # ç»Ÿè®¡ä¿¡æ¯
                    file_size = os.path.getsize(output_file)
                    total_size += file_size
                    saved_count += 1
                    saved_etfs.append(etf_code)
                    
                    if not self.config.performance_mode:
                        print(f"   ğŸ’¾ {etf_code}: {len(df)}è¡Œ â†’ {file_size/1024:.1f}KB")
                    
                except Exception as e:
                    print(f"   âŒ ä¿å­˜å¤±è´¥ {etf_code}: {str(e)}")
            
            stats = {
                'threshold': threshold,
                'saved_count': saved_count,
                'total_files': len(results),
                'success_rate': (saved_count / len(results)) * 100 if results else 0,
                'total_size_kb': total_size / 1024,
                'output_directory': threshold_output_dir,
                'etf_codes': saved_etfs
            }
            
            print(f"âœ… {threshold}: ä¿å­˜å®Œæˆ")
            print(f"   ğŸ“Š æ–‡ä»¶: {saved_count}/{len(results)}")
            print(f"   ğŸ’¾ å¤§å°: {stats['total_size_kb']:.1f}KB")
            
            return stats
            
        except Exception as e:
            print(f"âŒ å†å²ç»“æœä¿å­˜å¼‚å¸¸: {str(e)}")
            return {'error': str(e)}