#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ³¢åŠ¨ç‡å†å²è®¡ç®—å™¨
=============

å®ç°æ³¢åŠ¨ç‡æŒ‡æ ‡çš„å†å²æ•°æ®è®¡ç®—ã€å¢é‡æ›´æ–°å’Œå‘é‡åŒ–æ‰¹é‡å¤„ç†
åŸºäºWMAå†å²è®¡ç®—å™¨æ¶æ„è®¾è®¡
"""

import os
import gc
import pandas as pd
import numpy as np
from datetime import datetime
from typing import Dict, List, Optional, Any, Tuple
from ..infrastructure.config import VolatilityConfig
from .volatility_engine import VolatilityEngine


class VolatilityHistoricalCalculator:
    """æ³¢åŠ¨ç‡å†å²è®¡ç®—å™¨"""
    
    def __init__(self, config: VolatilityConfig, cache_manager=None):
        """
        åˆå§‹åŒ–å†å²è®¡ç®—å™¨
        
        Args:
            config: æ³¢åŠ¨ç‡é…ç½®å¯¹è±¡
            cache_manager: ç¼“å­˜ç®¡ç†å™¨ï¼ˆå¯é€‰ï¼‰
        """
        self.config = config
        self.volatility_engine = VolatilityEngine(config)
        self.cache_manager = cache_manager
        
        print("ğŸš€ æ³¢åŠ¨ç‡å†å²è®¡ç®—å™¨åˆå§‹åŒ–å®Œæˆ")
        print("   ğŸ“Š æ”¯æŒå‘é‡åŒ–æ‰¹é‡è®¡ç®—")
        print("   âš¡ æ”¯æŒå¢é‡æ›´æ–°")
        print("   ğŸ—‚ï¸ æ”¯æŒæ™ºèƒ½ç¼“å­˜")
    
    def calculate_full_historical_volatility_optimized(self, df: pd.DataFrame, 
                                                     etf_code: str) -> Optional[pd.DataFrame]:
        """
        è®¡ç®—å®Œæ•´å†å²æ³¢åŠ¨ç‡æ•°æ® - å®Œå…¨æ¨¡ä»¿å¸ƒæ—å¸¦çš„å‘é‡åŒ–ä¼˜åŒ–ç‰ˆæœ¬
        
        Args:
            df: ä»·æ ¼æ•°æ®DataFrame
            etf_code: ETFä»£ç 
            
        Returns:
            pd.DataFrame: åŒ…å«å†å²æ³¢åŠ¨ç‡æ•°æ®çš„DataFrame
        """
        try:
            if df.empty or 'æ”¶ç›˜ä»·' not in df.columns:
                print(f"âŒ {etf_code}: æ•°æ®ä¸ºç©ºæˆ–ç¼ºå°‘å¿…éœ€å­—æ®µ")
                return None
            
            # æ£€æŸ¥æ•°æ®é‡æ˜¯å¦è¶³å¤Ÿï¼ˆæ¨¡ä»¿å¸ƒæ—å¸¦çš„æ•°æ®éªŒè¯ï¼‰
            max_period = max(self.config.volatility_periods) if self.config.volatility_periods else 60
            if len(df) < max_period:
                print(f"âŒ {etf_code}: æ•°æ®ä¸è¶³ ({len(df)} < {max_period})")
                return None
            
            print(f"ğŸ”¬ {etf_code}: å¼€å§‹å‘é‡åŒ–å†å²æ³¢åŠ¨ç‡è®¡ç®—...")
            
            # å‡†å¤‡ç»“æœDataFrameï¼ˆæ¨¡ä»¿å¸ƒæ—å¸¦çš„æ•°æ®ç»“æ„å¤„ç†ï¼‰
            result_df = df.copy()
            # ç¡®ä¿æŒ‰æ—¥æœŸæ­£åºæ’åˆ—ï¼Œç”¨äºè®¡ç®—
            result_df = result_df.sort_values('æ—¥æœŸ', ascending=True).reset_index(drop=True)
            
            # å­—æ®µåè½¬æ¢ï¼šä¸­æ–‡ â†’ è‹±æ–‡ï¼ˆæŒ‰ç¬¬ä¸€å¤§ç±»æ ‡å‡†ï¼‰
            column_mapping = {
                'æ—¥æœŸ': 'date',
                'å¼€ç›˜ä»·': 'open', 
                'æœ€é«˜ä»·': 'high',
                'æœ€ä½ä»·': 'low',
                'æ”¶ç›˜ä»·': 'close',
                'æˆäº¤é‡': 'volume'
            }
            
            for chinese_col, english_col in column_mapping.items():
                if chinese_col in result_df.columns:
                    result_df[english_col] = result_df[chinese_col]
            
            # æ—¥æœŸæ ¼å¼æ ‡å‡†åŒ– - å¤„ç†æ•°å­—æ ¼å¼æ—¥æœŸï¼ˆå¦‚20250711ï¼‰
            if 'æ—¥æœŸ' in result_df.columns:
                # å°†æ•°å­—æ ¼å¼æ—¥æœŸè½¬æ¢ä¸ºæ ‡å‡†æ—¥æœŸæ ¼å¼
                result_df['date'] = pd.to_datetime(result_df['æ—¥æœŸ'], format='%Y%m%d', errors='coerce').dt.strftime('%Y-%m-%d')
            elif 'date' in result_df.columns:
                try:
                    result_df['date'] = pd.to_datetime(result_df['date'], errors='coerce').dt.strftime('%Y-%m-%d')
                except:
                    result_df['date'] = result_df['date']
            
            # æ·»åŠ ETFä»£ç åˆ—ï¼ˆæŒ‰README.mdè§„èŒƒï¼šçº¯æ•°å­—ï¼Œæ— äº¤æ˜“æ‰€åç¼€ï¼‰
            clean_code = etf_code.replace('.SH', '').replace('.SZ', '')
            result_df['code'] = clean_code
            
            # ä½¿ç”¨æ³¢åŠ¨ç‡å¼•æ“è¿›è¡Œå‘é‡åŒ–è®¡ç®—ï¼ˆæ¨¡ä»¿å¸ƒæ—å¸¦è°ƒç”¨å¼•æ“çš„æ–¹å¼ï¼‰
            historical_df = self.volatility_engine.calculate_historical_volatility_indicators(df)
            
            if historical_df.empty:
                print(f"âŒ {etf_code}: æ³¢åŠ¨ç‡è®¡ç®—å¤±è´¥")
                return None
            
            # å°†è®¡ç®—ç»“æœåˆå¹¶åˆ°ç»“æœDataFrameï¼ˆç¡®ä¿æ—¥æœŸå¯¹åº”å…³ç³»æ­£ç¡®ï¼‰
            # å…ˆç¡®ä¿historical_dfä¹ŸæŒ‰æ—¥æœŸæ­£åºæ’åˆ—ï¼Œä¸result_dfä¸€è‡´
            if 'æ—¥æœŸ' in historical_df.columns:
                historical_df = historical_df.sort_values('æ—¥æœŸ', ascending=True).reset_index(drop=True)
            
            vol_columns = [col for col in historical_df.columns if col.startswith(('vol_', 'rolling_vol_', 'price_range'))]
            vol_columns.extend(['vol_ratio_20_30', 'vol_state', 'vol_level'])
            
            # ç¡®ä¿ä¸¤ä¸ªDataFrameé•¿åº¦ä¸€è‡´ä¸”ç´¢å¼•å¯¹åº”
            if len(result_df) == len(historical_df):
                for col in vol_columns:
                    if col in historical_df.columns:
                        result_df[col] = historical_df[col].values  # ä½¿ç”¨.valuesç¡®ä¿ç´¢å¼•å¯¹é½
            else:
                print(f"âš ï¸ {etf_code}: DataFrameé•¿åº¦ä¸åŒ¹é… result_df={len(result_df)}, historical_df={len(historical_df)}")
                # å›é€€åˆ°æ›´å®‰å…¨çš„æ–¹æ³•ï¼šé‡æ–°è®¡ç®—
                return None
            
            # æ·»åŠ è®¡ç®—å…ƒæ•°æ®
            result_df['calc_time'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            
            # æŒ‰ç…§æ–°æ ‡å‡†è§„å®šçš„è¾“å‡ºæ ¼å¼é€‰æ‹©å­—æ®µï¼ˆç»Ÿä¸€å°å†™ï¼‰
            # æ ¼å¼: code,date,vol_10,vol_20,vol_30,rolling_vol_10,rolling_vol_30,price_range,vol_ratio_20_30,vol_state,vol_level,calc_time
            output_columns = ['code', 'date']
            
            # æ·»åŠ æ³¢åŠ¨ç‡æŒ‡æ ‡å­—æ®µï¼ˆå°å†™å­—æ®µåï¼‰
            for period in self.config.volatility_periods:
                col_name = f'vol_{period}'
                if col_name in result_df.columns:
                    output_columns.append(col_name)
                else:
                    # å¦‚æœå­—æ®µä¸å­˜åœ¨ï¼Œæ·»åŠ ç©ºå€¼å ä½
                    result_df[col_name] = np.nan
                    output_columns.append(col_name)
            
            # æ·»åŠ æ»šåŠ¨æ³¢åŠ¨ç‡å­—æ®µï¼ˆå°å†™å­—æ®µåï¼‰
            for period in [10, 30]:
                col_name = f'rolling_vol_{period}'
                if col_name in result_df.columns:
                    output_columns.append(col_name)
                else:
                    # å¦‚æœå­—æ®µä¸å­˜åœ¨ï¼Œæ·»åŠ ç©ºå€¼å ä½
                    result_df[col_name] = np.nan
                    output_columns.append(col_name)
            
            # æ·»åŠ å…¶ä»–æŒ‡æ ‡å­—æ®µï¼ˆå°å†™å­—æ®µåï¼‰
            other_fields = ['price_range', 'vol_ratio_20_30', 'vol_state', 'vol_level']
            
            for field in other_fields:
                if field in result_df.columns:
                    output_columns.append(field)
                else:
                    # å¦‚æœå­—æ®µä¸å­˜åœ¨ï¼Œæ·»åŠ ç©ºå€¼å ä½
                    result_df[field] = np.nan if field != 'vol_state' and field != 'vol_level' else 'UNKNOWN'
                    output_columns.append(field)
            
            # æ·»åŠ è®¡ç®—æ—¶é—´
            if 'calc_time' in result_df.columns:
                output_columns.append('calc_time')
            
            # æœ€ç»ˆç»“æœç­›é€‰
            final_df = result_df[output_columns].copy()
            
            # æœ€ç»ˆæ’åºï¼šæŒ‰æ—¥æœŸé™åºæ’åˆ—ï¼Œç¡®ä¿æœ€æ–°æ—¥æœŸåœ¨æœ€ä¸Šé¢
            if 'date' in final_df.columns:
                final_df['date'] = pd.to_datetime(final_df['date'], errors='coerce')
                final_df = final_df.sort_values('date', ascending=False).reset_index(drop=True)
                # è½¬å›å­—ç¬¦ä¸²æ ¼å¼
                final_df['date'] = final_df['date'].dt.strftime('%Y-%m-%d')
            
            print(f"âœ… {etf_code}: å‘é‡åŒ–å†å²è®¡ç®—å®Œæˆ ({len(final_df)}è¡Œ)")
            
            return final_df
            
        except Exception as e:
            print(f"âŒ {etf_code}: å‘é‡åŒ–å†å²è®¡ç®—å¼‚å¸¸: {str(e)}")
            return None
    
    def _calculate_vectorized_volatility_indicators(self, df: pd.DataFrame) -> None:
        """
        å‘é‡åŒ–è®¡ç®—æ³¢åŠ¨ç‡è¡ç”ŸæŒ‡æ ‡
        
        Args:
            df: æ•°æ®æ¡†ï¼ˆä¼šè¢«ä¿®æ”¹ï¼‰
        """
        try:
            # è®¡ç®—æ³¢åŠ¨ç‡æ¯”ç‡ï¼ˆå‘é‡åŒ–ï¼‰- æŒ‰ç¬¬ä¸€å¤§ç±»æ ‡å‡†ä½¿ç”¨å°å†™å­—æ®µå
            if 'vol_20' in df.columns and 'vol_30' in df.columns:
                vol_20 = df['vol_20']
                vol_30 = df['vol_30']
                
                # é¿å…é™¤é›¶
                vol_ratio = np.where(vol_30 != 0, vol_20 / vol_30, np.nan)
                df['vol_ratio_20_30'] = vol_ratio
                
                # å‘é‡åŒ–æ³¢åŠ¨ç‡çŠ¶æ€åˆ¤æ–­ - ä½¿ç”¨è‹±æ–‡çŠ¶æ€å€¼
                vol_state = np.select(
                    [vol_ratio > 1.5, vol_ratio > 1.2, vol_ratio > 0.8],
                    ['HIGH', 'MEDIUM', 'NORMAL'],
                    default='LOW'
                )
                df['vol_state'] = vol_state
            
            # è®¡ç®—æ³¢åŠ¨ç‡æ°´å¹³ï¼ˆå‘é‡åŒ–ï¼‰- æŒ‰ç¬¬ä¸€å¤§ç±»æ ‡å‡†ä½¿ç”¨å°å†™å­—æ®µå
            if 'vol_10' in df.columns:
                vol_10 = df['vol_10']
                
                if self.config.annualized:
                    vol_level = np.select(
                        [vol_10 > 0.4, vol_10 > 0.25, vol_10 > 0.15],
                        ['EXTREME_HIGH', 'HIGH', 'MEDIUM'],
                        default='LOW'
                    )
                else:
                    vol_level = np.select(
                        [vol_10 > 0.025, vol_10 > 0.016, vol_10 > 0.009],
                        ['EXTREME_HIGH', 'HIGH', 'MEDIUM'],
                        default='LOW'
                    )
                
                df['vol_level'] = vol_level
            
        except Exception as e:
            print(f"  âš ï¸ å‘é‡åŒ–æ³¢åŠ¨ç‡æŒ‡æ ‡è®¡ç®—è­¦å‘Š: {str(e)}")
    
    def calculate_incremental_update(self, cached_df: pd.DataFrame, new_df: pd.DataFrame,
                                   etf_code: str) -> Optional[pd.DataFrame]:
        """
        è®¡ç®—å¢é‡æ›´æ–°
        
        Args:
            cached_df: ç¼“å­˜çš„å†å²æ•°æ®
            new_df: æ–°çš„æ•°æ®
            etf_code: ETFä»£ç 
            
        Returns:
            pd.DataFrame: æ›´æ–°åçš„å®Œæ•´æ•°æ®
        """
        try:
            print(f"âš¡ {etf_code}: å¼€å§‹å¢é‡æ›´æ–°è®¡ç®—...")
            
            # ç¡®ä¿æ—¥æœŸåˆ—æ ¼å¼ä¸€è‡´
            if 'date' not in cached_df.columns:
                cached_df = cached_df.rename(columns={'æ—¥æœŸ': 'date'})
            if 'æ—¥æœŸ' in new_df.columns:
                new_df = new_df.rename(columns={'æ—¥æœŸ': 'date'})
            
            cached_df['date'] = pd.to_datetime(cached_df['date'])
            new_df['date'] = pd.to_datetime(new_df['date'])
            
            # æ‰¾å‡ºæ–°å¢çš„æ•°æ®è¡Œ
            cached_dates = set(cached_df['date'])
            new_dates = set(new_df['date'])
            
            # æ–°å¢æ—¥æœŸ
            incremental_dates = new_dates - cached_dates
            
            if not incremental_dates:
                print(f"   ğŸ“Š {etf_code}: æ— æ–°å¢æ•°æ®ï¼Œè¿”å›ç¼“å­˜æ•°æ®")
                return cached_df
            
            print(f"   ğŸ“ˆ {etf_code}: å‘ç° {len(incremental_dates)} ä¸ªæ–°å¢äº¤æ˜“æ—¥")
            
            # ä¼˜åŒ–ï¼šä½¿ç”¨æ›´é«˜æ•ˆçš„æ•°æ®åˆå¹¶æ–¹å¼
            incremental_df = new_df[new_df['date'].isin(incremental_dates)].copy()
            
            # æŒ‰æ—¥æœŸæ’åºååˆå¹¶ï¼ˆé¿å…å¤šæ¬¡æ’åºï¼‰
            incremental_df = incremental_df.sort_values('date', ascending=False).reset_index(drop=True)
            cached_df_sorted = cached_df.sort_values('date', ascending=False).reset_index(drop=True)
            
            # ä½¿ç”¨numpyæ•°ç»„åˆå¹¶æé«˜æ•ˆç‡
            combined_df = pd.concat([incremental_df, cached_df_sorted], ignore_index=True)
            
            # é‡æ–°è®¡ç®—æ‰€æœ‰æ³¢åŠ¨ç‡æŒ‡æ ‡ï¼ˆå› ä¸ºæ»šåŠ¨è®¡ç®—éœ€è¦è€ƒè™‘æ–°æ•°æ®ï¼‰
            max_period = max(self.config.volatility_periods) if self.config.volatility_periods else 60
            recalc_rows = min(len(combined_df), max_period * 2)  # é‡ç®—å½±å“èŒƒå›´
            
            print(f"   ğŸ”„ {etf_code}: é‡æ–°è®¡ç®—å‰ {recalc_rows} è¡Œæ•°æ®...")
            
            # åªé‡ç®—å—å½±å“çš„éƒ¨åˆ†ï¼ˆä¼˜åŒ–å†…å­˜ä½¿ç”¨ï¼‰
            if recalc_rows < len(combined_df):
                recalc_df = combined_df.iloc[:recalc_rows].copy()
                unchanged_df = combined_df.iloc[recalc_rows:].copy()
            else:
                recalc_df = combined_df.copy()
                unchanged_df = pd.DataFrame()
            
            # é‡æ–°è®¡ç®—æ³¢åŠ¨ç‡æŒ‡æ ‡
            updated_df = self.calculate_full_historical_volatility_optimized(
                recalc_df.rename(columns={'date': 'æ—¥æœŸ'}), etf_code
            )
            
            if updated_df is None:
                print(f"âŒ {etf_code}: å¢é‡è®¡ç®—å¤±è´¥")
                return cached_df
            
            # åˆå¹¶é‡ç®—æ•°æ®å’Œæœªå˜åŒ–æ•°æ®
            if not unchanged_df.empty:
                # ç¡®ä¿åˆ—ç»“æ„ä¸€è‡´
                for col in updated_df.columns:
                    if col not in unchanged_df.columns:
                        unchanged_df[col] = np.nan
                
                final_df = pd.concat([updated_df, unchanged_df], ignore_index=True)
            else:
                final_df = updated_df
            
            print(f"âœ… {etf_code}: å¢é‡æ›´æ–°å®Œæˆ (æ€»è®¡ {len(final_df)} è¡Œ)")
            
            # å†…å­˜æ¸…ç†
            del combined_df, recalc_df
            if not unchanged_df.empty:
                del unchanged_df
            gc.collect()
            
            return final_df
            
        except Exception as e:
            print(f"âŒ {etf_code}: å¢é‡æ›´æ–°å¼‚å¸¸: {str(e)}")
            return cached_df  # è¿”å›åŸå§‹ç¼“å­˜æ•°æ®
    
    def batch_calculate_historical_volatility(self, etf_files_dict: Dict[str, str],
                                            etf_codes: List[str], threshold: Optional[str] = None) -> Dict[str, pd.DataFrame]:
        """
        æ‰¹é‡è®¡ç®—å†å²æ³¢åŠ¨ç‡æ•°æ® - è¶…é«˜æ€§èƒ½å‘é‡åŒ–ç‰ˆæœ¬ï¼ˆæ”¯æŒç¼“å­˜ï¼‰
        
        Args:
            etf_files_dict: ETFä»£ç åˆ°æ–‡ä»¶è·¯å¾„çš„æ˜ å°„
            etf_codes: ETFä»£ç åˆ—è¡¨
            threshold: é—¨æ§›ç±»å‹ï¼ˆç”¨äºç¼“å­˜ï¼‰
            
        Returns:
            Dict[str, pd.DataFrame]: ETFä»£ç åˆ°å†å²æ•°æ®çš„æ˜ å°„
        """
        print(f"ğŸš€ å¼€å§‹æ‰¹é‡å†å²æ³¢åŠ¨ç‡è®¡ç®— ({len(etf_codes)}ä¸ªETF)...")
        results = {}
        
        # æ·»åŠ å†…å­˜ç®¡ç†ï¼šæ‰¹é‡å¤„ç†
        batch_size = 50  # æ¯æ‰¹å¤„ç†50ä¸ªETF
        processed_count = 0
        cache_hits = 0
        fresh_calculations = 0
        
        for i, etf_code in enumerate(etf_codes, 1):
            try:
                file_path = etf_files_dict.get(etf_code)
                if not file_path or not os.path.exists(file_path):
                    print(f"âš ï¸ [{i}/{len(etf_codes)}] {etf_code}: æ–‡ä»¶ä¸å­˜åœ¨")
                    continue
                
                print(f"ğŸ“Š [{i}/{len(etf_codes)}] å¤„ç†: {etf_code}")
                
                historical_df = None
                
                # å°è¯•ä»ç¼“å­˜åŠ è½½
                if self.cache_manager:
                    is_valid, meta_data = self.cache_manager.check_cache_validity(etf_code, file_path, threshold)
                    if is_valid:
                        cached_df = self.cache_manager.load_cache(etf_code, threshold)
                        if cached_df is not None and not cached_df.empty:
                            historical_df = cached_df
                            cache_hits += 1
                            print(f"   ğŸ’¾ {etf_code}: ç¼“å­˜å‘½ä¸­ ({len(historical_df)}è¡Œ)")
                
                # å¦‚æœç¼“å­˜æœªå‘½ä¸­ï¼Œè¿›è¡Œå…¨é‡è®¡ç®—
                if historical_df is None:
                    # è¯»å–æ•°æ®
                    df = pd.read_csv(file_path, encoding='utf-8')
                    
                    if df.empty:
                        print(f"   âŒ {etf_code}: æ•°æ®ä¸ºç©º")
                        continue
                    
                    # æ•°æ®é¢„å¤„ç†
                    required_columns = ['æ—¥æœŸ', 'å¼€ç›˜ä»·', 'æœ€é«˜ä»·', 'æœ€ä½ä»·', 'æ”¶ç›˜ä»·']
                    if not all(col in df.columns for col in required_columns):
                        print(f"   âŒ {etf_code}: ç¼ºå°‘å¿…éœ€å­—æ®µ")
                        continue
                    
                    # å‘é‡åŒ–è®¡ç®—
                    historical_df = self.calculate_full_historical_volatility_optimized(df, etf_code)
                    
                    if historical_df is not None:
                        fresh_calculations += 1
                        print(f"âœ… {etf_code}: å‘é‡åŒ–å†å²è®¡ç®—å®Œæˆ ({len(historical_df)}è¡Œ)")
                        
                        # ä¿å­˜åˆ°ç¼“å­˜
                        if self.cache_manager:
                            self.cache_manager.save_cache(etf_code, historical_df, file_path, threshold)
                    else:
                        print(f"   âŒ {etf_code}: è®¡ç®—å¤±è´¥")
                        continue
                    
                    # æ¸…ç†ä¸´æ—¶å˜é‡
                    del df
                
                # æ·»åŠ åˆ°ç»“æœ
                if historical_df is not None:
                    results[etf_code] = historical_df
                    print(f"   âœ… {etf_code}: å®Œæˆ ({len(historical_df)}è¡Œ)")
                    processed_count += 1
                
                # å†…å­˜ç®¡ç†ï¼šæ¯å¤„ç†ä¸€æ‰¹ETFåæ¸…ç†å†…å­˜
                if processed_count % batch_size == 0:
                    gc.collect()
                    print(f"   ğŸ§¹ å†…å­˜æ¸…ç†å®Œæˆ (å·²å¤„ç† {processed_count}/{len(etf_codes)})")
                
                # æ¸…ç†ä¸´æ—¶å˜é‡
                if 'historical_df' in locals():
                    del historical_df
                
            except Exception as e:
                print(f"   âŒ {etf_code}: æ‰¹é‡è®¡ç®—å¼‚å¸¸: {str(e)}")
                continue
        
        success_rate = (len(results) / len(etf_codes)) * 100
        print(f"\nğŸ‰ æ‰¹é‡å†å²è®¡ç®—å®Œæˆ!")
        print(f"   ğŸ“Š æˆåŠŸ: {len(results)}/{len(etf_codes)} ({success_rate:.1f}%)")
        print(f"   ğŸ’¾ ç¼“å­˜å‘½ä¸­: {cache_hits}")
        print(f"   ğŸ”„ å…¨æ–°è®¡ç®—: {fresh_calculations}")
        
        return results
    
    def save_historical_results(self, results: Dict[str, pd.DataFrame], 
                              output_dir: str, threshold: str) -> Dict[str, Any]:
        """
        ä¿å­˜å†å²è®¡ç®—ç»“æœ
        
        Args:
            results: è®¡ç®—ç»“æœ
            output_dir: è¾“å‡ºç›®å½•
            threshold: é—¨æ§›ç±»å‹
            
        Returns:
            Dict: ä¿å­˜ç»Ÿè®¡ä¿¡æ¯
        """
        try:
            # åˆ›å»ºè¾“å‡ºç›®å½•
            threshold_output_dir = os.path.join(output_dir, threshold)
            os.makedirs(threshold_output_dir, exist_ok=True)
            
            saved_count = 0
            total_size = 0
            saved_etfs = []
            
            print(f"ğŸ’¾ ä¿å­˜å†å²æ•°æ®åˆ°: {threshold_output_dir}")
            
            for etf_code, df in results.items():
                try:
                    clean_code = etf_code.replace('.SH', '').replace('.SZ', '')
                    output_file = os.path.join(threshold_output_dir, f"{clean_code}.csv")
                    
                    # ä¿å­˜æ–‡ä»¶
                    df.to_csv(output_file, index=False, encoding='utf-8', float_format='%.8f')
                    
                    # ç»Ÿè®¡ä¿¡æ¯
                    file_size = os.path.getsize(output_file)
                    total_size += file_size
                    saved_count += 1
                    saved_etfs.append(etf_code)
                    
                    if not self.config.performance_mode:
                        print(f"   ğŸ’¾ {etf_code}: {len(df)}è¡Œ â†’ {file_size/1024:.1f}KB")
                    
                except Exception as e:
                    print(f"   âŒ ä¿å­˜å¤±è´¥ {etf_code}: {str(e)}")
            
            stats = {
                'threshold': threshold,
                'saved_count': saved_count,
                'total_files': len(results),
                'success_rate': (saved_count / len(results)) * 100 if results else 0,
                'total_size_kb': total_size / 1024,
                'output_directory': threshold_output_dir,
                'etf_codes': saved_etfs
            }
            
            print(f"âœ… {threshold}: ä¿å­˜å®Œæˆ")
            print(f"   ğŸ“Š æ–‡ä»¶: {saved_count}/{len(results)}")
            print(f"   ğŸ’¾ å¤§å°: {stats['total_size_kb']:.1f}KB")
            
            return stats
            
        except Exception as e:
            print(f"âŒ å†å²ç»“æœä¿å­˜å¼‚å¸¸: {str(e)}")
            return {'error': str(e)}