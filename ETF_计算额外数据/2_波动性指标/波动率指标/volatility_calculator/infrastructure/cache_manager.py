#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ³¢åŠ¨ç‡ç¼“å­˜ç®¡ç†å™¨
=============

åŸºäºç¬¬ä¸€å¤§ç±»æ ‡å‡†çš„æ³¢åŠ¨ç‡ç¼“å­˜ç®¡ç†ç³»ç»Ÿ
"""

import os
import json
import pandas as pd
import numpy as np
from datetime import datetime
from typing import Dict, List, Optional, Any, Tuple
from .config import VolatilityConfig


class VolatilityCacheManager:
    """æ³¢åŠ¨ç‡ç¼“å­˜ç®¡ç†å™¨"""
    
    def __init__(self, config: VolatilityConfig):
        """
        åˆå§‹åŒ–ç¼“å­˜ç®¡ç†å™¨
        
        Args:
            config: æ³¢åŠ¨ç‡é…ç½®å¯¹è±¡
        """
        self.config = config
        self.cache_base_dir = os.path.join(config.volatility_script_dir, "cache")
        self.meta_dir = os.path.join(self.cache_base_dir, "meta")
        
        # ç¡®ä¿ç¼“å­˜ç›®å½•å­˜åœ¨
        os.makedirs(self.cache_base_dir, exist_ok=True)
        os.makedirs(self.meta_dir, exist_ok=True)
        
        if not config.performance_mode:
            print("ğŸ—‚ï¸ æ³¢åŠ¨ç‡ç¼“å­˜ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")
            print(f"   ğŸ“ ç¼“å­˜ç›®å½•: {self.cache_base_dir}")
    
    def get_cache_file_path(self, etf_code: str, threshold: Optional[str] = None) -> str:
        """è·å–ç¼“å­˜æ–‡ä»¶è·¯å¾„"""
        if threshold:
            threshold_dir = os.path.join(self.cache_base_dir, threshold)
            os.makedirs(threshold_dir, exist_ok=True)
            clean_code = etf_code.replace('.SH', '').replace('.SZ', '')
            return os.path.join(threshold_dir, f"{clean_code}.csv")
        else:
            clean_code = etf_code.replace('.SH', '').replace('.SZ', '')
            return os.path.join(self.cache_base_dir, f"{clean_code}.csv")
    
    def get_meta_file_path(self, etf_code: str, threshold: Optional[str] = None) -> str:
        """è·å–å…ƒæ•°æ®æ–‡ä»¶è·¯å¾„"""
        clean_code = etf_code.replace('.SH', '').replace('.SZ', '')
        if threshold:
            return os.path.join(self.meta_dir, f"{threshold}_{clean_code}_meta.json")
        else:
            return os.path.join(self.meta_dir, f"{clean_code}_meta.json")
    
    def check_cache_validity(self, etf_code: str, source_file_path: str,
                           threshold: Optional[str] = None) -> Tuple[bool, Optional[Dict]]:
        """æ£€æŸ¥ç¼“å­˜æœ‰æ•ˆæ€§"""
        try:
            cache_file = self.get_cache_file_path(etf_code, threshold)
            meta_file = self.get_meta_file_path(etf_code, threshold)
            
            # æ£€æŸ¥ç¼“å­˜æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not os.path.exists(cache_file) or not os.path.exists(meta_file):
                return False, None
            
            # è¯»å–å…ƒæ•°æ®
            with open(meta_file, 'r', encoding='utf-8') as f:
                meta_data = json.load(f)
            
            # æ£€æŸ¥æºæ–‡ä»¶ä¿®æ”¹æ—¶é—´
            if not os.path.exists(source_file_path):
                return False, None
            
            source_mtime = os.path.getmtime(source_file_path)
            cached_mtime = meta_data.get('source_file_mtime', 0)
            
            # æ£€æŸ¥é…ç½®æ˜¯å¦å˜åŒ–
            cached_config = meta_data.get('config', {})
            current_config = {
                'adj_type': self.config.adj_type,
                'volatility_periods': self.config.volatility_periods,
                'annualized': self.config.annualized
            }
            
            config_changed = cached_config != current_config
            file_changed = abs(source_mtime - cached_mtime) > 5  # 5ç§’å®¹å·®ï¼Œé¿å…æ–‡ä»¶ç³»ç»Ÿæ—¶é—´ç²¾åº¦é—®é¢˜
            
            is_valid = not (config_changed or file_changed)
            
            return is_valid, meta_data
            
        except Exception as e:
            if not self.config.performance_mode:
                print(f"âŒ ç¼“å­˜æ£€æŸ¥å¼‚å¸¸ {etf_code}: {str(e)}")
            return False, None
    
    def load_cache(self, etf_code: str, threshold: Optional[str] = None) -> Optional[pd.DataFrame]:
        """åŠ è½½ç¼“å­˜æ•°æ®"""
        try:
            cache_file = self.get_cache_file_path(etf_code, threshold)
            
            if not os.path.exists(cache_file):
                return None
            
            df = pd.read_csv(cache_file, encoding='utf-8')
            
            # ç¡®ä¿æ—¥æœŸåˆ—æ­£ç¡®è§£æ
            if 'date' in df.columns:
                df['date'] = pd.to_datetime(df['date'])
            
            return df
            
        except Exception as e:
            if not self.config.performance_mode:
                print(f"âŒ ç¼“å­˜åŠ è½½å¼‚å¸¸ {etf_code}: {str(e)}")
            return None
    
    def save_cache(self, etf_code: str, df: pd.DataFrame, source_file_path: str,
                   threshold: Optional[str] = None, additional_meta: Optional[Dict] = None) -> bool:
        """ä¿å­˜ç¼“å­˜æ•°æ®"""
        try:
            cache_file = self.get_cache_file_path(etf_code, threshold)
            meta_file = self.get_meta_file_path(etf_code, threshold)
            
            # ä¿å­˜æ•°æ®
            df.to_csv(cache_file, index=False, encoding='utf-8')
            
            # ç”Ÿæˆå…ƒæ•°æ®
            meta_data = {
                'etf_code': etf_code,
                'threshold': threshold,
                'cache_created_time': datetime.now().isoformat(),
                'source_file_path': source_file_path,
                'source_file_mtime': os.path.getmtime(source_file_path) if os.path.exists(source_file_path) else 0,
                'config': {
                    'adj_type': self.config.adj_type,
                    'volatility_periods': self.config.volatility_periods,
                    'annualized': self.config.annualized
                },
                'data_info': {
                    'rows': len(df),
                    'columns': list(df.columns),
                    'date_range': {
                        'start': df['date'].min().isoformat() if 'date' in df.columns and not df.empty else None,
                        'end': df['date'].max().isoformat() if 'date' in df.columns and not df.empty else None
                    }
                }
            }
            
            # æ·»åŠ é¢å¤–å…ƒæ•°æ®
            if additional_meta:
                meta_data.update(additional_meta)
            
            # ä¿å­˜å…ƒæ•°æ®
            with open(meta_file, 'w', encoding='utf-8') as f:
                json.dump(meta_data, f, ensure_ascii=False, indent=2)
            
            return True
            
        except Exception as e:
            if not self.config.performance_mode:
                print(f"âŒ ç¼“å­˜ä¿å­˜å¼‚å¸¸ {etf_code}: {str(e)}")
            return False
    
    def invalidate_cache(self, etf_code: str, threshold: Optional[str] = None) -> bool:
        """ä½¿ç¼“å­˜å¤±æ•ˆ"""
        try:
            cache_file = self.get_cache_file_path(etf_code, threshold)
            meta_file = self.get_meta_file_path(etf_code, threshold)
            
            # åˆ é™¤ç¼“å­˜æ–‡ä»¶
            if os.path.exists(cache_file):
                os.remove(cache_file)
            
            # åˆ é™¤å…ƒæ•°æ®æ–‡ä»¶
            if os.path.exists(meta_file):
                os.remove(meta_file)
            
            return True
            
        except Exception as e:
            if not self.config.performance_mode:
                print(f"âŒ ç¼“å­˜å¤±æ•ˆå¼‚å¸¸ {etf_code}: {str(e)}")
            return False
    
    def get_cache_info(self, threshold: Optional[str] = None) -> Dict[str, Any]:
        """è·å–ç¼“å­˜ä¿¡æ¯"""
        try:
            if threshold:
                cache_dir = os.path.join(self.cache_base_dir, threshold)
            else:
                cache_dir = self.cache_base_dir
            
            if not os.path.exists(cache_dir):
                return {'cached_files': 0, 'total_size_kb': 0}
            
            cached_files = []
            total_size = 0
            
            for file in os.listdir(cache_dir):
                if file.endswith('.csv'):
                    file_path = os.path.join(cache_dir, file)
                    file_size = os.path.getsize(file_path)
                    total_size += file_size
                    cached_files.append(file.replace('.csv', ''))
            
            return {
                'cached_files': len(cached_files),
                'total_size_kb': round(total_size / 1024, 2),
                'etf_codes': cached_files[:10]  # åªè¿”å›å‰10ä¸ª
            }
            
        except Exception as e:
            return {'error': f'è·å–ç¼“å­˜ä¿¡æ¯å¤±è´¥: {str(e)}'}
    
    def clear_cache(self, threshold: Optional[str] = None) -> int:
        """æ¸…é™¤ç¼“å­˜"""
        try:
            cleared_count = 0
            
            if threshold:
                # æ¸…é™¤ç‰¹å®šthresholdçš„ç¼“å­˜
                cache_dir = os.path.join(self.cache_base_dir, threshold)
                if os.path.exists(cache_dir):
                    for file in os.listdir(cache_dir):
                        if file.endswith('.csv'):
                            file_path = os.path.join(cache_dir, file)
                            os.remove(file_path)
                            cleared_count += 1
                            
                            # åˆ é™¤å¯¹åº”çš„å…ƒæ•°æ®
                            etf_code = file.replace('.csv', '')
                            meta_file = self.get_meta_file_path(etf_code, threshold)
                            if os.path.exists(meta_file):
                                os.remove(meta_file)
            else:
                # æ¸…é™¤æ‰€æœ‰ç¼“å­˜ï¼ˆåŒ…æ‹¬æ‰€æœ‰thresholdå­ç›®å½•ï¼‰
                if os.path.exists(self.cache_base_dir):
                    # æ¸…é™¤æ ¹ç›®å½•ä¸‹çš„csvæ–‡ä»¶
                    for file in os.listdir(self.cache_base_dir):
                        if file.endswith('.csv'):
                            file_path = os.path.join(self.cache_base_dir, file)
                            os.remove(file_path)
                            cleared_count += 1
                            
                            # åˆ é™¤å¯¹åº”çš„å…ƒæ•°æ®
                            etf_code = file.replace('.csv', '')
                            meta_file = self.get_meta_file_path(etf_code, None)
                            if os.path.exists(meta_file):
                                os.remove(meta_file)
                    
                    # æ¸…é™¤æ‰€æœ‰thresholdå­ç›®å½•
                    for item in os.listdir(self.cache_base_dir):
                        item_path = os.path.join(self.cache_base_dir, item)
                        if os.path.isdir(item_path) and item != "meta":
                            for file in os.listdir(item_path):
                                if file.endswith('.csv'):
                                    file_path = os.path.join(item_path, file)
                                    os.remove(file_path)
                                    cleared_count += 1
                                    
                                    # åˆ é™¤å¯¹åº”çš„å…ƒæ•°æ®
                                    etf_code = file.replace('.csv', '')
                                    meta_file = self.get_meta_file_path(etf_code, item)
                                    if os.path.exists(meta_file):
                                        os.remove(meta_file)
            
            return cleared_count
            
        except Exception as e:
            if not self.config.performance_mode:
                print(f"âŒ æ¸…é™¤ç¼“å­˜å¼‚å¸¸: {str(e)}")
            return 0