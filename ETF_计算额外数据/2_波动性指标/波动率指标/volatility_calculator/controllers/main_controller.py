#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ³¢åŠ¨ç‡ä¸»æ§åˆ¶å™¨
=============

åŸºäºç¬¬ä¸€å¤§ç±»æ ‡å‡†çš„æ³¢åŠ¨ç‡ä¸»æ§åˆ¶å™¨
ç»Ÿä¸€å­—æ®µæ ¼å¼ã€ç¼“å­˜ç®¡ç†å’Œæ‰¹é‡å¤„ç†
"""

import os
import pandas as pd
import numpy as np
from datetime import datetime
from typing import Dict, List, Optional, Any
from ..infrastructure.config import VolatilityConfig
from ..infrastructure.data_reader import VolatilityDataReader
from ..infrastructure.cache_manager import VolatilityCacheManager
from ..engines.volatility_engine import VolatilityEngine
from ..engines.historical_calculator import VolatilityHistoricalCalculator
from ..outputs.result_processor import VolatilityResultProcessor
from .etf_processor import VolatilityETFProcessor
from .batch_processor import VolatilityBatchProcessor


class VolatilityMainController:
    """æ³¢åŠ¨ç‡ä¸»æ§åˆ¶å™¨"""
    
    def __init__(self, adj_type: str = "å‰å¤æƒ", volatility_periods: Optional[List[int]] = None, 
                 output_dir: Optional[str] = None, enable_cache: bool = True, 
                 performance_mode: bool = True, annualized: bool = True):
        """
        åˆå§‹åŒ–æ³¢åŠ¨ç‡ä¸»æ§åˆ¶å™¨
        
        Args:
            adj_type: å¤æƒç±»å‹ï¼Œé»˜è®¤"å‰å¤æƒ"
            volatility_periods: æ³¢åŠ¨ç‡å‘¨æœŸåˆ—è¡¨ï¼Œé»˜è®¤[10, 20, 30, 60]
            output_dir: è¾“å‡ºç›®å½•ï¼Œé»˜è®¤Noneï¼ˆä½¿ç”¨é…ç½®ä¸­çš„é»˜è®¤ç›®å½•ï¼‰
            enable_cache: æ˜¯å¦å¯ç”¨ç¼“å­˜ï¼Œé»˜è®¤True
            performance_mode: æ˜¯å¦å¯ç”¨æ€§èƒ½æ¨¡å¼ï¼ˆå…³é—­è°ƒè¯•è¾“å‡ºï¼‰
            annualized: æ˜¯å¦è®¡ç®—å¹´åŒ–æ³¢åŠ¨ç‡
        """
        print("=" * 60)
        print("ğŸ“Š æ³¢åŠ¨ç‡ä¸»æ§åˆ¶å™¨å¯åŠ¨ - åŸºäºç¬¬ä¸€å¤§ç±»æ ‡å‡†")
        print("=" * 60)
        
        # åˆå§‹åŒ–é…ç½®
        self.config = VolatilityConfig(
            adj_type=adj_type, 
            volatility_periods=volatility_periods, 
            enable_cache=enable_cache, 
            performance_mode=performance_mode,
            annualized=annualized
        )
        self.output_dir = output_dir or self.config.default_output_dir
        self.enable_cache = enable_cache
        self.performance_mode = performance_mode
        
        # åˆå§‹åŒ–ç¼“å­˜ç®¡ç†å™¨
        self.cache_manager = None
        if enable_cache:
            self.cache_manager = VolatilityCacheManager(self.config)
        
        # åˆå§‹åŒ–æ ¸å¿ƒç»„ä»¶
        self.data_reader = VolatilityDataReader(self.config)
        self.volatility_engine = VolatilityEngine(self.config)
        self.historical_calculator = VolatilityHistoricalCalculator(self.config, self.cache_manager)
        self.result_processor = VolatilityResultProcessor(self.config)
        
        # åˆå§‹åŒ–å¤„ç†å™¨
        self.etf_processor = VolatilityETFProcessor(
            data_reader=self.data_reader,
            volatility_engine=self.volatility_engine,
            config=self.config
        )
        
        self.batch_processor = VolatilityBatchProcessor(
            etf_processor=self.etf_processor,
            cache_manager=self.cache_manager,
            config=self.config,
            enable_cache=enable_cache
        )
        
        print("ğŸ—‚ï¸ æ™ºèƒ½ç¼“å­˜ç³»ç»Ÿå·²å¯ç”¨" if enable_cache else "âš ï¸ ç¼“å­˜ç³»ç»Ÿå·²ç¦ç”¨")
        print("âœ… æ‰€æœ‰ç»„ä»¶åˆå§‹åŒ–å®Œæˆ")
        print("=" * 60)
    
    def get_available_etfs(self) -> List[str]:
        """è·å–å¯ç”¨çš„ETFä»£ç åˆ—è¡¨"""
        return self.data_reader.get_available_etfs()
    
    def process_single_etf(self, etf_code: str, include_advanced_analysis: bool = False) -> Optional[Dict]:
        """
        å¤„ç†å•ä¸ªETFçš„æ³¢åŠ¨ç‡è®¡ç®—
        
        Args:
            etf_code: ETFä»£ç 
            include_advanced_analysis: æ˜¯å¦åŒ…å«é«˜çº§åˆ†æ
            
        Returns:
            Dict: è®¡ç®—ç»“æœæˆ–None
        """
        print(f"ğŸ”„ å¼€å§‹å¤„ç†: {etf_code}")
        
        try:
            result = self.etf_processor.process_single_etf(etf_code, include_advanced_analysis)
            
            if result:
                print(f"âœ… {etf_code} å¤„ç†å®Œæˆ")
                return result
            else:
                print(f"âŒ {etf_code} å¤„ç†å¤±è´¥")
                return None
                
        except Exception as e:
            print(f"âŒ {etf_code} å¤„ç†å¼‚å¸¸: {str(e)}")
            return None
    
    def process_multiple_etfs(self, etf_codes: List[str], 
                            include_advanced_analysis: bool = False) -> List[Dict]:
        """
        å¤„ç†å¤šä¸ªETFçš„æ³¢åŠ¨ç‡è®¡ç®—
        
        Args:
            etf_codes: ETFä»£ç åˆ—è¡¨
            include_advanced_analysis: æ˜¯å¦åŒ…å«é«˜çº§åˆ†æ
            
        Returns:
            List[Dict]: è®¡ç®—ç»“æœåˆ—è¡¨
        """
        print(f"ğŸ“Š å¼€å§‹æ‰¹é‡å¤„ç† {len(etf_codes)} ä¸ªETF...")
        
        return self.batch_processor.process_etf_list(etf_codes, None, include_advanced_analysis)
    
    def calculate_and_save_screening_results(self, thresholds: Optional[List[str]] = None) -> Dict[str, Any]:
        """
        è®¡ç®—å¹¶ä¿å­˜ç­›é€‰ç»“æœçš„æ³¢åŠ¨ç‡æ•°æ® - æŒ‰ç¬¬ä¸€å¤§ç±»æ ‡å‡†
        
        Args:
            thresholds: é—¨æ§›åˆ—è¡¨ï¼Œé»˜è®¤["3000ä¸‡é—¨æ§›", "5000ä¸‡é—¨æ§›"]
            
        Returns:
            Dict[str, Any]: å¤„ç†ç»“æœç»Ÿè®¡
        """
        thresholds = thresholds or ["3000ä¸‡é—¨æ§›", "5000ä¸‡é—¨æ§›"]
        
        print(f"ğŸ“Š å¼€å§‹ç­›é€‰ç»“æœæ³¢åŠ¨ç‡è®¡ç®—å’Œä¿å­˜...")
        print(f"ğŸ“Š é—¨æ§›è®¾ç½®: {thresholds}")
        
        all_results = {}
        
        for threshold in thresholds:
            print(f"\nğŸ“ˆ å¤„ç†é—¨æ§›: {threshold}")
            
            # ä½¿ç”¨æ‰¹é‡å¤„ç†å™¨è¿›è¡Œå¢é‡æ›´æ–°è®¡ç®—
            results = self.batch_processor.process_screening_results(threshold)
            
            if results:
                all_results[threshold] = results
                print(f"âœ… {threshold}: {len(results)}ä¸ªETFå¢é‡æ›´æ–°å®Œæˆ")
                
                # æ˜¾ç¤ºå¢é‡æ›´æ–°ç»Ÿè®¡
                cache_hits = len([r for r in results if r.get('data_source') == 'cache'])
                incremental_updates = len([r for r in results if r.get('data_source') == 'incremental_update'])
                full_calculations = len([r for r in results if r.get('data_source') not in ['cache', 'incremental_update']])
                
                print(f"   ğŸ’¾ ç¼“å­˜å‘½ä¸­: {cache_hits}")
                print(f"   âš¡ å¢é‡æ›´æ–°: {incremental_updates}")
                print(f"   ğŸ”„ å…¨é‡è®¡ç®—: {full_calculations}")
            else:
                all_results[threshold] = []
                print(f"âŒ {threshold}: æ— å¯ç”¨ç»“æœ")
        
        # ä¿å­˜ç­›é€‰ç»“æœåˆ°dataç›®å½•
        if all_results:
            print(f"\nğŸ’¾ ä¿å­˜ç­›é€‰ç»“æœåˆ°dataç›®å½•...")
            save_stats = self.result_processor.save_screening_batch_results(all_results, self.output_dir)
            print(f"âœ… dataæ–‡ä»¶ä¿å­˜å®Œæˆ")
        
        # æ˜¾ç¤ºç»“æœé¢„è§ˆ
        for threshold, results in all_results.items():
            if results:
                print(f"\nğŸ“Š {threshold} ç»“æœé¢„è§ˆ:")
                self.result_processor.display_results(results[:3])  # æ˜¾ç¤ºå‰3ä¸ª
        
        return {
            'calculation_results': all_results,
            'total_etfs': sum(len(results) for results in all_results.values()),
            'mode': 'complete_with_data_save'
        }
    
    def calculate_historical_batch(self, etf_codes: Optional[List[str]] = None, 
                                 thresholds: Optional[List[str]] = None) -> Dict[str, Any]:
        """
        è¶…é«˜æ€§èƒ½å†å²æ‰¹é‡è®¡ç®— - æŒ‰ç¬¬ä¸€å¤§ç±»æ ‡å‡†
        
        Args:
            etf_codes: ETFä»£ç åˆ—è¡¨ï¼ŒNoneåˆ™å¤„ç†æ‰€æœ‰å¯ç”¨ETF
            thresholds: é—¨æ§›åˆ—è¡¨ï¼Œé»˜è®¤["3000ä¸‡é—¨æ§›", "5000ä¸‡é—¨æ§›"]
            
        Returns:
            Dict[str, Any]: å¤„ç†ç»“æœç»Ÿè®¡
        """
        thresholds = thresholds or ["3000ä¸‡é—¨æ§›", "5000ä¸‡é—¨æ§›"]
        
        print(f"ğŸš€ å¼€å§‹å†å²æ³¢åŠ¨ç‡æ•°æ®è®¡ç®—å’Œä¿å­˜...")
        print(f"ğŸ“Š é—¨æ§›è®¾ç½®: {thresholds}")
        
        all_stats = {}
        
        # ä¸ºæ¯ä¸ªé—¨æ§›åˆ†åˆ«å¤„ç†
        for threshold in thresholds:
            print(f"\nğŸ“ˆ è®¡ç®—é—¨æ§›: {threshold}")
            
            # è·å–è¯¥é—¨æ§›çš„ETFåˆ—è¡¨
            if etf_codes is None:
                threshold_etf_codes = self.data_reader.get_screening_etf_codes(threshold)
                print(f"ğŸ“Š {threshold}: è¯»å–ç­›é€‰ç»“æœ...")
                print(f"ğŸ“Š {threshold}: æ‰¾åˆ° {len(threshold_etf_codes)} ä¸ªé€šè¿‡ç­›é€‰çš„ETF")
            else:
                threshold_etf_codes = etf_codes
            
            print(f"ğŸ“ˆ {threshold} å¾…å¤„ç†ETFæ•°é‡: {len(threshold_etf_codes)}")
            
            # è·å–è¯¥é—¨æ§›çš„ETFæ–‡ä»¶è·¯å¾„å­—å…¸
            etf_files_dict = {}
            for etf_code in threshold_etf_codes:
                file_path = self.data_reader.get_etf_file_path(etf_code)
                if file_path and os.path.exists(file_path):
                    etf_files_dict[etf_code] = file_path
            
            print(f"ğŸ“ {threshold} æœ‰æ•ˆETFæ–‡ä»¶æ•°é‡: {len(etf_files_dict)}")
            
            # æ‰¹é‡è®¡ç®—å†å²æ³¢åŠ¨ç‡ï¼ˆæ”¯æŒç¼“å­˜ï¼‰
            results = self.historical_calculator.batch_calculate_historical_volatility(
                etf_files_dict, list(etf_files_dict.keys()), threshold
            )
            
            if results:
                # ä¿å­˜å†å²æ•°æ®æ–‡ä»¶
                save_stats = self.historical_calculator.save_historical_results(
                    results, self.output_dir, threshold
                )
                all_stats[threshold] = save_stats
                
                print(f"âœ… {threshold}: å†å²æ•°æ®è®¡ç®—å’Œä¿å­˜å®Œæˆ")
            else:
                print(f"âŒ {threshold}: å†å²æ•°æ®è®¡ç®—å¤±è´¥")
                all_stats[threshold] = {}
        
        # è®¡ç®—æ€»å¤„ç†ETFæ•°é‡
        total_etfs = sum(len(stats.get('etf_codes', [])) for stats in all_stats.values() if stats)
        
        return {
            'processing_statistics': all_stats,
            'total_etfs_processed': total_etfs,
            'thresholds_processed': thresholds
        }
    
    def quick_analysis(self, etf_code: str, include_historical: bool = False) -> Optional[Dict]:
        """
        å¿«é€Ÿåˆ†æå•ä¸ªETF
        
        Args:
            etf_code: ETFä»£ç 
            include_historical: æ˜¯å¦åŒ…å«å†å²æ•°æ®åˆ†æ
            
        Returns:
            Dict: åˆ†æç»“æœæˆ–None
        """
        print(f"ğŸ” å¿«é€Ÿåˆ†æ: {etf_code}")
        
        # å¤„ç†å•ä¸ªETF
        result = self.etf_processor.process_single_etf(etf_code, include_advanced_analysis=True)
        
        if not result:
            print(f"âŒ {etf_code}: åˆ†æå¤±è´¥")
            return None
        
        # æ˜¾ç¤ºåŸºç¡€ç»“æœ
        self.result_processor.display_results([result])
        
        # å¦‚æœéœ€è¦å†å²æ•°æ®åˆ†æ
        if include_historical:
            print(f"\nğŸš€ {etf_code}: å¼€å§‹å†å²æ•°æ®åˆ†æ...")
            
            # è¯»å–å®Œæ•´æ•°æ®
            data_result = self.data_reader.read_etf_data(etf_code)
            if data_result is not None:
                df, _ = data_result
                if not df.empty:
                    # è®¡ç®—å®Œæ•´å†å²æ³¢åŠ¨ç‡
                    historical_df = self.historical_calculator.calculate_full_historical_volatility_optimized(df, etf_code)
                    
                    if historical_df is not None:
                        # æ·»åŠ å†å²æ•°æ®åˆ°ç»“æœ
                        result['historical_analysis'] = {
                            'total_history_days': len(historical_df),
                            'valid_vol_days': historical_df[f'VOL_{max(self.config.volatility_periods)}'].notna().sum(),
                            'earliest_date': historical_df['date'].min() if 'date' in historical_df.columns else None,
                            'latest_date': historical_df['date'].max() if 'date' in historical_df.columns else None,
                            'historical_trend_summary': self._analyze_historical_trend(historical_df)
                        }
                        
                        print(f"âœ… {etf_code}: å†å²æ•°æ®åˆ†æå®Œæˆ")
                        print(f"   ğŸ“Š å†å²æ•°æ®: {result['historical_analysis']['total_history_days']}å¤©")
                        print(f"   ğŸ“ˆ æœ‰æ•ˆæ³¢åŠ¨ç‡: {result['historical_analysis']['valid_vol_days']}å¤©")
        
        return result
    
    def _analyze_historical_trend(self, historical_df: pd.DataFrame) -> Dict:
        """åˆ†æå†å²è¶‹åŠ¿"""
        try:
            # è·å–æœ€è¿‘30å¤©çš„æ•°æ®
            recent_data = historical_df.tail(30)  # æœ€æ–°åœ¨æœ€å
            
            if len(recent_data) < 10:
                return {'analysis': 'æ•°æ®ä¸è¶³ï¼Œæ— æ³•è¿›è¡Œè¶‹åŠ¿åˆ†æ'}
            
            # ä½¿ç”¨è‹±æ–‡å­—æ®µåï¼ˆå¤§å†™ï¼‰
            ratio_col = 'VOL_RATIO_20_30'
            
            if ratio_col in recent_data.columns:
                ratio_values = recent_data[ratio_col].dropna()
                if len(ratio_values) >= 5:
                    high_vol_count = (ratio_values > 1.2).sum()
                    trend_strength = high_vol_count / len(ratio_values)
                    
                    if trend_strength >= 0.7:
                        trend_desc = "é«˜æ³¢åŠ¨è¶‹åŠ¿"
                    elif trend_strength >= 0.3:
                        trend_desc = "æ³¢åŠ¨éœ‡è¡"
                    else:
                        trend_desc = "ä½æ³¢åŠ¨è¶‹åŠ¿"
                    
                    return {
                        'recent_trend': trend_desc,
                        'trend_strength': f"{trend_strength*100:.1f}%",
                        'recent_days_analyzed': len(ratio_values),
                        'latest_ratio': float(ratio_values.iloc[-1]) if len(ratio_values) > 0 else None,
                        'column_used': ratio_col
                    }
            
            return {'analysis': 'è¶‹åŠ¿åˆ†ææ•°æ®ä¸å®Œæ•´'}
            
        except Exception as e:
            return {'analysis': f'è¶‹åŠ¿åˆ†æå¤±è´¥: {str(e)}', 'error': str(e)}
    
    def get_system_status(self) -> Dict:
        """è·å–ç³»ç»ŸçŠ¶æ€"""
        try:
            status = {
                'system_info': {
                    'version': '1.0.0',
                    'config': f'æ³¢åŠ¨ç‡ç³»ç»Ÿ - {self.config.adj_type}',
                    'data_path': self.config.data_path,
                    'output_path': self.output_dir
                },
                'data_status': {
                    'available_etfs_count': len(self.data_reader.get_available_etfs()),
                    'data_path_valid': True,
                    'sample_etfs': self.data_reader.get_available_etfs()[:5]
                },
                'components': {
                    'Data Reader': 'Ready',
                    'Volatility Engine': 'Ready',
                    'ETF Processor': 'Ready',
                    'Batch Processor': 'Ready',
                    'Cache Manager': 'Ready' if self.enable_cache else 'Disabled'
                }
            }
            
            return status
            
        except Exception as e:
            return {'error': f'ç³»ç»ŸçŠ¶æ€æ£€æŸ¥å¤±è´¥: {str(e)}'}