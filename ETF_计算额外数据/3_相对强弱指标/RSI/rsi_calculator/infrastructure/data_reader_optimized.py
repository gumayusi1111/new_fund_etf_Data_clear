"""
RSIæŒ‡æ ‡ä¼˜åŒ–æ•°æ®è¯»å–å™¨
åŸºäºå¨å»‰æŒ‡æ ‡çš„ä¼˜åŒ–æ•°æ®è¯»å–æ¶æ„

ä¼˜åŒ–å†…å®¹ï¼š
1. é«˜æ•ˆçš„ETFæ•°æ®æ–‡ä»¶æ£€ç´¢å’Œè¯»å–
2. æ™ºèƒ½çš„æ•°æ®ç±»å‹è½¬æ¢å’ŒéªŒè¯
3. å†…å­˜ä¼˜åŒ–çš„æ•°æ®å¤„ç†æµç¨‹
4. æ”¯æŒå¤šç§å¤æƒç±»å‹çš„æ•°æ®è¯»å–
"""

import os
import pandas as pd
import numpy as np
from datetime import datetime
import traceback


class RSIDataReaderOptimized:
    """RSIæŒ‡æ ‡ä¼˜åŒ–æ•°æ®è¯»å–å™¨"""

    def __init__(self, config):
        """
        åˆå§‹åŒ–RSIæ•°æ®è¯»å–å™¨
        
        Args:
            config: RSIé…ç½®å¯¹è±¡
        """
        self.config = config
        self.data_source_path = config.data_source_path
        
        # éªŒè¯æ•°æ®æºè·¯å¾„
        if not os.path.exists(self.data_source_path):
            raise FileNotFoundError(f"æ•°æ®æºè·¯å¾„ä¸å­˜åœ¨: {self.data_source_path}")
        
        # æ€§èƒ½ç»Ÿè®¡
        self.stats = {
            'files_read': 0,
            'data_validation_errors': 0,
            'read_time_ms': 0
        }
        
        print(f"âœ… RSIä¼˜åŒ–æ•°æ®è¯»å–å™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"ğŸ“ æ•°æ®æºè·¯å¾„: {self.data_source_path}")

    def read_etf_data(self, etf_code):
        """
        è¯»å–æŒ‡å®šETFçš„OHLCVæ•°æ®
        
        Args:
            etf_code: ETFä»£ç 
            
        Returns:
            DataFrame: ETFæ•°æ®ï¼ŒåŒ…å«RSIè®¡ç®—æ‰€éœ€çš„æ¶¨è·Œå¹…å­—æ®µ
        """
        try:
            start_time = datetime.now()
            
            # æ¸…ç†ETFä»£ç 
            clean_code = self._clean_etf_code(etf_code)
            
            # æŸ¥æ‰¾æ•°æ®æ–‡ä»¶
            file_path = self._find_etf_data_file(clean_code)
            if not file_path:
                print(f"âš ï¸ æœªæ‰¾åˆ°ETFæ•°æ®æ–‡ä»¶: {etf_code}")
                return None
            
            # è¯»å–CSVæ•°æ®
            try:
                df = pd.read_csv(file_path, encoding='utf-8')
            except UnicodeDecodeError:
                # å¤‡ç”¨ç¼–ç 
                df = pd.read_csv(file_path, encoding='gbk')
            
            if df.empty:
                print(f"âš ï¸ ETFæ•°æ®æ–‡ä»¶ä¸ºç©º: {etf_code}")
                return None
            
            # æ•°æ®éªŒè¯å’Œæ¸…æ´—
            df = self._validate_and_clean_data(df, etf_code)
            if df is None:
                return None
            
            # æ·»åŠ RSIè®¡ç®—å¿…éœ€çš„æ¶¨è·Œå¹…å­—æ®µ
            df = self._add_price_change_fields(df, etf_code)
            
            # æ€§èƒ½ç»Ÿè®¡
            read_time = (datetime.now() - start_time).total_seconds() * 1000
            self.stats['files_read'] += 1
            self.stats['read_time_ms'] += read_time
            
            print(f"ğŸ“ˆ æˆåŠŸè¯»å–ETFæ•°æ®: {etf_code} ({len(df)}è¡Œ, {read_time:.2f}ms)")
            
            return df
            
        except Exception as e:
            print(f"âŒ è¯»å–ETFæ•°æ®å¤±è´¥: {etf_code} - {str(e)}")
            print(f"ğŸ” å¼‚å¸¸è¯¦æƒ…: {traceback.format_exc()}")
            return None

    def _clean_etf_code(self, etf_code):
        """æ¸…ç†ETFä»£ç æ ¼å¼"""
        if not etf_code:
            return ""
        
        # å»é™¤ç©ºæ ¼å’Œç‰¹æ®Šå­—ç¬¦
        clean_code = str(etf_code).strip()
        
        # ç¡®ä¿æ˜¯6ä½æ•°å­—æ ¼å¼
        if clean_code.isdigit() and len(clean_code) == 6:
            return clean_code
        
        # å°è¯•æå–6ä½æ•°å­—
        import re
        match = re.search(r'\d{6}', clean_code)
        if match:
            return match.group()
        
        return clean_code

    def _find_etf_data_file(self, etf_code):
        """
        æŸ¥æ‰¾ETFæ•°æ®æ–‡ä»¶
        æ”¯æŒå¤šç§æ–‡ä»¶åæ ¼å¼
        """
        if not etf_code:
            return None
        
        # å¯èƒ½çš„æ–‡ä»¶åæ ¼å¼
        possible_filenames = [
            f"{etf_code}.csv",
            f"{etf_code}.CSV"
        ]
        
        for filename in possible_filenames:
            file_path = os.path.join(self.data_source_path, filename)
            if os.path.exists(file_path):
                return file_path
        
        return None

    def _validate_and_clean_data(self, df, etf_code):
        """
        éªŒè¯å’Œæ¸…æ´—æ•°æ®
        ç¡®ä¿æ•°æ®è´¨é‡æ»¡è¶³RSIè®¡ç®—è¦æ±‚
        """
        try:
            # æ£€æŸ¥å¿…éœ€åˆ— - æ”¯æŒå¤šç§æ¶¨è·Œå¹…å­—æ®µå
            required_columns = ['æ—¥æœŸ', 'æ”¶ç›˜ä»·']
            change_columns = ['æ¶¨è·Œå¹…', 'æ¶¨å¹…%', 'æ¶¨è·Œ']  # å¯èƒ½çš„æ¶¨è·Œå¹…å­—æ®µå
            
            missing_columns = [col for col in required_columns if col not in df.columns]
            
            # æ£€æŸ¥æ˜¯å¦æœ‰ä»»ä½•ä¸€ä¸ªæ¶¨è·Œå¹…å­—æ®µ
            has_change_column = any(col in df.columns for col in change_columns)
            
            if missing_columns:
                print(f"âŒ ETFæ•°æ®ç¼ºå°‘å¿…éœ€åˆ—: {etf_code} - {missing_columns}")
                self.stats['data_validation_errors'] += 1
                return None
            
            if not has_change_column:
                print(f"âŒ ETFæ•°æ®ç¼ºå°‘æ¶¨è·Œå¹…ç›¸å…³åˆ—: {etf_code} - éœ€è¦ä»¥ä¸‹ä»»ä¸€åˆ—: {change_columns}")
                self.stats['data_validation_errors'] += 1
                return None
            
            # å¤‡ä»½åŸå§‹æ•°æ®
            original_length = len(df)
            
            # æ—¥æœŸå­—æ®µå¤„ç†
            if 'æ—¥æœŸ' in df.columns:
                try:
                    # å°è¯•å¤šç§æ—¥æœŸæ ¼å¼è½¬æ¢
                    if df['æ—¥æœŸ'].dtype == 'object':
                        # å¦‚æœæ˜¯å­—ç¬¦ä¸²ç±»å‹ï¼Œå°è¯•è½¬æ¢
                        df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'], format='%Y%m%d', errors='coerce')
                    elif df['æ—¥æœŸ'].dtype in ['int64', 'float64']:
                        # å¦‚æœæ˜¯æ•°å€¼ç±»å‹ï¼Œå…ˆè½¬æ¢ä¸ºå­—ç¬¦ä¸²å†è½¬æ¢ä¸ºæ—¥æœŸ
                        df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'].astype(str), format='%Y%m%d', errors='coerce')
                    else:
                        df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'], errors='coerce')
                    
                    # å»é™¤æ—¥æœŸæ— æ•ˆçš„è¡Œ
                    df = df.dropna(subset=['æ—¥æœŸ'])
                    print(f"ğŸ“… æ—¥æœŸè½¬æ¢æˆåŠŸ: {etf_code} - æ—¥æœŸèŒƒå›´ {df['æ—¥æœŸ'].min()} åˆ° {df['æ—¥æœŸ'].max()}")
                except Exception as e:
                    print(f"âš ï¸ æ—¥æœŸè½¬æ¢å¤±è´¥: {etf_code} - {str(e)}")
                    return None
            
            # æ•°å€¼å­—æ®µå¤„ç†
            numeric_columns = ['æ”¶ç›˜ä»·']
            
            # æ‰¾åˆ°å®é™…çš„æ¶¨è·Œå¹…å­—æ®µ
            change_column = None
            for col in ['æ¶¨è·Œå¹…', 'æ¶¨å¹…%', 'æ¶¨è·Œ']:
                if col in df.columns:
                    change_column = col
                    numeric_columns.append(col)
                    break
            
            for col in numeric_columns:
                if col in df.columns:
                    # è½¬æ¢ä¸ºæ•°å€¼ç±»å‹
                    df[col] = pd.to_numeric(df[col], errors='coerce')
            
            # å»é™¤å…³é”®æ•°å€¼å­—æ®µçš„ç©ºå€¼
            dropna_columns = ['æ”¶ç›˜ä»·']
            if change_column:
                dropna_columns.append(change_column)
            df = df.dropna(subset=dropna_columns)
            
            # æ£€æŸ¥æ•°æ®é‡æ˜¯å¦è¶³å¤Ÿ
            min_data_points = self.config.DATA_QUALITY_REQUIREMENTS['min_data_points']
            if len(df) < min_data_points:
                print(f"âš ï¸ ETFæ•°æ®é‡ä¸è¶³: {etf_code} - éœ€è¦{min_data_points}è¡Œï¼Œå®é™…{len(df)}è¡Œ")
                return None
            
            # æŒ‰æ—¥æœŸæ’åº
            df = df.sort_values('æ—¥æœŸ').reset_index(drop=True)
            
            # æ•°æ®è´¨é‡ç»Ÿè®¡
            cleaned_rows = original_length - len(df)
            if cleaned_rows > 0:
                print(f"ğŸ§¹ æ•°æ®æ¸…æ´—: {etf_code} - æ¸…æ´—äº†{cleaned_rows}è¡Œæ•°æ®")
            
            return df
            
        except Exception as e:
            print(f"âŒ æ•°æ®éªŒè¯å¤±è´¥: {etf_code} - {str(e)}")
            self.stats['data_validation_errors'] += 1
            return None

    def _add_price_change_fields(self, df, etf_code):
        """
        æ·»åŠ RSIè®¡ç®—å¿…éœ€çš„ä»·æ ¼å˜åŒ–å­—æ®µ
        
        Args:
            df: æ¸…æ´—åçš„æ•°æ®æ¡†
            etf_code: ETFä»£ç 
            
        Returns:
            DataFrame: åŒ…å«ä»·æ ¼å˜åŒ–å­—æ®µçš„æ•°æ®
        """
        try:
            # æŸ¥æ‰¾å¯ç”¨çš„æ¶¨è·Œå¹…å­—æ®µ
            change_column = None
            for col in ['æ¶¨è·Œå¹…', 'æ¶¨å¹…%', 'æ¶¨è·Œ']:
                if col in df.columns:
                    change_column = col
                    break
            
            if change_column:
                # ä½¿ç”¨æ¶¨è·Œå¹…å­—æ®µ
                if change_column == 'æ¶¨å¹…%':
                    # æ¶¨å¹…%å·²ç»æ˜¯ç™¾åˆ†æ¯”å½¢å¼ï¼Œç›´æ¥é™¤ä»¥100è½¬æ¢ä¸ºå°æ•°
                    df['price_change_pct'] = df[change_column] / 100.0
                else:
                    # å…¶ä»–å­—æ®µå¯èƒ½éœ€è¦ä¸åŒå¤„ç†
                    df['price_change_pct'] = df[change_column] / 100.0
            else:
                # å¦‚æœæ²¡æœ‰æ¶¨è·Œå¹…ï¼Œé€šè¿‡æ”¶ç›˜ä»·è®¡ç®—
                if 'æ”¶ç›˜ä»·' in df.columns:
                    df['price_change_pct'] = df['æ”¶ç›˜ä»·'].pct_change()
                else:
                    print(f"âŒ æ— æ³•è®¡ç®—ä»·æ ¼å˜åŒ–: {etf_code} - ç¼ºå°‘æ¶¨è·Œå¹…æˆ–æ”¶ç›˜ä»·å­—æ®µ")
                    return None
            
            # å»é™¤ç¬¬ä¸€è¡Œï¼ˆæ— æ³•è®¡ç®—å˜åŒ–ç‡ï¼‰
            df = df.dropna(subset=['price_change_pct']).reset_index(drop=True)
            
            # éªŒè¯ä»·æ ¼å˜åŒ–æ•°æ®çš„åˆç†æ€§
            price_changes = df['price_change_pct']
            
            # æ£€æŸ¥å¼‚å¸¸å€¼ï¼ˆæ—¥æ¶¨è·Œå¹…è¶…è¿‡50%çš„æƒ…å†µï¼‰
            extreme_changes = abs(price_changes) > 0.5
            if extreme_changes.any():
                extreme_count = extreme_changes.sum()
                print(f"âš ï¸ å‘ç°{extreme_count}ä¸ªæç«¯æ¶¨è·Œå¹…æ•°æ®: {etf_code}")
                
                # å¯é€‰ï¼šæ ‡è®°ä½†ä¸åˆ é™¤æç«¯å€¼ï¼Œè®©RSIè®¡ç®—å¼•æ“å¤„ç†
                df['has_extreme_change'] = extreme_changes
            
            return df
            
        except Exception as e:
            print(f"âŒ æ·»åŠ ä»·æ ¼å˜åŒ–å­—æ®µå¤±è´¥: {etf_code} - {str(e)}")
            return None

    def get_etf_file_list(self, threshold="3000ä¸‡é—¨æ§›"):
        """
        è·å–é€šè¿‡åˆç­›çš„ETFåˆ—è¡¨(ä¿®å¤ç‰ˆ)
        
        Args:
            threshold: é—¨æ§›ç±»å‹ ("3000ä¸‡é—¨æ§›" æˆ– "5000ä¸‡é—¨æ§›")
        
        Returns:
            list: é€šè¿‡åˆç­›çš„ETFä»£ç åˆ—è¡¨
        """
        try:
            etf_codes = []
            
            # æ„å»ºåˆç­›ç»“æœæ–‡ä»¶è·¯å¾„
            filter_file_path = os.path.join(
                self.config.project_root, 
                "ETF_åˆç­›", 
                "data", 
                threshold, 
                "é€šè¿‡ç­›é€‰ETF.txt"
            )
            
            if not os.path.exists(filter_file_path):
                print(f"âŒ åˆç­›ç»“æœæ–‡ä»¶ä¸å­˜åœ¨: {filter_file_path}")
                # é™çº§åˆ°åŸæœ‰é€»è¾‘
                return self._get_etf_file_list_fallback()
            
            # è¯»å–åˆç­›ç»“æœæ–‡ä»¶
            with open(filter_file_path, 'r', encoding='utf-8') as f:
                lines = f.readlines()
            
            # è§£æETFä»£ç 
            for line in lines:
                line = line.strip()
                # è·³è¿‡æ³¨é‡Šè¡Œå’Œç©ºè¡Œ
                if line and not line.startswith('#'):
                    etf_code = line
                    if etf_code.isdigit() and len(etf_code) == 6:
                        etf_codes.append(etf_code)
            
            etf_codes.sort()  # æ’åº
            print(f"ğŸ“Š è¯»å–{threshold}åˆç­›ç»“æœ: {len(etf_codes)}ä¸ªETF")
            
            return etf_codes
            
        except Exception as e:
            print(f"âŒ è¯»å–åˆç­›ç»“æœå¤±è´¥: {str(e)}")
            print("ğŸ”„ é™çº§åˆ°åŸæœ‰è·å–é€»è¾‘")
            return self._get_etf_file_list_fallback()

    def _get_etf_file_list_fallback(self):
        """
        é™çº§è·å–é€»è¾‘ï¼šæ‰«ææ•°æ®æºç›®å½•(åŸæœ‰é€»è¾‘)
        
        Returns:
            list: ETFä»£ç åˆ—è¡¨
        """
        try:
            etf_codes = []
            
            if not os.path.exists(self.data_source_path):
                print(f"âŒ æ•°æ®æºè·¯å¾„ä¸å­˜åœ¨: {self.data_source_path}")
                return etf_codes
            
            # éå†æ•°æ®æºç›®å½•
            for filename in os.listdir(self.data_source_path):
                if filename.endswith('.csv') or filename.endswith('.CSV'):
                    # æå–ETFä»£ç 
                    etf_code = filename.replace('.csv', '').replace('.CSV', '')
                    if etf_code.isdigit() and len(etf_code) == 6:
                        etf_codes.append(etf_code)
            
            etf_codes.sort()  # æ’åº
            print(f"ğŸ“Š é™çº§æ¨¡å¼: å‘ç°{len(etf_codes)}ä¸ªETFæ•°æ®æ–‡ä»¶")
            
            return etf_codes
            
        except Exception as e:
            print(f"âŒ é™çº§è·å–ETFæ–‡ä»¶åˆ—è¡¨å¤±è´¥: {str(e)}")
            return []

    def validate_data_source(self):
        """
        éªŒè¯æ•°æ®æºå®Œæ•´æ€§
        
        Returns:
            dict: éªŒè¯ç»“æœ
        """
        try:
            result = {
                'is_valid': True,
                'total_files': 0,
                'valid_files': 0,
                'invalid_files': 0,
                'error_details': []
            }
            
            if not os.path.exists(self.data_source_path):
                result['is_valid'] = False
                result['error_details'].append(f"æ•°æ®æºè·¯å¾„ä¸å­˜åœ¨: {self.data_source_path}")
                return result
            
            # è·å–æ‰€æœ‰æ–‡ä»¶
            all_files = [f for f in os.listdir(self.data_source_path) 
                        if f.endswith('.csv') or f.endswith('.CSV')]
            result['total_files'] = len(all_files)
            
            # éªŒè¯æ–‡ä»¶æ ¼å¼
            for filename in all_files[:10]:  # åªéªŒè¯å‰10ä¸ªæ–‡ä»¶ä»¥èŠ‚çœæ—¶é—´
                file_path = os.path.join(self.data_source_path, filename)
                try:
                    df = pd.read_csv(file_path, nrows=5)  # åªè¯»å–å‰5è¡Œ
                    required_columns = ['æ—¥æœŸ', 'æ”¶ç›˜ä»·']
                    if all(col in df.columns for col in required_columns):
                        result['valid_files'] += 1
                    else:
                        result['invalid_files'] += 1
                        result['error_details'].append(f"æ–‡ä»¶ç¼ºå°‘å¿…éœ€åˆ—: {filename}")
                except Exception as e:
                    result['invalid_files'] += 1
                    result['error_details'].append(f"æ–‡ä»¶è¯»å–å¤±è´¥: {filename} - {str(e)}")
            
            # å¦‚æœæŠ½æ ·éªŒè¯çš„æ–‡ä»¶éƒ½æœ‰é—®é¢˜ï¼Œæ ‡è®°ä¸ºæ— æ•ˆ
            if result['valid_files'] == 0 and result['invalid_files'] > 0:
                result['is_valid'] = False
            
            return result
            
        except Exception as e:
            return {
                'is_valid': False,
                'total_files': 0,
                'valid_files': 0,
                'invalid_files': 0,
                'error_details': [f"æ•°æ®æºéªŒè¯å¤±è´¥: {str(e)}"]
            }

    def get_performance_stats(self):
        """è·å–æ€§èƒ½ç»Ÿè®¡ä¿¡æ¯"""
        if self.stats['files_read'] > 0:
            avg_read_time = self.stats['read_time_ms'] / self.stats['files_read']
        else:
            avg_read_time = 0
        
        return {
            'files_read': self.stats['files_read'],
            'average_read_time_ms': round(avg_read_time, 2),
            'total_read_time_ms': round(self.stats['read_time_ms'], 2),
            'data_validation_errors': self.stats['data_validation_errors'],
            'success_rate': (self.stats['files_read'] / 
                           max(1, self.stats['files_read'] + self.stats['data_validation_errors']))
        }

    def print_performance_summary(self):
        """æ‰“å°æ€§èƒ½æ‘˜è¦"""
        stats = self.get_performance_stats()
        
        print(f"\n{'=' * 60}")
        print("ğŸ“Š RSIæ•°æ®è¯»å–å™¨æ€§èƒ½æ‘˜è¦")
        print(f"{'=' * 60}")
        print(f"ğŸ“ å·²è¯»å–æ–‡ä»¶æ•°: {stats['files_read']}")
        print(f"â±ï¸ å¹³å‡è¯»å–æ—¶é—´: {stats['average_read_time_ms']:.2f}ms")
        print(f"âš¡ æ€»è¯»å–æ—¶é—´: {stats['total_read_time_ms']:.2f}ms")
        print(f"âŒ éªŒè¯é”™è¯¯æ•°: {stats['data_validation_errors']}")
        print(f"âœ… æˆåŠŸç‡: {stats['success_rate']:.2%}")
        print(f"{'=' * 60}")


if __name__ == "__main__":
    # æ•°æ®è¯»å–å™¨æµ‹è¯•
    try:
        from config import RSIConfig
        
        print("ğŸ§ª RSIæ•°æ®è¯»å–å™¨æµ‹è¯•")
        config = RSIConfig()
        reader = RSIDataReaderOptimized(config)
        
        # éªŒè¯æ•°æ®æº
        validation = reader.validate_data_source()
        print(f"æ•°æ®æºéªŒè¯: {'âœ…' if validation['is_valid'] else 'âŒ'}")
        
        # è·å–ETFåˆ—è¡¨
        etf_list = reader.get_etf_file_list()
        if etf_list:
            print(f"å‘ç°{len(etf_list)}ä¸ªETFæ–‡ä»¶")
            
            # æµ‹è¯•è¯»å–ç¬¬ä¸€ä¸ªETF
            test_etf = etf_list[0]
            test_data = reader.read_etf_data(test_etf)
            if test_data is not None:
                print(f"æµ‹è¯•è¯»å–æˆåŠŸ: {test_etf} ({len(test_data)}è¡Œæ•°æ®)")
            
        # æ‰“å°æ€§èƒ½æ‘˜è¦
        reader.print_performance_summary()
        
        print("âœ… RSIæ•°æ®è¯»å–å™¨æµ‹è¯•å®Œæˆ")
        
    except Exception as e:
        print(f"âŒ RSIæ•°æ®è¯»å–å™¨æµ‹è¯•å¤±è´¥: {str(e)}")
        print(f"ğŸ” å¼‚å¸¸è¯¦æƒ…: {traceback.format_exc()}")