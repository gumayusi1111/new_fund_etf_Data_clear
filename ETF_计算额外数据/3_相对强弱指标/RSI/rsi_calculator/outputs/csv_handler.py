"""
RSIæŒ‡æ ‡CSVè¾“å‡ºå¤„ç†å™¨
åŸºäºå¨å»‰æŒ‡æ ‡çš„CSVå¤„ç†æ¶æ„

åŠŸèƒ½ç‰¹æ€§ï¼š
1. æ ‡å‡†åŒ–çš„CSVè¾“å‡ºæ ¼å¼
2. æ”¯æŒå¢é‡æ•°æ®åˆå¹¶
3. å¤šé—¨æ§›æ•°æ®ç»„ç»‡
4. æ•°æ®å®Œæ•´æ€§éªŒè¯
"""

import os
import pandas as pd
from datetime import datetime
import traceback


class RSICSVHandler:
    """RSIæŒ‡æ ‡CSVè¾“å‡ºå¤„ç†å™¨"""

    def __init__(self, config):
        """
        åˆå§‹åŒ–RSI CSVå¤„ç†å™¨
        
        Args:
            config: RSIé…ç½®å¯¹è±¡
        """
        self.config = config
        self.data_output_path = config.data_output_path
        
        # è¾“å‡ºç»Ÿè®¡
        self.output_stats = {
            'files_written': 0,
            'total_rows_written': 0,
            'merge_operations': 0,
            'validation_errors': 0
        }
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        self._ensure_output_directories()
        
        print("âœ… RSI CSVå¤„ç†å™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"ğŸ“¤ è¾“å‡ºè·¯å¾„: {self.data_output_path}")

    def _ensure_output_directories(self):
        """ç¡®ä¿è¾“å‡ºç›®å½•ç»“æ„å­˜åœ¨"""
        try:
            directories = [
                self.data_output_path,
                self.config.get_data_output_path("3000ä¸‡é—¨æ§›"),
                self.config.get_data_output_path("5000ä¸‡é—¨æ§›")
            ]
            
            for directory in directories:
                if not os.path.exists(directory):
                    os.makedirs(directory, exist_ok=True)
                    print(f"ğŸ“ åˆ›å»ºè¾“å‡ºç›®å½•: {directory}")
                    
        except Exception as e:
            print(f"âŒ åˆ›å»ºè¾“å‡ºç›®å½•å¤±è´¥: {str(e)}")

    def save_etf_rsi_data(self, etf_code, rsi_data, threshold):
        """
        ä¿å­˜ETFçš„RSIæ•°æ®åˆ°CSVæ–‡ä»¶
        
        Args:
            etf_code: ETFä»£ç 
            rsi_data: RSIè®¡ç®—ç»“æœæ•°æ®
            threshold: é—¨æ§›å€¼
            
        Returns:
            bool: ä¿å­˜æ˜¯å¦æˆåŠŸ
        """
        try:
            if rsi_data is None or rsi_data.empty:
                print(f"âš ï¸ RSIæ•°æ®ä¸ºç©ºï¼Œè·³è¿‡ä¿å­˜: {etf_code}")
                return False
            
            # è·å–è¾“å‡ºæ–‡ä»¶è·¯å¾„
            output_file_path = self._get_output_file_path(etf_code, threshold)
            
            # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
            output_dir = os.path.dirname(output_file_path)
            if not os.path.exists(output_dir):
                os.makedirs(output_dir, exist_ok=True)
            
            # éªŒè¯æ•°æ®æ ¼å¼
            if not self._validate_rsi_data(rsi_data, etf_code):
                return False
            
            # è®¾ç½®æ•°å€¼åˆ—çš„æ ¼å¼åŒ–ç²¾åº¦ï¼ˆ8ä½å°æ•°ï¼‰
            numeric_columns = ['rsi_6', 'rsi_12', 'rsi_24', 'rsi_diff_6_24', 'rsi_change_rate']
            format_dict = {}
            for col in numeric_columns:
                if col in rsi_data.columns:
                    format_dict[col] = '%.8f'
            
            # ä¿å­˜CSVæ–‡ä»¶ï¼Œä½¿ç”¨8ä½å°æ•°ç²¾åº¦æ ¼å¼
            rsi_data.to_csv(
                output_file_path, 
                index=False, 
                encoding=self.config.CSV_CONFIG['encoding'],
                date_format=self.config.CSV_CONFIG['date_format'],
                float_format='%.8f'  # å¼ºåˆ¶ä½¿ç”¨8ä½å°æ•°æ ¼å¼
            )
            
            # æ›´æ–°ç»Ÿè®¡
            self.output_stats['files_written'] += 1
            self.output_stats['total_rows_written'] += len(rsi_data)
            
            print(f"ğŸ“¤ RSIæ•°æ®ä¿å­˜æˆåŠŸ: {etf_code} ({len(rsi_data)}è¡Œæ•°æ®)")
            
            return True
            
        except Exception as e:
            print(f"âŒ RSIæ•°æ®ä¿å­˜å¤±è´¥: {etf_code} - {str(e)}")
            print(f"ğŸ” å¼‚å¸¸è¯¦æƒ…: {traceback.format_exc()}")
            self.output_stats['validation_errors'] += 1
            return False

    def _get_output_file_path(self, etf_code, threshold):
        """è·å–è¾“å‡ºæ–‡ä»¶è·¯å¾„"""
        output_dir = self.config.get_data_output_path(threshold)
        return os.path.join(output_dir, f"{etf_code}.csv")

    def _validate_rsi_data(self, rsi_data, etf_code):
        """
        éªŒè¯RSIæ•°æ®æ ¼å¼
        
        Args:
            rsi_data: RSIæ•°æ®
            etf_code: ETFä»£ç 
            
        Returns:
            bool: æ•°æ®æ˜¯å¦æœ‰æ•ˆ
        """
        try:
            # æ£€æŸ¥å¿…éœ€å­—æ®µ
            required_fields = ['code', 'date', 'rsi_6', 'rsi_12', 'rsi_24']
            missing_fields = [field for field in required_fields if field not in rsi_data.columns]
            
            if missing_fields:
                print(f"âŒ RSIæ•°æ®ç¼ºå°‘å¿…éœ€å­—æ®µ: {etf_code} - {missing_fields}")
                self.output_stats['validation_errors'] += 1
                return False
            
            # æ£€æŸ¥æ•°æ®ç±»å‹
            if rsi_data['code'].isna().any() or (rsi_data['code'] == '').any():
                print(f"âš ï¸ RSIæ•°æ®åŒ…å«ç©ºçš„ETFä»£ç : {etf_code}")
                # ä¸è¿”å›Falseï¼Œåªç»™å‡ºè­¦å‘Šï¼Œå…è®¸æ•°æ®ä¿å­˜
            
            if rsi_data['date'].isna().any():
                print(f"âš ï¸ RSIæ•°æ®åŒ…å«ç©ºçš„æ—¥æœŸ: {etf_code}")
                return False
            
            # æ£€æŸ¥RSIæ•°å€¼èŒƒå›´ï¼ˆ0-100ï¼‰
            rsi_fields = ['rsi_6', 'rsi_12', 'rsi_24']
            for field in rsi_fields:
                if field in rsi_data.columns:
                    valid_values = rsi_data[field].dropna()
                    if not valid_values.empty:
                        out_of_range = ((valid_values < 0) | (valid_values > 100))
                        if out_of_range.any():
                            print(f"âš ï¸ RSIæ•°æ®è¶…å‡ºèŒƒå›´(0-100): {etf_code} - {field}")
                            # ä¸è¿”å›Falseï¼Œå…è®¸æ•°æ®ä¿å­˜ä½†ç»™å‡ºè­¦å‘Š
            
            return True
            
        except Exception as e:
            print(f"âŒ RSIæ•°æ®éªŒè¯å¤±è´¥: {etf_code} - {str(e)}")
            self.output_stats['validation_errors'] += 1
            return False

    def merge_incremental_data(self, etf_code, threshold, incremental_data):
        """
        åˆå¹¶å¢é‡æ•°æ®åˆ°ç°æœ‰æ–‡ä»¶
        
        Args:
            etf_code: ETFä»£ç 
            threshold: é—¨æ§›å€¼
            incremental_data: å¢é‡æ•°æ®
            
        Returns:
            DataFrame: åˆå¹¶åçš„å®Œæ•´æ•°æ®
        """
        try:
            if incremental_data is None or incremental_data.empty:
                print(f"ğŸ“Š æ— å¢é‡æ•°æ®éœ€è¦åˆå¹¶: {etf_code}")
                return pd.DataFrame()
            
            output_file_path = self._get_output_file_path(etf_code, threshold)
            
            # æ£€æŸ¥ç°æœ‰æ–‡ä»¶
            if os.path.exists(output_file_path):
                try:
                    existing_data = pd.read_csv(output_file_path)
                    print(f"ğŸ“Š åŠ è½½ç°æœ‰æ•°æ®: {etf_code} ({len(existing_data)}è¡Œ)")
                except Exception as e:
                    print(f"âš ï¸ è¯»å–ç°æœ‰æ–‡ä»¶å¤±è´¥: {etf_code} - {str(e)}")
                    existing_data = pd.DataFrame()
            else:
                existing_data = pd.DataFrame()
            
            # åˆå¹¶æ•°æ®
            if not existing_data.empty:
                # å»é‡åˆå¹¶ï¼ˆåŸºäºæ—¥æœŸï¼‰
                if 'date' in existing_data.columns and 'date' in incremental_data.columns:
                    # ç§»é™¤ç°æœ‰æ•°æ®ä¸­ä¸å¢é‡æ•°æ®æ—¥æœŸé‡å¤çš„è¡Œ
                    incremental_dates = set(incremental_data['date'].unique())
                    existing_data = existing_data[~existing_data['date'].isin(incremental_dates)]
                    
                    # åˆå¹¶æ•°æ®
                    merged_data = pd.concat([existing_data, incremental_data], ignore_index=True)
                    
                    # æŒ‰æ—¥æœŸæ’åº
                    merged_data = merged_data.sort_values('date').reset_index(drop=True)
                    
                    print(f"ğŸ“Š æ•°æ®åˆå¹¶å®Œæˆ: {etf_code} ({len(existing_data)}+{len(incremental_data)}={len(merged_data)}è¡Œ)")
                else:
                    print(f"âš ï¸ æ— æ³•åŸºäºæ—¥æœŸåˆå¹¶ï¼Œä½¿ç”¨å¢é‡æ•°æ®: {etf_code}")
                    merged_data = incremental_data
            else:
                merged_data = incremental_data
                print(f"ğŸ“Š ä½¿ç”¨å¢é‡æ•°æ®ä½œä¸ºå®Œæ•´æ•°æ®: {etf_code} ({len(merged_data)}è¡Œ)")
            
            # ä¿å­˜åˆå¹¶åçš„æ•°æ®
            if self.save_etf_rsi_data(etf_code, merged_data, threshold):
                self.output_stats['merge_operations'] += 1
                return merged_data
            else:
                return pd.DataFrame()
            
        except Exception as e:
            print(f"âŒ å¢é‡æ•°æ®åˆå¹¶å¤±è´¥: {etf_code} - {str(e)}")
            print(f"ğŸ” å¼‚å¸¸è¯¦æƒ…: {traceback.format_exc()}")
            return pd.DataFrame()

    def load_existing_data(self, etf_code, threshold):
        """
        åŠ è½½ç°æœ‰çš„RSIæ•°æ®
        
        Args:
            etf_code: ETFä»£ç 
            threshold: é—¨æ§›å€¼
            
        Returns:
            DataFrame: ç°æœ‰æ•°æ®
        """
        try:
            output_file_path = self._get_output_file_path(etf_code, threshold)
            
            if not os.path.exists(output_file_path):
                print(f"ğŸ“ è¾“å‡ºæ–‡ä»¶ä¸å­˜åœ¨: {etf_code}")
                return pd.DataFrame()
            
            # è¯»å–ç°æœ‰æ•°æ®
            existing_data = pd.read_csv(output_file_path)
            
            if existing_data.empty:
                print(f"âš ï¸ è¾“å‡ºæ–‡ä»¶ä¸ºç©º: {etf_code}")
                return pd.DataFrame()
            
            print(f"ğŸ“Š åŠ è½½ç°æœ‰æ•°æ®: {etf_code} ({len(existing_data)}è¡Œ)")
            return existing_data
            
        except Exception as e:
            print(f"âŒ åŠ è½½ç°æœ‰æ•°æ®å¤±è´¥: {etf_code} - {str(e)}")
            return pd.DataFrame()

    def batch_export_rsi_data(self, rsi_results_dict, threshold):
        """
        æ‰¹é‡å¯¼å‡ºRSIæ•°æ®
        
        Args:
            rsi_results_dict: RSIç»“æœå­—å…¸ {etf_code: rsi_data}
            threshold: é—¨æ§›å€¼
            
        Returns:
            dict: å¯¼å‡ºç»Ÿè®¡ä¿¡æ¯
        """
        try:
            export_stats = {
                'total_etfs': len(rsi_results_dict),
                'successful_exports': 0,
                'failed_exports': 0,
                'total_rows': 0
            }
            
            print(f"ğŸ“¦ å¼€å§‹æ‰¹é‡å¯¼å‡ºRSIæ•°æ®: {threshold}")
            print(f"ğŸ“Š å¾…å¯¼å‡ºETFæ•°é‡: {export_stats['total_etfs']}")
            
            for etf_code, rsi_data in rsi_results_dict.items():
                try:
                    if self.save_etf_rsi_data(etf_code, rsi_data, threshold):
                        export_stats['successful_exports'] += 1
                        export_stats['total_rows'] += len(rsi_data) if rsi_data is not None else 0
                    else:
                        export_stats['failed_exports'] += 1
                        
                except Exception as e:
                    print(f"âŒ å¯¼å‡ºå•ä¸ªETFå¤±è´¥: {etf_code} - {str(e)}")
                    export_stats['failed_exports'] += 1
            
            # æ‰“å°å¯¼å‡ºæ‘˜è¦
            success_rate = (export_stats['successful_exports'] / export_stats['total_etfs'] * 100) if export_stats['total_etfs'] > 0 else 0
            
            print(f"ğŸ“¦ æ‰¹é‡å¯¼å‡ºå®Œæˆ:")
            print(f"   æ€»ETFæ•°: {export_stats['total_etfs']}")
            print(f"   æˆåŠŸå¯¼å‡º: {export_stats['successful_exports']}")
            print(f"   å¤±è´¥å¯¼å‡º: {export_stats['failed_exports']}")
            print(f"   æˆåŠŸç‡: {success_rate:.1f}%")
            print(f"   æ€»è¡Œæ•°: {export_stats['total_rows']}")
            
            return export_stats
            
        except Exception as e:
            print(f"âŒ æ‰¹é‡å¯¼å‡ºå¤±è´¥: {str(e)}")
            return {'error': str(e)}

    def get_file_list(self, threshold):
        """
        è·å–æŒ‡å®šé—¨æ§›çš„æ‰€æœ‰RSIæ–‡ä»¶åˆ—è¡¨
        
        Args:
            threshold: é—¨æ§›å€¼
            
        Returns:
            list: æ–‡ä»¶åˆ—è¡¨
        """
        try:
            output_dir = self.config.get_data_output_path(threshold)
            
            if not os.path.exists(output_dir):
                print(f"ğŸ“ è¾“å‡ºç›®å½•ä¸å­˜åœ¨: {output_dir}")
                return []
            
            # è·å–æ‰€æœ‰CSVæ–‡ä»¶
            csv_files = [f for f in os.listdir(output_dir) if f.endswith('.csv')]
            
            # æå–ETFä»£ç 
            etf_codes = []
            for filename in csv_files:
                etf_code = filename.replace('.csv', '')
                if etf_code.isdigit() and len(etf_code) == 6:
                    etf_codes.append(etf_code)
            
            etf_codes.sort()
            print(f"ğŸ“Š å‘ç°{len(etf_codes)}ä¸ªRSIæ•°æ®æ–‡ä»¶: {threshold}")
            
            return etf_codes
            
        except Exception as e:
            print(f"âŒ è·å–æ–‡ä»¶åˆ—è¡¨å¤±è´¥: {threshold} - {str(e)}")
            return []

    def validate_output_data(self, threshold, sample_size=10):
        """
        éªŒè¯è¾“å‡ºæ•°æ®è´¨é‡
        
        Args:
            threshold: é—¨æ§›å€¼
            sample_size: æŠ½æ ·éªŒè¯çš„æ–‡ä»¶æ•°é‡
            
        Returns:
            dict: éªŒè¯ç»“æœ
        """
        try:
            validation_result = {
                'total_files': 0,
                'validated_files': 0,
                'valid_files': 0,
                'invalid_files': 0,
                'validation_errors': []
            }
            
            # è·å–æ–‡ä»¶åˆ—è¡¨
            etf_codes = self.get_file_list(threshold)
            validation_result['total_files'] = len(etf_codes)
            
            if not etf_codes:
                return validation_result
            
            # æŠ½æ ·éªŒè¯
            sample_codes = etf_codes[:min(sample_size, len(etf_codes))]
            
            for etf_code in sample_codes:
                validation_result['validated_files'] += 1
                
                try:
                    # è¯»å–æ–‡ä»¶
                    rsi_data = self.load_existing_data(etf_code, threshold)
                    
                    if rsi_data.empty:
                        validation_result['invalid_files'] += 1
                        validation_result['validation_errors'].append(f"{etf_code}: æ–‡ä»¶ä¸ºç©º")
                        continue
                    
                    # éªŒè¯æ•°æ®æ ¼å¼
                    if self._validate_rsi_data(rsi_data, etf_code):
                        validation_result['valid_files'] += 1
                    else:
                        validation_result['invalid_files'] += 1
                        validation_result['validation_errors'].append(f"{etf_code}: æ•°æ®æ ¼å¼æ— æ•ˆ")
                        
                except Exception as e:
                    validation_result['invalid_files'] += 1
                    validation_result['validation_errors'].append(f"{etf_code}: è¯»å–å¤±è´¥ - {str(e)}")
            
            # è®¡ç®—éªŒè¯æˆåŠŸç‡
            if validation_result['validated_files'] > 0:
                validation_result['success_rate'] = (
                    validation_result['valid_files'] / validation_result['validated_files'] * 100
                )
            else:
                validation_result['success_rate'] = 0
            
            print(f"ğŸ” æ•°æ®éªŒè¯å®Œæˆ: {threshold}")
            print(f"   éªŒè¯æ–‡ä»¶: {validation_result['validated_files']}/{validation_result['total_files']}")
            print(f"   æœ‰æ•ˆæ–‡ä»¶: {validation_result['valid_files']}")
            print(f"   æ— æ•ˆæ–‡ä»¶: {validation_result['invalid_files']}")
            print(f"   æˆåŠŸç‡: {validation_result['success_rate']:.1f}%")
            
            return validation_result
            
        except Exception as e:
            print(f"âŒ æ•°æ®éªŒè¯å¤±è´¥: {threshold} - {str(e)}")
            return {'error': str(e)}

    def get_output_stats(self):
        """è·å–è¾“å‡ºç»Ÿè®¡ä¿¡æ¯"""
        return {
            'files_written': self.output_stats['files_written'],
            'total_rows_written': self.output_stats['total_rows_written'],
            'merge_operations': self.output_stats['merge_operations'],
            'validation_errors': self.output_stats['validation_errors'],
            'average_rows_per_file': (
                self.output_stats['total_rows_written'] / max(1, self.output_stats['files_written'])
            )
        }

    def print_output_summary(self):
        """æ‰“å°è¾“å‡ºå¤„ç†å™¨æ‘˜è¦"""
        stats = self.get_output_stats()
        
        print(f"\n{'=' * 60}")
        print("ğŸ“¤ RSI CSVå¤„ç†å™¨æ‘˜è¦")
        print(f"{'=' * 60}")
        print(f"ğŸ“ å·²å†™å…¥æ–‡ä»¶: {stats['files_written']}")
        print(f"ğŸ“Š æ€»å†™å…¥è¡Œæ•°: {stats['total_rows_written']}")
        print(f"ğŸ“ˆ å¹³å‡æ¯æ–‡ä»¶è¡Œæ•°: {stats['average_rows_per_file']:.1f}")
        print(f"ğŸ”„ åˆå¹¶æ“ä½œæ¬¡æ•°: {stats['merge_operations']}")
        print(f"âŒ éªŒè¯é”™è¯¯æ•°: {stats['validation_errors']}")
        print(f"{'=' * 60}")


if __name__ == "__main__":
    # CSVå¤„ç†å™¨æµ‹è¯•
    try:
        from infrastructure.config import RSIConfig
        
        print("ğŸ§ª RSI CSVå¤„ç†å™¨æµ‹è¯•")
        config = RSIConfig()
        csv_handler = RSICSVHandler(config)
        
        # æ‰“å°å¤„ç†å™¨æ‘˜è¦
        csv_handler.print_output_summary()
        
        # æµ‹è¯•è·å–æ–‡ä»¶åˆ—è¡¨
        for threshold in ["3000ä¸‡é—¨æ§›", "5000ä¸‡é—¨æ§›"]:
            file_list = csv_handler.get_file_list(threshold)
            print(f"ğŸ“Š {threshold}: {len(file_list)}ä¸ªæ–‡ä»¶")
        
        print("âœ… RSI CSVå¤„ç†å™¨æµ‹è¯•å®Œæˆ")
        
    except Exception as e:
        print(f"âŒ RSI CSVå¤„ç†å™¨æµ‹è¯•å¤±è´¥: {str(e)}")
        print(f"ğŸ” å¼‚å¸¸è¯¦æƒ…: {traceback.format_exc()}")