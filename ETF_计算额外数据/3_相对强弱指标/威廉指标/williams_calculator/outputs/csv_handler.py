"""
å¨å»‰æŒ‡æ ‡CSVè¾“å‡ºå¤„ç†æ¨¡å—
åŸºäºè¶‹åŠ¿æŒ‡æ ‡å’Œæ³¢åŠ¨æ€§æŒ‡æ ‡çš„ç»Ÿä¸€è¾“å‡ºæ¶æ„

CSVå¤„ç†å™¨ï¼Œæä¾›ï¼š
- æ ‡å‡†åŒ–CSVè¾“å‡ºæ ¼å¼
- 8ä½å°æ•°ç²¾åº¦ç»Ÿä¸€å¤„ç†
- åŒé—¨æ§›æ–‡ä»¶ç»„ç»‡ç®¡ç†
- UTF-8ç¼–ç è¾“å‡º
- æ•°æ®å®Œæ•´æ€§éªŒè¯
- æ‰¹é‡æ–‡ä»¶æ“ä½œæ”¯æŒ
"""

import os
import pandas as pd
import numpy as np
from datetime import datetime
import warnings

# å¿½ç•¥pandasçš„é“¾å¼èµ‹å€¼è­¦å‘Š
warnings.filterwarnings('ignore', category=pd.errors.PerformanceWarning)


class WilliamsCSVHandler:
    """å¨å»‰æŒ‡æ ‡CSVè¾“å‡ºå¤„ç†å™¨"""
    
    def __init__(self, config):
        """
        åˆå§‹åŒ–CSVå¤„ç†å™¨
        
        Args:
            config: å¨å»‰æŒ‡æ ‡é…ç½®å¯¹è±¡
        """
        self.config = config
        self.data_output_path = config.data_output_path
        self.csv_config = config.CSV_CONFIG
        self.output_fields = config.get_output_fields()
        self.decimal_precision = config.CSV_CONFIG['decimal_places']
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        self._ensure_output_directories()

    def _ensure_output_directories(self):
        """ç¡®ä¿è¾“å‡ºç›®å½•ç»“æ„å­˜åœ¨"""
        directories = [
            self.data_output_path,
            os.path.join(self.data_output_path, "3000ä¸‡é—¨æ§›"),
            os.path.join(self.data_output_path, "5000ä¸‡é—¨æ§›")
        ]
        
        for directory in directories:
            if not os.path.exists(directory):
                os.makedirs(directory, exist_ok=True)

    def save_etf_williams_data(self, etf_code, df, threshold):
        """
        ä¿å­˜ETFå¨å»‰æŒ‡æ ‡æ•°æ®åˆ°CSVæ–‡ä»¶
        
        Args:
            etf_code: ETFä»£ç 
            df: å¨å»‰æŒ‡æ ‡æ•°æ®DataFrame
            threshold: é—¨æ§›å€¼('3000ä¸‡é—¨æ§›' or '5000ä¸‡é—¨æ§›')
            
        Returns:
            bool: ä¿å­˜æ˜¯å¦æˆåŠŸ
        """
        try:
            if df.empty:
                print(f"âš ï¸ ç©ºæ•°æ®ï¼Œè·³è¿‡ä¿å­˜: {etf_code}")
                return False
            
            # æ ¼å¼åŒ–è¾“å‡ºæ•°æ®
            formatted_df = self._format_output_data(df, etf_code)
            if formatted_df.empty:
                print(f"âš ï¸ æ•°æ®æ ¼å¼åŒ–å¤±è´¥: {etf_code}")
                return False
            
            # æ„å»ºè¾“å‡ºæ–‡ä»¶è·¯å¾„
            output_file_path = self._get_output_file_path(etf_code, threshold)
            
            # ä¿å­˜åˆ°CSVæ–‡ä»¶
            self._save_to_csv_file(formatted_df, output_file_path, etf_code)
            
            return True
            
        except Exception as e:
            print(f"âŒ ä¿å­˜ETFå¨å»‰æŒ‡æ ‡æ•°æ®å¤±è´¥: {etf_code} - {str(e)}")
            return False

    def _format_output_data(self, df, etf_code):
        """
        æ ¼å¼åŒ–è¾“å‡ºæ•°æ®
        
        Args:
            df: åŸå§‹æ•°æ®DataFrame
            etf_code: ETFä»£ç 
            
        Returns:
            DataFrame: æ ¼å¼åŒ–åçš„æ•°æ®
        """
        try:
            if df.empty:
                return pd.DataFrame()
            
            # åˆ›å»ºè¾“å‡ºDataFrame
            output_df = pd.DataFrame()
            
            # æ·»åŠ åŸºç¡€å­—æ®µ
            clean_code = etf_code.replace('.SH', '').replace('.SZ', '')
            output_df['code'] = [clean_code] * len(df)
            
            # å¤„ç†æ—¥æœŸå­—æ®µ
            if 'date' in df.columns:
                output_df['date'] = pd.to_datetime(df['date']).dt.strftime(self.csv_config['date_format'])
            elif 'æ—¥æœŸ' in df.columns:
                output_df['date'] = pd.to_datetime(df['æ—¥æœŸ']).dt.strftime(self.csv_config['date_format'])
            else:
                print(f"âš ï¸ æœªæ‰¾åˆ°æ—¥æœŸå­—æ®µ: {etf_code}")
                return pd.DataFrame()
            
            # æ·»åŠ å¨å»‰æŒ‡æ ‡å­—æ®µ
            williams_fields = ['wr_9', 'wr_14', 'wr_21', 'wr_diff_9_21', 'wr_range', 'wr_change_rate']
            for field in williams_fields:
                if field in df.columns:
                    # ç¡®ä¿8ä½å°æ•°ç²¾åº¦
                    output_df[field] = df[field].round(self.decimal_precision)
                else:
                    # å¦‚æœå­—æ®µä¸å­˜åœ¨ï¼Œå¡«å……NaN
                    output_df[field] = np.nan
                    print(f"âš ï¸ ç¼ºå°‘å¨å»‰æŒ‡æ ‡å­—æ®µ: {field} - {etf_code}")
            
            # æ·»åŠ è®¡ç®—æ—¶é—´æˆ³
            if 'calc_time' in df.columns:
                output_df['calc_time'] = df['calc_time']
            else:
                output_df['calc_time'] = datetime.now().strftime(self.csv_config['time_format'])
            
            # æŒ‰æ—¥æœŸå€’åºæ’åˆ—ï¼ˆæœ€æ–°æ•°æ®åœ¨å‰ï¼‰
            output_df = output_df.sort_values('date', ascending=False).reset_index(drop=True)
            
            return output_df
            
        except Exception as e:
            print(f"âŒ æ•°æ®æ ¼å¼åŒ–å¤±è´¥: {etf_code} - {str(e)}")
            return pd.DataFrame()

    def _get_output_file_path(self, etf_code, threshold):
        """
        è·å–è¾“å‡ºæ–‡ä»¶è·¯å¾„
        
        Args:
            etf_code: ETFä»£ç 
            threshold: é—¨æ§›å€¼
            
        Returns:
            str: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        """
        clean_code = etf_code.replace('.SH', '').replace('.SZ', '')
        filename = f"{clean_code}.csv"
        return os.path.join(self.data_output_path, threshold, filename)

    def _save_to_csv_file(self, df, file_path, etf_code):
        """
        ä¿å­˜DataFrameåˆ°CSVæ–‡ä»¶
        
        Args:
            df: æ•°æ®DataFrame
            file_path: æ–‡ä»¶è·¯å¾„
            etf_code: ETFä»£ç ï¼ˆç”¨äºæ—¥å¿—ï¼‰
        """
        try:
            # åˆ›å»ºç›®å½•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
            os.makedirs(os.path.dirname(file_path), exist_ok=True)
            
            # ä¿å­˜åˆ°CSVæ–‡ä»¶ï¼Œä½¿ç”¨UTF-8ç¼–ç 
            df.to_csv(
                file_path, 
                index=False, 
                encoding=self.csv_config['encoding'],
                float_format=f'%.{self.decimal_precision}f'
            )
            
            print(f"ğŸ’¾ CSVæ–‡ä»¶å·²ä¿å­˜: {etf_code} -> {file_path}")
            
        except Exception as e:
            print(f"âŒ CSVæ–‡ä»¶ä¿å­˜å¤±è´¥: {etf_code} - {str(e)}")
            raise

    def load_existing_williams_data(self, etf_code, threshold):
        """
        åŠ è½½ç°æœ‰çš„å¨å»‰æŒ‡æ ‡æ•°æ®
        
        Args:
            etf_code: ETFä»£ç 
            threshold: é—¨æ§›å€¼
            
        Returns:
            DataFrame: ç°æœ‰æ•°æ®ï¼Œä¸å­˜åœ¨è¿”å›ç©ºDataFrame
        """
        try:
            file_path = self._get_output_file_path(etf_code, threshold)
            
            if not os.path.exists(file_path):
                return pd.DataFrame()
            
            # è¯»å–ç°æœ‰æ•°æ®
            existing_df = pd.read_csv(file_path, encoding=self.csv_config['encoding'])
            
            # éªŒè¯æ•°æ®å®Œæ•´æ€§
            if not self._validate_csv_data_integrity(existing_df, etf_code):
                print(f"âš ï¸ ç°æœ‰CSVæ•°æ®å®Œæ•´æ€§éªŒè¯å¤±è´¥: {etf_code}")
                return pd.DataFrame()
            
            return existing_df
            
        except Exception as e:
            print(f"âš ï¸ åŠ è½½ç°æœ‰å¨å»‰æŒ‡æ ‡æ•°æ®å¤±è´¥: {etf_code} - {str(e)}")
            return pd.DataFrame()

    def _validate_csv_data_integrity(self, df, etf_code):
        """
        éªŒè¯CSVæ•°æ®å®Œæ•´æ€§
        
        Args:
            df: æ•°æ®DataFrame
            etf_code: ETFä»£ç 
            
        Returns:
            bool: æ•°æ®å®Œæ•´æ€§æ˜¯å¦é€šè¿‡
        """
        try:
            if df.empty:
                return False
            
            # æ£€æŸ¥å¿…è¦å­—æ®µ
            required_fields = ['code', 'date', 'wr_9', 'wr_14', 'wr_21']
            for field in required_fields:
                if field not in df.columns:
                    print(f"âš ï¸ CSVç¼ºå°‘å¿…è¦å­—æ®µ: {field} - {etf_code}")
                    return False
            
            # æ£€æŸ¥æ•°æ®ç±»å‹
            try:
                pd.to_datetime(df['date'])
            except:
                print(f"âš ï¸ æ—¥æœŸæ ¼å¼é”™è¯¯: {etf_code}")
                return False
            
            # æ£€æŸ¥å¨å»‰æŒ‡æ ‡æ•°å€¼èŒƒå›´ï¼ˆ-100åˆ°0ä¹‹é—´ï¼‰
            williams_columns = ['wr_9', 'wr_14', 'wr_21']
            for col in williams_columns:
                if col in df.columns:
                    valid_values = df[col].dropna()
                    if not valid_values.empty:
                        if (valid_values < -100).any() or (valid_values > 0).any():
                            print(f"âš ï¸ å¨å»‰æŒ‡æ ‡æ•°å€¼è¶…å‡ºæ­£å¸¸èŒƒå›´: {col} - {etf_code}")
                            # ä¸è¿”å›Falseï¼Œåªæ˜¯è­¦å‘Š
            
            return True
            
        except Exception as e:
            print(f"âš ï¸ CSVæ•°æ®å®Œæ•´æ€§éªŒè¯å¼‚å¸¸: {etf_code} - {str(e)}")
            return False

    def merge_incremental_data(self, etf_code, threshold, new_df):
        """
        å¢é‡åˆå¹¶æ•°æ®
        
        å°†æ–°è®¡ç®—çš„æ•°æ®ä¸ç°æœ‰æ•°æ®åˆå¹¶ï¼Œé¿å…é‡å¤
        
        Args:
            etf_code: ETFä»£ç 
            threshold: é—¨æ§›å€¼
            new_df: æ–°è®¡ç®—çš„æ•°æ®
            
        Returns:
            DataFrame: åˆå¹¶åçš„å®Œæ•´æ•°æ®
        """
        try:
            # åŠ è½½ç°æœ‰æ•°æ®
            existing_df = self.load_existing_williams_data(etf_code, threshold)
            
            if existing_df.empty:
                # å¦‚æœæ²¡æœ‰ç°æœ‰æ•°æ®ï¼Œç›´æ¥è¿”å›æ–°æ•°æ®
                return new_df
            
            if new_df.empty:
                # å¦‚æœæ²¡æœ‰æ–°æ•°æ®ï¼Œè¿”å›ç°æœ‰æ•°æ®
                return existing_df
            
            # åˆå¹¶æ•°æ®
            combined_df = pd.concat([existing_df, new_df], ignore_index=True)
            
            # æŒ‰æ—¥æœŸå»é‡ï¼Œä¿ç•™æœ€æ–°çš„è®°å½•
            combined_df = combined_df.drop_duplicates(subset=['date'], keep='last')
            
            # æŒ‰æ—¥æœŸå€’åºæ’åˆ—
            combined_df = combined_df.sort_values('date', ascending=False).reset_index(drop=True)
            
            print(f"ğŸ”„ æ•°æ®åˆå¹¶å®Œæˆ: {etf_code} - ç°æœ‰{len(existing_df)}æ¡ï¼Œæ–°å¢{len(new_df)}æ¡ï¼Œåˆå¹¶å{len(combined_df)}æ¡")
            
            return combined_df
            
        except Exception as e:
            print(f"âŒ å¢é‡æ•°æ®åˆå¹¶å¤±è´¥: {etf_code} - {str(e)}")
            # åˆå¹¶å¤±è´¥æ—¶è¿”å›æ–°æ•°æ®
            return new_df

    def batch_save_williams_data(self, etf_data_dict, threshold):
        """
        æ‰¹é‡ä¿å­˜å¨å»‰æŒ‡æ ‡æ•°æ®
        
        Args:
            etf_data_dict: ETFæ•°æ®å­—å…¸ {etf_code: dataframe}
            threshold: é—¨æ§›å€¼
            
        Returns:
            dict: ä¿å­˜ç»“æœç»Ÿè®¡
        """
        try:
            results = {
                'success_count': 0,
                'fail_count': 0,
                'total_count': len(etf_data_dict),
                'failed_etfs': []
            }
            
            print(f"ğŸš€ å¼€å§‹æ‰¹é‡ä¿å­˜å¨å»‰æŒ‡æ ‡æ•°æ®: {threshold}")
            print(f"ğŸ“Š å¾…ä¿å­˜ETFæ•°é‡: {results['total_count']}")
            
            for etf_code, df in etf_data_dict.items():
                try:
                    if self.save_etf_williams_data(etf_code, df, threshold):
                        results['success_count'] += 1
                    else:
                        results['fail_count'] += 1
                        results['failed_etfs'].append(etf_code)
                        
                except Exception as e:
                    print(f"âŒ æ‰¹é‡ä¿å­˜ä¸­å‡ºç°å¼‚å¸¸: {etf_code} - {str(e)}")
                    results['fail_count'] += 1
                    results['failed_etfs'].append(etf_code)
            
            # æ‰“å°ä¿å­˜ç»“æœ
            success_rate = (results['success_count'] / results['total_count'] * 100) if results['total_count'] > 0 else 0
            print(f"âœ… æ‰¹é‡ä¿å­˜å®Œæˆ: {threshold}")
            print(f"ğŸ“ˆ æˆåŠŸç‡: {success_rate:.1f}% ({results['success_count']}/{results['total_count']})")
            
            if results['failed_etfs']:
                print(f"âŒ å¤±è´¥çš„ETF: {', '.join(results['failed_etfs'][:10])}")
                if len(results['failed_etfs']) > 10:
                    print(f"   ... ä»¥åŠå…¶ä»–{len(results['failed_etfs']) - 10}ä¸ª")
            
            return results
            
        except Exception as e:
            print(f"âŒ æ‰¹é‡ä¿å­˜è¿‡ç¨‹å‘ç”Ÿå¼‚å¸¸: {str(e)}")
            return {'success_count': 0, 'fail_count': len(etf_data_dict), 'total_count': len(etf_data_dict)}

    def get_output_statistics(self, threshold):
        """
        è·å–è¾“å‡ºæ–‡ä»¶ç»Ÿè®¡ä¿¡æ¯
        
        Args:
            threshold: é—¨æ§›å€¼
            
        Returns:
            dict: ç»Ÿè®¡ä¿¡æ¯
        """
        try:
            output_dir = os.path.join(self.data_output_path, threshold)
            
            if not os.path.exists(output_dir):
                return {'file_count': 0, 'total_size_mb': 0}
            
            # ç»Ÿè®¡CSVæ–‡ä»¶
            csv_files = [f for f in os.listdir(output_dir) if f.endswith('.csv')]
            total_size = 0
            
            for filename in csv_files:
                file_path = os.path.join(output_dir, filename)
                total_size += os.path.getsize(file_path)
            
            return {
                'file_count': len(csv_files),
                'total_size_mb': round(total_size / (1024 * 1024), 2),
                'output_directory': output_dir
            }
            
        except Exception as e:
            print(f"âš ï¸ è·å–è¾“å‡ºç»Ÿè®¡å¤±è´¥: {threshold} - {str(e)}")
            return {'file_count': 0, 'total_size_mb': 0}

    def validate_output_format(self, etf_code, threshold):
        """
        éªŒè¯è¾“å‡ºæ–‡ä»¶æ ¼å¼
        
        Args:
            etf_code: ETFä»£ç 
            threshold: é—¨æ§›å€¼
            
        Returns:
            dict: éªŒè¯ç»“æœ
        """
        try:
            file_path = self._get_output_file_path(etf_code, threshold)
            
            if not os.path.exists(file_path):
                return {'is_valid': False, 'error': 'æ–‡ä»¶ä¸å­˜åœ¨'}
            
            # è¯»å–æ–‡ä»¶
            df = pd.read_csv(file_path, encoding=self.csv_config['encoding'])
            
            validation_result = {
                'is_valid': True,
                'file_path': file_path,
                'record_count': len(df),
                'columns': list(df.columns),
                'issues': []
            }
            
            # éªŒè¯å­—æ®µå®Œæ•´æ€§
            expected_fields = ['code', 'date', 'wr_9', 'wr_14', 'wr_21', 'wr_diff_9_21', 'wr_range', 'wr_change_rate', 'calc_time']
            for field in expected_fields:
                if field not in df.columns:
                    validation_result['issues'].append(f"ç¼ºå°‘å­—æ®µ: {field}")
            
            # éªŒè¯æ•°æ®ç²¾åº¦
            williams_fields = ['wr_9', 'wr_14', 'wr_21', 'wr_diff_9_21', 'wr_range', 'wr_change_rate']
            for field in williams_fields:
                if field in df.columns:
                    # æ£€æŸ¥å°æ•°ä½æ•°æ˜¯å¦ç¬¦åˆè¦æ±‚
                    sample_values = df[field].dropna().head(5)
                    for value in sample_values:
                        if pd.notna(value):
                            decimal_places = len(str(value).split('.')[-1]) if '.' in str(value) else 0
                            if decimal_places > self.decimal_precision:
                                validation_result['issues'].append(f"{field}å­—æ®µç²¾åº¦è¿‡é«˜: {decimal_places}ä½å°æ•°")
                                break
            
            if validation_result['issues']:
                validation_result['is_valid'] = False
            
            return validation_result
            
        except Exception as e:
            return {
                'is_valid': False,
                'error': f"éªŒè¯è¿‡ç¨‹å‘ç”Ÿå¼‚å¸¸: {str(e)}"
            }

    def print_output_summary(self):
        """æ‰“å°è¾“å‡ºå¤„ç†å™¨æ‘˜è¦"""
        print("=" * 60)
        print("ğŸ“¤ å¨å»‰æŒ‡æ ‡CSVè¾“å‡ºå¤„ç†å™¨æ‘˜è¦")
        print("=" * 60)
        print(f"ğŸ“ è¾“å‡ºè·¯å¾„: {self.data_output_path}")
        print(f"ğŸ“Š æ•°å€¼ç²¾åº¦: {self.decimal_precision}ä½å°æ•°")
        print(f"ğŸ”¤ ç¼–ç æ ¼å¼: {self.csv_config['encoding']}")
        print(f"ğŸ“… æ—¥æœŸæ ¼å¼: {self.csv_config['date_format']}")
        print(f"â° æ—¶é—´æ ¼å¼: {self.csv_config['time_format']}")
        
        # ç»Ÿè®¡å„é—¨æ§›çš„è¾“å‡ºæ–‡ä»¶
        for threshold in ["3000ä¸‡é—¨æ§›", "5000ä¸‡é—¨æ§›"]:
            stats = self.get_output_statistics(threshold)
            print(f"ğŸ“ˆ {threshold}: {stats['file_count']}ä¸ªæ–‡ä»¶, {stats['total_size_mb']}MB")
        
        print("=" * 60)


if __name__ == "__main__":
    # CSVå¤„ç†å™¨æµ‹è¯•
    print("ğŸ§ª å¨å»‰æŒ‡æ ‡CSVå¤„ç†å™¨æµ‹è¯•")
    
    # æ³¨æ„ï¼šè¿™é‡Œéœ€è¦å®é™…çš„é…ç½®å¯¹è±¡æ¥å®Œæ•´æµ‹è¯•
    # è¿™ä¸ªæµ‹è¯•ä¸»è¦ç”¨äºéªŒè¯ä»£ç è¯­æ³•å’ŒåŸºæœ¬é€»è¾‘
    print("âœ… CSVå¤„ç†å™¨æ¨¡å—åŠ è½½æˆåŠŸ")
    print("ğŸ“ éœ€è¦é…ç½®å¯¹è±¡æ¥è¿›è¡Œå®Œæ•´åŠŸèƒ½æµ‹è¯•")