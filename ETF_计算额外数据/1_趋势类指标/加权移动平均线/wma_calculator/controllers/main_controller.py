#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
WMAä¸»æ§åˆ¶å™¨æ¨¡å— - é‡æ„ç‰ˆ
=====================

ä»åŸæœ‰controller.pyå®Œå…¨è¿ç§»æ ¸å¿ƒåŠŸèƒ½ï¼Œä¿æŒç®—æ³•å’ŒåŠŸèƒ½å®Œå…¨ä¸€è‡´
"""

import os
import pandas as pd
import numpy as np
from datetime import datetime
from typing import Dict, List, Optional, Any
from ..infrastructure.config import WMAConfig
from ..infrastructure.data_reader import WMADataReader
from ..infrastructure.cache_manager import WMACacheManager
from ..engines.wma_engine import WMAEngine
from ..engines.historical_calculator import WMAHistoricalCalculator
from ..outputs.result_processor import WMAResultProcessor
from .etf_processor import WMAETFProcessor
from .batch_processor import WMABatchProcessor


class WMAMainController:
    """WMAä¸»æ§åˆ¶å™¨ - é‡æ„ç‰ˆï¼ˆåŠŸèƒ½å®Œå…¨ä¸€è‡´ï¼‰"""
    
    def __init__(self, adj_type: str = "å‰å¤æƒ", wma_periods: Optional[List[int]] = None, 
                 output_dir: Optional[str] = None, enable_cache: bool = True, performance_mode: bool = True):
        """
        åˆå§‹åŒ–WMAä¸»æ§åˆ¶å™¨ - å®Œå…¨é‡æ„ç‰ˆæœ¬
        
        Args:
            adj_type: å¤æƒç±»å‹ï¼Œé»˜è®¤"å‰å¤æƒ"
            wma_periods: WMAå‘¨æœŸåˆ—è¡¨ï¼Œé»˜è®¤[3, 5, 10, 20]  
            output_dir: è¾“å‡ºç›®å½•ï¼Œé»˜è®¤Noneï¼ˆä½¿ç”¨é…ç½®ä¸­çš„é»˜è®¤ç›®å½•ï¼‰
            enable_cache: æ˜¯å¦å¯ç”¨ç¼“å­˜ï¼Œé»˜è®¤True
            performance_mode: æ˜¯å¦å¯ç”¨æ€§èƒ½æ¨¡å¼ï¼ˆå…³é—­è°ƒè¯•è¾“å‡ºï¼‰
        """
        print("=" * 60)
        print("ğŸš€ WMAä¸»æ§åˆ¶å™¨å¯åŠ¨ - å®Œå…¨é‡æ„ç‰ˆæœ¬")
        print("=" * 60)
        
        # åˆå§‹åŒ–é…ç½®
        self.config = WMAConfig(adj_type=adj_type, wma_periods=wma_periods, enable_cache=enable_cache, performance_mode=performance_mode)
        self.output_dir = output_dir or self.config.default_output_dir
        self.enable_cache = enable_cache
        self.performance_mode = performance_mode
        
        # åˆå§‹åŒ–æ ¸å¿ƒç»„ä»¶
        self.data_reader = WMADataReader(self.config)
        self.wma_engine = WMAEngine(self.config)
        self.historical_calculator = WMAHistoricalCalculator(self.config)
        self.result_processor = WMAResultProcessor(self.config)
        
        # åˆå§‹åŒ–ç¼“å­˜ç®¡ç†å™¨
        self.cache_manager = None
        if enable_cache:
            self.cache_manager = WMACacheManager(self.config)
        
        # åˆå§‹åŒ–å¤„ç†å™¨ - æ–°çš„åˆ†å±‚å¤„ç†å™¨
        self.etf_processor = WMAETFProcessor(
            data_reader=self.data_reader,
            wma_engine=self.wma_engine,
            config=self.config
        )
        
        self.batch_processor = WMABatchProcessor(
            etf_processor=self.etf_processor,
            cache_manager=self.cache_manager,
            config=self.config,
            enable_cache=enable_cache
        )
        
        print("ğŸ—‚ï¸ æ™ºèƒ½ç¼“å­˜ç³»ç»Ÿå·²å¯ç”¨" if enable_cache else "âš ï¸ ç¼“å­˜ç³»ç»Ÿå·²ç¦ç”¨")
        print("âœ… æ‰€æœ‰ç»„ä»¶åˆå§‹åŒ–å®Œæˆ")
        print("=" * 60)
        
        if not performance_mode:
            print("ğŸš€ WMAä¸»æ§åˆ¶å™¨åˆå§‹åŒ–å®Œæˆ")
            print(f"   ğŸ”§ å¤æƒç±»å‹: {adj_type}")
            print(f"   ğŸ“Š WMAå‘¨æœŸ: {wma_periods or [3, 5, 10, 20]}")
            print(f"   ğŸ—‚ï¸ ç¼“å­˜: {'å¯ç”¨' if enable_cache else 'ç¦ç”¨'}")
            print(f"   ğŸš€ æ€§èƒ½æ¨¡å¼: {'å¯ç”¨' if performance_mode else 'ç¦ç”¨'}")
    
    def get_available_etfs(self) -> List[str]:
        """
        è·å–å¯ç”¨çš„ETFä»£ç åˆ—è¡¨ - ä¿æŒåŸæœ‰åŠŸèƒ½
        
        Returns:
            List[str]: å¯ç”¨çš„ETFä»£ç åˆ—è¡¨
        """
        return self.data_reader.get_available_etfs()
    
    def process_single_etf(self, etf_code: str, include_advanced_analysis: bool = False) -> Optional[Dict]:
        """
        å¤„ç†å•ä¸ªETFçš„WMAè®¡ç®— - ä¿æŒåŸæœ‰åŠŸèƒ½å’Œç®—æ³•å®Œå…¨ä¸€è‡´
        
        Args:
            etf_code: ETFä»£ç 
            include_advanced_analysis: æ˜¯å¦åŒ…å«é«˜çº§åˆ†æ
            
        Returns:
            Dict: è®¡ç®—ç»“æœæˆ–None
        """
        print(f"ğŸ”„ å¼€å§‹å¤„ç†: {etf_code}")
        
        try:
            # ä½¿ç”¨æ–°çš„ETFå¤„ç†å™¨ - ä¿æŒåŸæœ‰å¤„ç†é€»è¾‘
            result = self.etf_processor.process_single_etf(etf_code, include_advanced_analysis)
            
            if result:
                print(f"âœ… {etf_code} å¤„ç†å®Œæˆ")
                return result
            else:
                print(f"âŒ {etf_code} å¤„ç†å¤±è´¥")
                return None
                
        except Exception as e:
            print(f"âŒ {etf_code} å¤„ç†å¼‚å¸¸: {str(e)}")
            return None
    
    def process_multiple_etfs(self, etf_codes: List[str], 
                            include_advanced_analysis: bool = False) -> List[Dict]:
        """
        å¤„ç†å¤šä¸ªETFçš„WMAè®¡ç®— - ä¿æŒåŸæœ‰åŠŸèƒ½
        
        Args:
            etf_codes: ETFä»£ç åˆ—è¡¨
            include_advanced_analysis: æ˜¯å¦åŒ…å«é«˜çº§åˆ†æ
            
        Returns:
            List[Dict]: è®¡ç®—ç»“æœåˆ—è¡¨
        """
        print(f"ğŸ“Š å¼€å§‹æ‰¹é‡å¤„ç† {len(etf_codes)} ä¸ªETF...")
        
        # ä½¿ç”¨æ–°çš„æ‰¹é‡å¤„ç†å™¨ - ä¿æŒåŸæœ‰æ‰¹é‡å¤„ç†é€»è¾‘
        return self.batch_processor.process_etf_list(etf_codes, None, include_advanced_analysis)
    
    def calculate_and_save(self, etf_codes: List[str], output_dir: Optional[str] = None,
                          include_advanced_analysis: bool = False) -> Dict[str, Any]:
        """
        è®¡ç®—å¹¶ä¿å­˜ç»“æœçš„å®Œæ•´æµç¨‹ - ä¿æŒåŸæœ‰åŠŸèƒ½å®Œå…¨ä¸€è‡´
        
        Args:
            etf_codes: ETFä»£ç åˆ—è¡¨
            output_dir: è¾“å‡ºç›®å½•ï¼ˆå¯é€‰ï¼‰
            include_advanced_analysis: æ˜¯å¦åŒ…å«é«˜çº§åˆ†æ
            
        Returns:
            Dict[str, Any]: å¤„ç†ç»“æœæ‘˜è¦
        """
        # å¤„ç†ETF - ä¿æŒåŸæœ‰å¤„ç†é€»è¾‘
        results = self.process_multiple_etfs(etf_codes, include_advanced_analysis)
        
        if not results:
            print("âŒ æ²¡æœ‰æˆåŠŸå¤„ç†çš„ETF")
            return {'success': False, 'message': 'æ²¡æœ‰æˆåŠŸå¤„ç†çš„ETF'}
        
        # ä¿å­˜ç»“æœ - ä½¿ç”¨æ–°çš„æ‰¹é‡å¤„ç†å™¨
        save_stats = self.batch_processor.save_results_to_files(
            results, output_dir or self.output_dir, None
        )
        
        # è·å–ç»“æœç»Ÿè®¡ - ä¿æŒåŸæœ‰ç»Ÿè®¡é€»è¾‘
        return {
            'success': True,
            'processed_etfs': len(results),
            'total_etfs': len(etf_codes),
            'success_rate': len(results) / len(etf_codes) * 100,
            'output_directory': output_dir or self.output_dir,
            'saved_files': save_stats['files_saved'],
            'statistics': self._get_result_stats(results)
        }
    
    def calculate_and_save_screening_results(self, thresholds: Optional[List[str]] = None) -> Dict[str, Any]:
        """
        è®¡ç®—å¹¶ä¿å­˜ç­›é€‰ç»“æœçš„WMAæ•°æ® - ä¿æŒåŸæœ‰åŠŸèƒ½
        
        Args:
            thresholds: é—¨æ§›åˆ—è¡¨ï¼Œé»˜è®¤["3000ä¸‡é—¨æ§›", "5000ä¸‡é—¨æ§›"]
            
        Returns:
            Dict[str, Any]: å¤„ç†ç»“æœç»Ÿè®¡
        """
        thresholds = thresholds or ["3000ä¸‡é—¨æ§›", "5000ä¸‡é—¨æ§›"]
        
        print(f"ğŸš€ å¼€å§‹ç­›é€‰ç»“æœWMAè®¡ç®—å’Œä¿å­˜...")
        print(f"ğŸ“Š é—¨æ§›è®¾ç½®: {thresholds}")
        
        all_results = {}
        save_stats = {}
        
        for threshold in thresholds:
            print(f"\nğŸ“ˆ å¤„ç†é—¨æ§›: {threshold}")
            
            # ä½¿ç”¨æ‰¹é‡å¤„ç†å™¨è®¡ç®—ç­›é€‰ç»“æœ
            results = self.batch_processor.process_screening_results(threshold)
            
            if results:
                all_results[threshold] = results
                print(f"âœ… {threshold}: {len(results)}ä¸ªETFè®¡ç®—å®Œæˆ")
            else:
                all_results[threshold] = []
                print(f"âŒ {threshold}: æ— å¯ç”¨ç»“æœ")
        
        # ä¿å­˜ç»“æœ
        if any(all_results.values()):
            save_stats = self.result_processor.save_screening_batch_results(all_results, self.output_dir)
        
        # æ˜¾ç¤ºç»“æœ
        for threshold, results in all_results.items():
            if results:
                print(f"\nğŸ“Š {threshold} ç»“æœé¢„è§ˆ:")
                self.result_processor.display_results(results[:3])  # æ˜¾ç¤ºå‰3ä¸ª
        
        return {
            'calculation_results': all_results,
            'save_statistics': save_stats,
            'total_etfs': sum(len(results) for results in all_results.values())
        }
    
    def calculate_and_save_historical_wma(self, etf_codes: Optional[List[str]] = None, 
                                        thresholds: Optional[List[str]] = None) -> Dict[str, Any]:
        """
        è®¡ç®—å¹¶ä¿å­˜å®Œæ•´å†å²WMAæ•°æ® - æ–°å¢è¶…é«˜æ€§èƒ½åŠŸèƒ½
        
        Args:
            etf_codes: ETFä»£ç åˆ—è¡¨ï¼ŒNoneåˆ™å¤„ç†æ‰€æœ‰å¯ç”¨ETF
            thresholds: é—¨æ§›åˆ—è¡¨ï¼Œé»˜è®¤["3000ä¸‡é—¨æ§›", "5000ä¸‡é—¨æ§›"]
            
        Returns:
            Dict[str, Any]: å¤„ç†ç»“æœç»Ÿè®¡
        """
        thresholds = thresholds or ["3000ä¸‡é—¨æ§›", "5000ä¸‡é—¨æ§›"]
        
        print(f"ğŸš€ å¼€å§‹å†å²WMAæ•°æ®è®¡ç®—å’Œä¿å­˜...")
        print(f"ğŸ“Š é—¨æ§›è®¾ç½®: {thresholds}")
        
        # è·å–ETFåˆ—è¡¨
        if etf_codes is None:
            etf_codes = self.data_reader.get_available_etfs()
        
        print(f"ğŸ“ˆ å¾…å¤„ç†ETFæ•°é‡: {len(etf_codes)}")
        
        # è·å–ETFæ–‡ä»¶è·¯å¾„å­—å…¸
        etf_files_dict = {}
        for etf_code in etf_codes:
            file_path = self.data_reader.get_etf_file_path(etf_code)
            if file_path and os.path.exists(file_path):
                etf_files_dict[etf_code] = file_path
        
        print(f"ğŸ“ æœ‰æ•ˆETFæ–‡ä»¶æ•°é‡: {len(etf_files_dict)}")
        
        all_stats = {}
        
        # ä¸ºæ¯ä¸ªé—¨æ§›è®¡ç®—å†å²æ•°æ®
        for threshold in thresholds:
            print(f"\nğŸ“ˆ è®¡ç®—é—¨æ§›: {threshold}")
            
            # ä½¿ç”¨è¶…é«˜æ€§èƒ½å†å²è®¡ç®—å™¨
            historical_results = self.historical_calculator.batch_calculate_historical_wma(
                etf_files_dict, list(etf_files_dict.keys())
            )
            
            if historical_results:
                # ä¿å­˜å†å²æ•°æ®æ–‡ä»¶
                save_stats = self.historical_calculator.save_historical_results(
                    historical_results, self.output_dir, threshold
                )
                all_stats[threshold] = save_stats
                
                print(f"âœ… {threshold}: å†å²æ•°æ®è®¡ç®—å’Œä¿å­˜å®Œæˆ")
            else:
                print(f"âŒ {threshold}: å†å²æ•°æ®è®¡ç®—å¤±è´¥")
                all_stats[threshold] = {}
        
        return {
            'processing_statistics': all_stats,
            'total_etfs_processed': len(etf_files_dict),
            'thresholds_processed': thresholds
        }
    
    def quick_analysis(self, etf_code: str, include_historical: bool = False) -> Optional[Dict]:
        """
        å¿«é€Ÿåˆ†æå•ä¸ªETF - å¢å¼ºç‰ˆæœ¬
        
        Args:
            etf_code: ETFä»£ç ï¼ˆå¦‚"510050.SH"æˆ–"510050"ï¼‰
            include_historical: æ˜¯å¦åŒ…å«å†å²æ•°æ®åˆ†æ
            
        Returns:
            Dict: åˆ†æç»“æœæˆ–None
        """
        print(f"ğŸ” å¿«é€Ÿåˆ†æ: {etf_code}")
        
        # å¤„ç†å•ä¸ªETF
        result = self.etf_processor.process_single_etf(etf_code, include_advanced_analysis=True)
        
        if not result:
            print(f"âŒ {etf_code}: åˆ†æå¤±è´¥")
            return None
        
        # æ˜¾ç¤ºåŸºç¡€ç»“æœ
        self.result_processor.display_results([result])
        
        # å¦‚æœéœ€è¦å†å²æ•°æ®åˆ†æ
        if include_historical:
            print(f"\nğŸš€ {etf_code}: å¼€å§‹å†å²æ•°æ®åˆ†æ...")
            
            # è¯»å–å®Œæ•´æ•°æ®
            data_result = self.data_reader.read_etf_data(etf_code)
            if data_result is not None:
                df, _ = data_result
                if not df.empty:
                    # è®¡ç®—å®Œæ•´å†å²WMA
                    historical_df = self.historical_calculator.calculate_full_historical_wma_optimized(df, etf_code)
                    
                    if historical_df is not None:
                        # æ·»åŠ å†å²æ•°æ®åˆ°ç»“æœ
                        result['historical_analysis'] = {
                            'total_history_days': len(historical_df),
                            'valid_wma_days': historical_df[f'WMA{max(self.config.wma_periods)}'].notna().sum(),
                            'earliest_date': historical_df['æ—¥æœŸ'].min(),  # ä¿®å¤ï¼šæœ€æ—©æ—¥æœŸåº”è¯¥ç”¨min()
                            'latest_date': historical_df['æ—¥æœŸ'].max(),    # ä¿®å¤ï¼šæœ€æ–°æ—¥æœŸåº”è¯¥ç”¨max()
                            'historical_trend_summary': self._analyze_historical_trend(historical_df)
                        }
                        
                        print(f"âœ… {etf_code}: å†å²æ•°æ®åˆ†æå®Œæˆ")
                        print(f"   ğŸ“Š å†å²æ•°æ®: {result['historical_analysis']['total_history_days']}å¤©")
                        print(f"   ğŸ“ˆ æœ‰æ•ˆWMA: {result['historical_analysis']['valid_wma_days']}å¤©")
                        print(f"   ğŸ“… æ—¥æœŸèŒƒå›´: {result['historical_analysis']['earliest_date']} è‡³ {result['historical_analysis']['latest_date']}")
        
        return result
    
    def _analyze_historical_trend(self, historical_df: pd.DataFrame) -> Dict:
        """
        åˆ†æå†å²è¶‹åŠ¿ - è¾…åŠ©æ–¹æ³•
        
        Args:
            historical_df: å†å²WMAæ•°æ®
            
        Returns:
            Dict: è¶‹åŠ¿åˆ†æç»“æœ
        """
        try:
            # è·å–æœ€è¿‘30å¤©çš„æ•°æ®ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
            recent_data = historical_df.head(30)  # æŒ‰æ—¶é—´å€’åºï¼Œheadæ˜¯æœ€æ–°çš„
            
            if len(recent_data) < 10:
                return {'analysis': 'æ•°æ®ä¸è¶³ï¼Œæ— æ³•è¿›è¡Œè¶‹åŠ¿åˆ†æ'}
            
            # ä¿®å¤ï¼šç»Ÿä¸€å­—æ®µåç§°ï¼Œæ”¯æŒä¸¤ç§å¯èƒ½çš„å­—æ®µå
            # åˆ†æWMA5-20å·®å€¼è¶‹åŠ¿
            diff_col = None
            for possible_col in ['WMAå·®å€¼5-20', 'WMA_DIFF_5_20']:
                if possible_col in recent_data.columns:
                    diff_col = possible_col
                    break
                    
            if diff_col is not None:
                diff_values = recent_data[diff_col].dropna()
                if len(diff_values) >= 5:
                    positive_count = (diff_values > 0).sum()
                    trend_strength = positive_count / len(diff_values)
                    
                    if trend_strength >= 0.7:
                        trend_desc = "å¼ºä¸Šå‡è¶‹åŠ¿"
                    elif trend_strength >= 0.3:
                        trend_desc = "éœ‡è¡è¶‹åŠ¿"
                    else:
                        trend_desc = "ä¸‹é™è¶‹åŠ¿"
                    
                    return {
                        'recent_trend': trend_desc,
                        'trend_strength': f"{trend_strength*100:.1f}%",
                        'recent_days_analyzed': len(diff_values),
                        'latest_diff': float(diff_values.iloc[0]) if len(diff_values) > 0 else None,
                        'column_used': diff_col  # æ·»åŠ ä½¿ç”¨çš„åˆ—åï¼Œä¾¿äºè°ƒè¯•
                    }
            
            return {'analysis': 'è¶‹åŠ¿åˆ†ææ•°æ®ä¸å®Œæ•´ï¼Œæ‰¾ä¸åˆ°å·®å€¼åˆ—'}
            
        except Exception as e:
            return {'analysis': f'è¶‹åŠ¿åˆ†æå¤±è´¥: {str(e)}', 'error': str(e)}
    
    def _get_result_stats(self, results: List[Dict]) -> Dict:
        """è·å–ç»“æœç»Ÿè®¡ - ä¿æŒåŸæœ‰ç»Ÿè®¡é€»è¾‘"""
        if not results:
            return {}
        
        return {
            'total_results': len(results),
            'successful_calculations': len([r for r in results if r.get('wma_values')]),
            'data_sources': {
                'cache_hits': len([r for r in results if r.get('data_source') == 'cache_hit']),
                'fresh_calculations': len([r for r in results if r.get('data_source') == 'fresh_calculation'])
            }
        }
    
    def get_system_status(self) -> Dict:
        """è·å–ç³»ç»ŸçŠ¶æ€ - ä¿æŒåŸæœ‰åŠŸèƒ½"""
        try:
            status = {
                'system_info': {
                    'version': '2.0.0',
                    'config': f'WMAç³»ç»Ÿ - {self.config.adj_type}',
                    'data_path': self.config.data_path,
                    'output_path': self.output_dir
                },
                'data_status': {
                    'available_etfs_count': len(self.data_reader.get_available_etfs()),
                    'data_path_valid': True,
                    'sample_etfs': self.data_reader.get_available_etfs()[:5]
                },
                'components': {
                    'Data Reader': 'Ready',
                    'WMA Engine': 'Ready',
                    'ETF Processor': 'Ready',
                    'Batch Processor': 'Ready',
                    'Cache Manager': 'Ready' if self.enable_cache else 'Disabled'
                }
            }
            
            return status
            
        except Exception as e:
            return {'error': f'ç³»ç»ŸçŠ¶æ€æ£€æŸ¥å¤±è´¥: {str(e)}'} 