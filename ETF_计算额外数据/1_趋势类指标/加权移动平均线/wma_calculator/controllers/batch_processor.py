#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
WMAæ‰¹é‡å¤„ç†å™¨æ¨¡å— - é‡æ„ç‰ˆ
=========================

å‚è€ƒSMAé¡¹ç›®çš„æ‰¹é‡å¤„ç†æ¶æ„ï¼Œæ”¯æŒæ™ºèƒ½ç¼“å­˜å’Œé«˜æ€§èƒ½æ‰¹é‡å¤„ç†
"""

import os
import pandas as pd
from datetime import datetime
from typing import Dict, List, Optional, Any
from ..infrastructure.config import WMAConfig
from ..infrastructure.cache_manager import WMACacheManager
from .etf_processor import WMAETFProcessor


class WMABatchProcessor:
    """WMAæ‰¹é‡å¤„ç†å™¨ - æ”¯æŒæ™ºèƒ½ç¼“å­˜çš„é«˜æ€§èƒ½æ‰¹é‡å¤„ç†"""
    
    def __init__(self, etf_processor: WMAETFProcessor, cache_manager: Optional[WMACacheManager],
                 config: WMAConfig, enable_cache: bool = True):
        """
        åˆå§‹åŒ–æ‰¹é‡å¤„ç†å™¨
        
        Args:
            etf_processor: ETFå¤„ç†å™¨
            cache_manager: ç¼“å­˜ç®¡ç†å™¨
            config: WMAé…ç½®
            enable_cache: æ˜¯å¦å¯ç”¨ç¼“å­˜
        """
        self.etf_processor = etf_processor
        self.cache_manager = cache_manager
        self.config = config
        self.enable_cache = enable_cache
    
    def process_etf_list(self, etf_codes: List[str], threshold: Optional[str] = None,
                        include_advanced_analysis: bool = False) -> List[Dict]:
        """
        æ‰¹é‡å¤„ç†ETFåˆ—è¡¨ - æ”¯æŒæ™ºèƒ½ç¼“å­˜
        
        Args:
            etf_codes: ETFä»£ç åˆ—è¡¨
            threshold: é—¨æ§›ç±»å‹ï¼ˆç”¨äºç¼“å­˜ï¼‰
            include_advanced_analysis: æ˜¯å¦åŒ…å«é«˜çº§åˆ†æ
            
        Returns:
            List[Dict]: å¤„ç†ç»“æœåˆ—è¡¨
        """
        results = []
        success_count = 0
        cache_hit_count = 0
        new_calculation_count = 0
        
        print(f"ğŸ“Š å¼€å§‹æ‰¹é‡å¤„ç† {len(etf_codes)} ä¸ªETF...")
        
        for i, etf_code in enumerate(etf_codes, 1):
            print(f"\n{'='*60}")
            print(f"ğŸ”„ å¤„ç†è¿›åº¦: {i}/{len(etf_codes)} - {etf_code}")
            print(f"{'='*60}")
            
            # æ™ºèƒ½å¤„ç†ï¼šä¼˜å…ˆå¢é‡æ›´æ–°ï¼Œå›é€€åˆ°ç¼“å­˜æˆ–å…¨é‡è®¡ç®—
            result = None
            if self.enable_cache and self.cache_manager and threshold:
                # å°è¯•å¢é‡æ›´æ–°æˆ–ç¼“å­˜åŠ è½½
                result = self._process_cached_etf(etf_code, threshold)
                if result:
                    if result.get('data_source') == 'cache':
                        cache_hit_count += 1
                        if not (self.config and self.config.performance_mode):
                            print(f"ğŸ’¾ {etf_code}: ä½¿ç”¨ç¼“å­˜")
                    elif result.get('data_source') == 'incremental_update':
                        new_calculation_count += 1
                        if not (self.config and self.config.performance_mode):
                            print(f"âš¡ {etf_code}: å¢é‡æ›´æ–° ({result.get('incremental_rows', 0)}è¡Œ)")
                    else:
                        new_calculation_count += 1
            
            if not result:
                # å›é€€åˆ°å…¨é‡è®¡ç®—
                result = self.etf_processor.process_single_etf(etf_code, include_advanced_analysis)
                if result:
                    new_calculation_count += 1
                    if not (self.config and self.config.performance_mode):
                        print(f"ğŸ”„ {etf_code}: å…¨é‡è®¡ç®—")
                    
                    # ä¿å­˜åˆ°ç¼“å­˜ï¼ˆå¦‚æœå¯ç”¨ç¼“å­˜ä¸”æœ‰é—¨æ§›ï¼‰
                    if self.enable_cache and self.cache_manager and threshold:
                        self._try_save_to_cache(etf_code, result, threshold)
            
            if result:
                results.append(result)
                success_count += 1
            else:
                print(f"âŒ {etf_code} å¤„ç†å¤±è´¥ï¼Œè·³è¿‡...")
        
        # æ›´æ–°ç¼“å­˜ç»Ÿè®¡ï¼ˆå¦‚æœå¯ç”¨ç¼“å­˜ä¸”æœ‰é—¨æ§›ï¼‰
        if self.enable_cache and self.cache_manager and threshold:
            self._update_cache_statistics(threshold, {
                'cache_hits': cache_hit_count,
                'new_calculations': new_calculation_count,
                'total_processed': len(etf_codes),
                'cache_hit_rate': (cache_hit_count / len(etf_codes)) * 100 if etf_codes else 0
            })
        
        print(f"\nâœ… æ‰¹é‡å¤„ç†å®Œæˆ! æˆåŠŸå¤„ç† {success_count}/{len(etf_codes)} ä¸ªETF")
        if self.enable_cache and threshold:
            print(f"ğŸ—‚ï¸ ç¼“å­˜å‘½ä¸­: {cache_hit_count}, æ–°è®¡ç®—: {new_calculation_count}")
        
        return results
    
    def _try_get_cached_result(self, etf_code: str, threshold: str) -> Optional[Dict]:
        """
        å°è¯•ä»ç¼“å­˜è·å–ç»“æœ
        
        Args:
            etf_code: ETFä»£ç 
            threshold: é—¨æ§›ç±»å‹
            
        Returns:
            Optional[Dict]: ç¼“å­˜ç»“æœæˆ–None
        """
        try:
            # æ£€æŸ¥ç¼“å­˜æ˜¯å¦æœ‰æ•ˆ
            source_file_path = self.config.get_file_path(etf_code)
            if not self.cache_manager.is_cache_valid(etf_code, threshold, source_file_path):
                return None
            
            # è·å–ç¼“å­˜ç»“æœ
            cached_df = self.cache_manager.load_cached_etf_data(etf_code, threshold)
            if cached_df is None or cached_df.empty:
                return None
            
            # ç¡®ä¿ç¼“å­˜æ•°æ®æŒ‰æ—¶é—´å€’åºæ’åˆ—ï¼Œç¬¬ä¸€è¡Œæ˜¯æœ€æ–°æ•°æ®
            cached_df = cached_df.sort_values('date', ascending=False)
            latest_row = cached_df.iloc[0]  # ç¬¬ä¸€è¡Œæ˜¯æœ€æ–°æ•°æ®ï¼ˆæŒ‰æ—¶é—´å€’åºï¼‰
            
            # æå–WMAå€¼
            wma_values = {}
            for col in cached_df.columns:
                if col.startswith('WMA'):
                    value = latest_row[col]
                    if pd.notna(value):
                        wma_values[col] = round(float(value), 8)
                    else:
                        wma_values[col] = None
            
            # æ„å»ºç»“æœ
            result = {
                'etf_code': etf_code,
                'wma_values': wma_values,
                'latest_price': {
                    'date': str(latest_row.get('date', '')),
                    'close': round(float(latest_row.get('æ”¶ç›˜ä»·', 0)), 8),
                    'change_pct': round(float(latest_row.get('æ¶¨å¹…%', 0)), 8) if 'æ¶¨å¹…%' in latest_row else 0.0
                },
                'date_range': {
                    'start_date': str(cached_df.iloc[-1].get('date', '')),
                    'end_date': str(cached_df.iloc[0].get('date', '')),
                    'total_days': len(cached_df)
                },
                'data_source': 'cache_hit',
                'cache_timestamp': datetime.fromtimestamp(
                    os.path.getmtime(self.cache_manager.get_cache_file_path(etf_code, threshold))
                ).isoformat()
            }
            
            return result
            
        except Exception as e:
            print(f"âš ï¸ ç¼“å­˜è¯»å–å¤±è´¥: {etf_code} - {str(e)}")
            return None
    
    def _try_save_to_cache(self, etf_code: str, result: Dict, threshold: str) -> bool:
        """
        å°è¯•ä¿å­˜ç»“æœåˆ°ç¼“å­˜ - ç»Ÿä¸€ç¼“å­˜æ ¼å¼
        
        Args:
            etf_code: ETFä»£ç 
            result: è®¡ç®—ç»“æœ
            threshold: é—¨æ§›ç±»å‹
            
        Returns:
            bool: ä¿å­˜æ˜¯å¦æˆåŠŸ
        """
        try:
            # ç»Ÿä¸€ç¼“å­˜æ ¼å¼ï¼šç›´æ¥ä¿å­˜historical_dataï¼ˆä¸SMAé¡¹ç›®ä¸€è‡´ï¼‰
            if result and result.get('historical_data') is not None:
                historical_data = result['historical_data']
                return self.cache_manager.save_etf_cache(etf_code, historical_data, threshold)
            
            return False
            
        except Exception as e:
            print(f"âš ï¸ ç¼“å­˜ä¿å­˜å¤±è´¥: {etf_code} - {str(e)}")
            return False
    
    def _update_cache_statistics(self, threshold: str, stats: Dict) -> None:
        """
        æ›´æ–°ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯
        
        Args:
            threshold: é—¨æ§›ç±»å‹
            stats: ç»Ÿè®¡ä¿¡æ¯
        """
        try:
            if self.cache_manager:
                self.cache_manager.update_processing_stats(threshold, stats)
        except Exception as e:
            print(f"âš ï¸ æ›´æ–°ç¼“å­˜ç»Ÿè®¡å¤±è´¥: {str(e)}")
    
    def _add_wma_to_dataframe(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        å°†WMAæ•°æ®æ·»åŠ åˆ°DataFrame
        
        Args:
            df: åŸå§‹æ•°æ®DataFrame
            
        Returns:
            pd.DataFrame: åŒ…å«WMAæ•°æ®çš„DataFrame
        """
        df_with_wma = df.copy()
        
        # è®¡ç®—å„å‘¨æœŸWMAï¼Œç»Ÿä¸€ä½¿ç”¨ä¸‹åˆ’çº¿æ ¼å¼
        for period in self.config.wma_periods:
            wma_series = self.etf_processor.wma_engine.calculate_single_wma(df['æ”¶ç›˜ä»·'], period)
            df_with_wma[f'WMA_{period}'] = wma_series
        
        # è®¡ç®—WMAå·®å€¼
        if 'WMA_5' in df_with_wma.columns and 'WMA_20' in df_with_wma.columns:
            diff_5_20 = df_with_wma['WMA_5'] - df_with_wma['WMA_20']
            df_with_wma['WMA_DIFF_5_20'] = diff_5_20
        
        if 'WMA_3' in df_with_wma.columns and 'WMA_5' in df_with_wma.columns:
            diff_3_5 = df_with_wma['WMA_3'] - df_with_wma['WMA_5']
            df_with_wma['WMA_DIFF_3_5'] = diff_3_5
        
        # è®¡ç®—ç›¸å¯¹å·®å€¼ç™¾åˆ†æ¯”
        if 'WMA_DIFF_5_20' in df_with_wma.columns and 'WMA_20' in df_with_wma.columns:
            diff_series = df_with_wma['WMA_DIFF_5_20']
            wma20_series = df_with_wma['WMA_20']
            # é¿å…é™¤ä»¥é›¶é”™è¯¯
            valid_mask = wma20_series != 0
            pct_series = pd.Series([0.0] * len(df_with_wma), index=df_with_wma.index)
            pct_series[valid_mask] = (diff_series[valid_mask] / wma20_series[valid_mask] * 100).round(8)
            df_with_wma['WMA_DIFF_5_20_PCT'] = pct_series
        
        return df_with_wma
    
    def save_results_to_files(self, results: List[Dict], output_dir: str, 
                            threshold: Optional[str] = None) -> Dict:
        """
        ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
        
        Args:
            results: å¤„ç†ç»“æœåˆ—è¡¨
            output_dir: è¾“å‡ºç›®å½•
            threshold: é—¨æ§›ç±»å‹
            
        Returns:
            Dict: ä¿å­˜ç»Ÿè®¡ä¿¡æ¯
        """
        if not results:
            return {'files_saved': 0, 'total_size': 0, 'failed_saves': 0}
        
        # ç¡®å®šè¾“å‡ºç›®å½•
        if threshold:
            final_output_dir = os.path.join(output_dir, threshold)
        else:
            final_output_dir = output_dir
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        try:
            os.makedirs(final_output_dir, exist_ok=True)
        except Exception as e:
            print(f"âŒ åˆ›å»ºç›®å½•å¤±è´¥ {final_output_dir}: {str(e)}")
            print("ğŸ’¡ å°è¯•ä½¿ç”¨å½“å‰ç›®å½•...")
            final_output_dir = "."
        
        files_saved = 0
        total_size = 0
        failed_saves = 0
        
        print(f"ğŸ’¾ å¼€å§‹ä¿å­˜ {len(results)} ä¸ªETFçš„å†å²æ•°æ®æ–‡ä»¶...")
        
        for result in results:
            try:
                etf_code = result['etf_code']
                
                # é‡æ–°è¯»å–å®Œæ•´æ•°æ®
                data_result = self.etf_processor.data_reader.read_etf_data(etf_code)
                if data_result is None:
                    failed_saves += 1
                    continue
                
                df, _ = data_result
                
                # è®¡ç®—å¹¶æ·»åŠ WMAæ•°æ®
                df_with_wma = self._add_wma_to_dataframe(df)
                
                # ä¿å­˜æ–‡ä»¶
                clean_etf_code = etf_code.replace('.SH', '').replace('.SZ', '')
                output_file = os.path.join(final_output_dir, f"{clean_etf_code}.csv")
                
                # ç¡®ä¿è¾“å‡ºæ–‡ä»¶çš„çˆ¶ç›®å½•å­˜åœ¨
                try:
                    os.makedirs(os.path.dirname(output_file), exist_ok=True)
                except Exception as dir_e:
                    print(f"âš ï¸ {etf_code}: åˆ›å»ºç›®å½•å¤±è´¥ - {str(dir_e)}")
                
                # æŒ‰æ—¶é—´å€’åºä¿å­˜ï¼ˆä¸åŸæœ‰é€»è¾‘ä¸€è‡´ï¼‰
                df_sorted = df_with_wma.sort_values('date', ascending=False)
                df_sorted.to_csv(output_file, index=False, encoding='utf-8')
                
                file_size = os.path.getsize(output_file)
                total_size += file_size
                files_saved += 1
                
                print(f"ğŸ’¾ {etf_code}: å·²ä¿å­˜ ({len(df_sorted)}è¡Œ, {file_size}å­—èŠ‚)")
                
            except Exception as e:
                print(f"âŒ {result.get('etf_code', 'Unknown')}: ä¿å­˜å¤±è´¥ - {str(e)}")
                failed_saves += 1
        
        print(f"âœ… æ–‡ä»¶ä¿å­˜å®Œæˆ: {files_saved}æˆåŠŸ, {failed_saves}å¤±è´¥, æ€»å¤§å°{total_size/1024/1024:.1f}MB")
        
        return {
            'files_saved': files_saved,
            'total_size': total_size,
            'failed_saves': failed_saves
        }
    
    def process_screening_results(self, threshold: str) -> List[Dict]:
        """
        å¤„ç†ç­›é€‰ç»“æœçš„ETFåˆ—è¡¨
        
        Args:
            threshold: é—¨æ§›ç±»å‹ (å¦‚: "3000ä¸‡é—¨æ§›", "5000ä¸‡é—¨æ§›")
            
        Returns:
            List[Dict]: å¤„ç†ç»“æœåˆ—è¡¨
        """
        print(f"ğŸ“Š è¯»å–{threshold}ç­›é€‰ç»“æœ...")
        
        # ä½¿ç”¨æ•°æ®è¯»å–å™¨è·å–ç­›é€‰ç»“æœ
        etf_codes = self.etf_processor.data_reader.get_screening_etf_codes(threshold)
        
        if not etf_codes:
            print(f"âŒ {threshold}: æœªæ‰¾åˆ°ç­›é€‰ç»“æœ")
            return []
        
        print(f"ğŸ“Š {threshold}: æ‰¾åˆ° {len(etf_codes)} ä¸ªé€šè¿‡ç­›é€‰çš„ETF")
        
        # ä½¿ç”¨ç°æœ‰çš„process_etf_listæ–¹æ³•å¤„ç†
        results = self.process_etf_list(etf_codes, threshold, include_advanced_analysis=False)
        
        print(f"âœ… {threshold}: å¤„ç†å®Œæˆï¼ŒæˆåŠŸå¤„ç† {len(results)} ä¸ªETF")
        
        return results
    
    def _process_incremental_etf(self, etf_code: str, threshold: str) -> Optional[Dict]:
        """å¢é‡æ›´æ–°ETF - åªè®¡ç®—æ–°å¢æ•°æ®"""
        try:
            # 1. è·å–ç¼“å­˜çš„æœ€æ–°æ—¥æœŸ
            cached_latest_date = self.cache_manager.get_cached_etf_latest_date(etf_code, threshold)
            if not cached_latest_date:
                # æ²¡æœ‰ç¼“å­˜ï¼Œè¿›è¡Œå…¨é‡è®¡ç®—
                return self._process_new_etf(etf_code, threshold, False)
            
            # 2. è¯»å–åŸå§‹ETFæ•°æ®
            source_file_path = self.config.get_file_path(etf_code)
            etf_df = pd.read_csv(source_file_path, encoding='utf-8')
            
            if etf_df.empty:
                return None
            
            # ç¡®ä¿æ—¥æœŸæ ¼å¼ç»Ÿä¸€ä¸ºYYYY-MM-DD
            etf_df['date'] = pd.to_datetime(etf_df['date']).dt.strftime('%Y-%m-%d')
            etf_df = etf_df.sort_values('date', ascending=False).reset_index(drop=True)
            
            # 3. æ£€æŸ¥æ˜¯å¦æœ‰æ–°æ•°æ®
            latest_source_date = etf_df.iloc[0]['date']
            if str(latest_source_date) <= str(cached_latest_date):
                # æ²¡æœ‰æ–°æ•°æ®ï¼Œç›´æ¥è¿”å›ç¼“å­˜ç»“æœ
                if not (self.config and self.config.performance_mode):
                    print(f"   ğŸ’¾ {etf_code}: ä½¿ç”¨ç¼“å­˜ (å·²æ˜¯æœ€æ–°)")
                return self._load_from_cache(etf_code, threshold)
            
            # 4. åŠ è½½ç¼“å­˜æ•°æ®
            cached_df = self.cache_manager.load_cached_etf_data(etf_code, threshold)
            if cached_df is None:
                # ç¼“å­˜åŠ è½½å¤±è´¥ï¼Œè¿›è¡Œå…¨é‡è®¡ç®—
                return self._process_new_etf(etf_code, threshold, False)
            
            # 5. æ‰¾å‡ºæ–°å¢çš„æ•°æ®è¡Œ
            new_data_df = etf_df[etf_df['date'] > cached_latest_date].copy()
            
            if new_data_df.empty:
                # æ²¡æœ‰æ–°æ•°æ®
                return self._load_from_cache(etf_code, threshold)
            
            new_rows_count = len(new_data_df)
            if not (self.config and self.config.performance_mode):
                print(f"   âš¡ {etf_code}: å¢é‡è®¡ç®— {new_rows_count} è¡Œæ–°æ•°æ®")
            
            # 6. è·å–è¶³å¤Ÿçš„å†å²æ•°æ®ç”¨äºè®¡ç®—WMA
            max_period = max(self.config.wma_periods)
            # éœ€è¦é¢å¤–çš„å†å²æ•°æ®æ¥è®¡ç®—æ–°æ•°æ®çš„WMA
            history_needed = max_period + new_rows_count
            
            # ä»åŸå§‹æ•°æ®è·å–è¶³å¤Ÿçš„å†å²è®°å½•
            calc_df = etf_df.head(history_needed).copy()
            
            # 7. è®¡ç®—æ–°æ•°æ®çš„WMA
            from ..engines.historical_calculator import WMAHistoricalCalculator
            calculator = WMAHistoricalCalculator(self.config)
            
            # è®¡ç®—åŒ…å«æ–°æ•°æ®çš„WMA
            new_wma_df = calculator.calculate_historical_wma(etf_code, calc_df)
            
            if new_wma_df is None:
                return None
            
            # 8. åªä¿ç•™æ–°å¢æ•°æ®çš„WMAç»“æœ
            new_wma_df = new_wma_df.head(new_rows_count)
            
            # 9. åˆå¹¶æ–°æ—§æ•°æ®
            # ç§»é™¤ç¼“å­˜ä¸­ä¸æ–°æ•°æ®æ—¥æœŸé‡å¤çš„è¡Œï¼ˆå¦‚æœæœ‰ï¼‰
            cached_df = cached_df[~cached_df['date'].isin(new_wma_df['date'])]
            
            # åˆå¹¶æ•°æ®ï¼ˆæ–°æ•°æ®åœ¨å‰ï¼‰
            updated_df = pd.concat([new_wma_df, cached_df], ignore_index=True)
            
            # ç¡®ä¿æŒ‰æ—¥æœŸå€’åºæ’åˆ—
            updated_df = updated_df.sort_values('date', ascending=False).reset_index(drop=True)
            
            # 10. æ›´æ–°ç¼“å­˜
            success = self.cache_manager.save_etf_cache(etf_code, updated_df, threshold)
            if not success:
                print(f"   âš ï¸ {etf_code}: ç¼“å­˜æ›´æ–°å¤±è´¥")
            
            # 11. æ„å»ºè¿”å›ç»“æœ
            latest_row = updated_df.iloc[0]
            
            # æ„å»ºæœ€æ–°ä»·æ ¼ä¿¡æ¯
            latest_price = {
                'date': str(latest_row['date']),
                'close': float(etf_df.iloc[0]['æ”¶ç›˜ä»·']) if 'æ”¶ç›˜ä»·' in etf_df.columns else 0.0,
                'change_pct': float(etf_df.iloc[0]['æ¶¨å¹…%']) if 'æ¶¨å¹…%' in etf_df.columns else 0.0
            }
            
            # æ„å»ºWMAå€¼ - ç»Ÿä¸€ä½¿ç”¨ä¸‹åˆ’çº¿æ ¼å¼
            wma_values = {}
            for period in self.config.wma_periods:
                wma_col = f'WMA_{period}'
                if wma_col in latest_row:
                    wma_val = latest_row[wma_col]
                    if pd.notna(wma_val):
                        wma_values[f'WMA_{period}'] = float(wma_val)
            
            # å·®å€¼æŒ‡æ ‡ - ç»Ÿä¸€ä½¿ç”¨ä¸‹åˆ’çº¿æ ¼å¼
            diff_fields = ['WMA_DIFF_5_20', 'WMA_DIFF_5_20_PCT', 'WMA_DIFF_3_5']
            for field in diff_fields:
                if field in latest_row:
                    val = latest_row[field]
                    if pd.notna(val):
                        wma_values[field] = float(val)
            
            result = {
                'etf_code': etf_code,
                'adj_type': self.config.adj_type,
                'latest_price': latest_price,
                'wma_values': wma_values,
                'processing_time': datetime.now().isoformat(),
                'data_source': 'incremental_update',
                'historical_data': updated_df,
                'success': True,
                'incremental_rows': new_rows_count
            }
            
            return result
            
        except Exception as e:
            print(f"   âŒ {etf_code}: å¢é‡æ›´æ–°å¤±è´¥: {str(e)}")
            # å¤±è´¥æ—¶å°è¯•å…¨é‡è®¡ç®—
            return self._process_new_etf(etf_code, threshold, False)
    
    def _process_cached_etf(self, etf_code: str, threshold: str) -> Optional[Dict]:
        """å¤„ç†ç¼“å­˜ä¸­çš„ETF - ä¼˜å…ˆä½¿ç”¨ç¼“å­˜ï¼Œåªåœ¨å¿…è¦æ—¶å¢é‡æ›´æ–°"""
        try:
            # 1. è·å–ç¼“å­˜çš„æœ€æ–°æ—¥æœŸ
            cached_latest_date = self.cache_manager.get_cached_etf_latest_date(etf_code, threshold)
            if not cached_latest_date:
                # æ²¡æœ‰ç¼“å­˜ï¼Œè¿›è¡Œå…¨é‡è®¡ç®—
                if not (self.config and self.config.performance_mode):
                    print(f"   ğŸ†• {etf_code}: æ— ç¼“å­˜ï¼Œå…¨é‡è®¡ç®—")
                return self._process_new_etf(etf_code, threshold, False)
            
            # 2. å¿«é€Ÿæ£€æŸ¥æºæ–‡ä»¶æ˜¯å¦æœ‰æ›´æ–°
            source_file_path = self.config.get_file_path(etf_code)
            
            # è¯»å–æºæ–‡ä»¶çš„ç¬¬ä¸€è¡Œæ¥è·å–æœ€æ–°æ—¥æœŸ
            try:
                # åªè¯»å–å‰å‡ è¡Œä»¥æé«˜æ€§èƒ½
                source_df = pd.read_csv(source_file_path, encoding='utf-8', nrows=2)
                if source_df.empty:
                    return None
                
                # ğŸ”§ ä¿®å¤ï¼šç»Ÿä¸€æ—¥æœŸæ ¼å¼å¤„ç†
                # æºæ–‡ä»¶æ—¥æœŸæ ¼å¼é€šå¸¸æ˜¯YYYYMMDDï¼Œéœ€è¦è½¬æ¢ä¸ºYYYY-MM-DDè¿›è¡Œæ¯”è¾ƒ
                source_date_raw = str(source_df.iloc[0]['date'])
                if len(source_date_raw) == 8 and source_date_raw.isdigit():
                    # YYYYMMDDæ ¼å¼ï¼Œè½¬æ¢ä¸ºYYYY-MM-DD
                    latest_source_date = f"{source_date_raw[:4]}-{source_date_raw[4:6]}-{source_date_raw[6:8]}"
                else:
                    # å·²ç»æ˜¯YYYY-MM-DDæ ¼å¼æˆ–å…¶ä»–æ ¼å¼
                    latest_source_date = str(pd.to_datetime(source_date_raw).strftime('%Y-%m-%d'))
                
                # ç¡®ä¿ç¼“å­˜æ—¥æœŸä¹Ÿæ˜¯YYYY-MM-DDæ ¼å¼
                cached_date_str = str(pd.to_datetime(cached_latest_date).strftime('%Y-%m-%d'))
                
                # 3. å¦‚æœæºæ•°æ®æ²¡æœ‰æ›´æ–°ï¼Œç›´æ¥ä½¿ç”¨ç¼“å­˜
                if latest_source_date <= cached_date_str:
                    if not (self.config and self.config.performance_mode):
                        print(f"   ğŸ’¾ {etf_code}: ä½¿ç”¨ç¼“å­˜ (æœ€æ–°: {cached_date_str})")
                    return self._load_from_cache(etf_code, threshold)
                
                # 4. æºæ•°æ®æœ‰æ›´æ–°ï¼Œè¿›è¡Œå¢é‡è®¡ç®—
                if not (self.config and self.config.performance_mode):
                    print(f"   âš¡ {etf_code}: æ£€æµ‹åˆ°æ›´æ–° ({cached_date_str} -> {latest_source_date})")
                return self._process_incremental_etf(etf_code, threshold)
                
            except Exception as e:
                # è¯»å–æºæ–‡ä»¶å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨ç¼“å­˜
                if not (self.config and self.config.performance_mode):
                    print(f"   âš ï¸ {etf_code}: æºæ–‡ä»¶è¯»å–å¤±è´¥ï¼Œä½¿ç”¨ç¼“å­˜")
                return self._load_from_cache(etf_code, threshold)
            
        except Exception as e:
            if not (self.config and self.config.performance_mode):
                print(f"   âŒ {etf_code}: ç¼“å­˜å¤„ç†å¤±è´¥: {str(e)}")
            return None
    
    def _process_new_etf(self, etf_code: str, threshold: str, include_advanced_analysis: bool = False) -> Optional[Dict]:
        """å¤„ç†æ–°ETF - å…¨é‡è®¡ç®—"""
        try:
            # ä½¿ç”¨ETFå¤„ç†å™¨è¿›è¡Œå…¨é‡è®¡ç®—
            result = self.etf_processor.process_single_etf(etf_code, include_advanced_analysis)
            if result:
                result['data_source'] = 'full_calculation'
                
                # ä¿å­˜åˆ°ç¼“å­˜
                if self.enable_cache and self.cache_manager and threshold:
                    self._try_save_to_cache(etf_code, result, threshold)
            
            return result
            
        except Exception as e:
            if not (self.config and self.config.performance_mode):
                print(f"   âŒ {etf_code}: å…¨é‡è®¡ç®—å¤±è´¥: {str(e)}")
            return None
    
    def _load_from_cache(self, etf_code: str, threshold: str) -> Optional[Dict]:
        """ä»ç¼“å­˜åŠ è½½ETFç»“æœ - ç»Ÿä¸€ç¼“å­˜æ ¼å¼"""
        try:
            cached_df = self.cache_manager.load_cached_etf_data(etf_code, threshold)
            
            if cached_df is None or cached_df.empty:
                return None
            
            # ç¡®ä¿ç¼“å­˜æ•°æ®æŒ‰æ—¶é—´å€’åºæ’åˆ—
            cached_df = cached_df.sort_values('date', ascending=False).reset_index(drop=True)
            latest_row = cached_df.iloc[0]  # ç¬¬ä¸€è¡Œæ˜¯æœ€æ–°æ•°æ®
            
            # æ„å»ºæœ€æ–°ä»·æ ¼ä¿¡æ¯
            latest_price = {
                'date': str(latest_row['date']),
                'close': 0.0,
                'change_pct': 0.0
            }
            
            # å°è¯•ä»æºæ–‡ä»¶è·å–æœ€æ–°ä»·æ ¼ä¿¡æ¯
            try:
                source_file_path = self.config.get_file_path(etf_code)
                source_df = pd.read_csv(source_file_path, encoding='utf-8', nrows=1)
                if not source_df.empty:
                    latest_price['close'] = float(source_df.iloc[0]['æ”¶ç›˜ä»·']) if 'æ”¶ç›˜ä»·' in source_df.columns else 0.0
                    latest_price['change_pct'] = float(source_df.iloc[0]['æ¶¨å¹…%']) if 'æ¶¨å¹…%' in source_df.columns else 0.0
            except:
                pass  # å¦‚æœè¯»å–å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼
            
            # æ„å»ºWMAå€¼ - ç»Ÿä¸€ä½¿ç”¨ä¸‹åˆ’çº¿æ ¼å¼
            wma_values = {}
            for period in self.config.wma_periods:
                wma_col = f'WMA_{period}'
                if wma_col in cached_df.columns:
                    wma_val = latest_row[wma_col]
                    if pd.notna(wma_val):
                        wma_values[f'WMA_{period}'] = float(wma_val)
            
            # å·®å€¼æŒ‡æ ‡ - ç»Ÿä¸€ä½¿ç”¨ä¸‹åˆ’çº¿æ ¼å¼
            diff_fields = ['WMA_DIFF_5_20', 'WMA_DIFF_5_20_PCT', 'WMA_DIFF_3_5']
            for field in diff_fields:
                if field in cached_df.columns:
                    val = latest_row[field]
                    if pd.notna(val):
                        wma_values[field] = float(val)
            
            # æ„å»ºç»“æœå¯¹è±¡
            result = {
                'etf_code': etf_code,
                'adj_type': self.config.adj_type,
                'latest_price': latest_price,
                'wma_values': wma_values,
                'processing_time': datetime.now().isoformat(),
                'data_source': 'cache',
                'historical_data': cached_df,
                'success': True
            }
            
            return result
            
        except Exception as e:
            if not (self.config and self.config.performance_mode):
                print(f"   âŒ {etf_code}: ç¼“å­˜åŠ è½½å¤±è´¥: {str(e)}")
            return None 