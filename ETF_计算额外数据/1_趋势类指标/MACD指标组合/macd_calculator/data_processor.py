#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
MACDæ•°æ®å¤„ç†å™¨
==============

è´Ÿè´£ETFæ•°æ®çš„è¯»å–ã€æ¸…æ´—ã€éªŒè¯å’Œç­›é€‰
ğŸ” åŠŸèƒ½: æ•°æ®æºç®¡ç†ã€æ•°æ®è´¨é‡æ£€æŸ¥ã€ETFç­›é€‰
ğŸ“Š æ”¯æŒ: å‰å¤æƒ/åå¤æƒ/é™¤æƒæ•°æ®ï¼Œæ‰¹é‡å¤„ç†

"""

import os
import pandas as pd
import numpy as np
from typing import Dict, List, Optional, Tuple
from .config import MACDConfig


class MACDDataProcessor:
    """MACDæ•°æ®å¤„ç†å™¨ - ä¸“ä¸šæ•°æ®ç®¡ç†ç‰ˆ"""
    
    def __init__(self, config: MACDConfig):
        """
        åˆå§‹åŒ–æ•°æ®å¤„ç†å™¨
        
        Args:
            config: MACDé…ç½®å¯¹è±¡
        """
        self.config = config
        self.data_source_path = config.get_data_source_path()
        
        print("ğŸ“Š MACDæ•°æ®å¤„ç†å™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"ğŸ“ æ•°æ®æºè·¯å¾„: {self.data_source_path}")
    
    def get_available_etf_files(self) -> List[str]:
        """
        è·å–å¯ç”¨çš„ETFæ–‡ä»¶åˆ—è¡¨
        
        Returns:
            ETFä»£ç åˆ—è¡¨
        """
        if not os.path.exists(self.data_source_path):
            print(f"âš ï¸ æ•°æ®æºè·¯å¾„ä¸å­˜åœ¨: {self.data_source_path}")
            return []
        
        etf_files = []
        for file in os.listdir(self.data_source_path):
            if file.endswith('.csv'):
                etf_code = file.replace('.csv', '').replace('.SZ', '').replace('.SH', '')
                etf_files.append(etf_code)
        
        print(f"ğŸ“ˆ å‘ç° {len(etf_files)} ä¸ªETFæ•°æ®æ–‡ä»¶")
        return sorted(etf_files)
    
    def load_etf_data(self, etf_code: str) -> Optional[pd.DataFrame]:
        """
        åŠ è½½å•ä¸ªETFçš„æ•°æ®
        
        Args:
            etf_code: ETFä»£ç 
            
        Returns:
            ETFæ•°æ®DataFrameï¼Œå¦‚æœåŠ è½½å¤±è´¥è¿”å›None
        """
        # å°è¯•ä¸åŒçš„æ–‡ä»¶åæ ¼å¼
        possible_filenames = [
            f"{etf_code}.csv",
            f"{etf_code}.SZ.csv",
            f"{etf_code}.SH.csv"
        ]
        
        for filename in possible_filenames:
            file_path = os.path.join(self.data_source_path, filename)
            if os.path.exists(file_path):
                try:
                    df = pd.read_csv(file_path)
                    return self._clean_and_validate_data(df, etf_code)
                except Exception as e:
                    print(f"âŒ è¯»å–æ–‡ä»¶å¤±è´¥ {filename}: {e}")
                    continue
        
        print(f"âŒ æœªæ‰¾åˆ°ETFæ•°æ®æ–‡ä»¶: {etf_code}")
        return None
    
    def _clean_and_validate_data(self, df: pd.DataFrame, etf_code: str) -> Optional[pd.DataFrame]:
        """
        æ¸…æ´—å’ŒéªŒè¯æ•°æ®
        
        Args:
            df: åŸå§‹æ•°æ®DataFrame
            etf_code: ETFä»£ç 
            
        Returns:
            æ¸…æ´—åçš„DataFrame
        """
        try:
            # ä¸­æ–‡åˆ—åæ˜ å°„åˆ°è‹±æ–‡
            column_mapping = {
                'æ—¥æœŸ': 'Date',
                'å¼€ç›˜ä»·': 'Open', 
                'æœ€é«˜ä»·': 'High',
                'æœ€ä½ä»·': 'Low',
                'æ”¶ç›˜ä»·': 'Close',
                'æˆäº¤é‡(æ‰‹æ•°)': 'Volume',
                'æˆäº¤é¢(åƒå…ƒ)': 'Amount'
            }
            
            # é‡å‘½ååˆ—
            df = df.rename(columns=column_mapping)
            
            # æ£€æŸ¥å¿…è¦åˆ—
            required_columns = ['Date', 'Open', 'High', 'Low', 'Close', 'Volume']
            missing_columns = [col for col in required_columns if col not in df.columns]
            
            if missing_columns:
                print(f"âŒ {etf_code} ç¼ºå°‘å¿…è¦åˆ—: {missing_columns}")
                print(f"   å®é™…åˆ—å: {list(df.columns)}")
                return None
            
            # æ•°æ®ç±»å‹è½¬æ¢
            # å¤„ç†æ—¥æœŸæ ¼å¼ï¼š20250627 -> 2025-06-27
            df['Date'] = pd.to_datetime(df['Date'], format='%Y%m%d', errors='coerce')
            
            for col in ['Open', 'High', 'Low', 'Close']:
                df[col] = pd.to_numeric(df[col], errors='coerce')
            df['Volume'] = pd.to_numeric(df['Volume'], errors='coerce')
            
            # ç§»é™¤æ— æ•ˆæ•°æ®è¡Œ
            df = df.dropna(subset=['Date', 'Close'])
            
            # æŒ‰æ—¥æœŸæ’åº
            df = df.sort_values('Date').reset_index(drop=True)
            
            # æ•°æ®è´¨é‡æ£€æŸ¥
            if len(df) < 100:  # è‡³å°‘éœ€è¦100ä¸ªäº¤æ˜“æ—¥
                print(f"âš ï¸ {etf_code} æ•°æ®é‡ä¸è¶³ ({len(df)} è¡Œ)")
                return None
            
            # ä»·æ ¼åˆç†æ€§æ£€æŸ¥
            if df['Close'].min() <= 0:
                print(f"âš ï¸ {etf_code} å­˜åœ¨éæ­£ä»·æ ¼")
                df = df[df['Close'] > 0].reset_index(drop=True)
            
            # æ£€æŸ¥ä»·æ ¼è¿ç»­æ€§
            price_changes = df['Close'].pct_change().abs()
            extreme_changes = price_changes > 0.5  # 50%ä»¥ä¸Šçš„å•æ—¥å˜åŠ¨
            if extreme_changes.sum() > 5:
                print(f"âš ï¸ {etf_code} å­˜åœ¨ {extreme_changes.sum()} ä¸ªå¼‚å¸¸ä»·æ ¼å˜åŠ¨")
            
            print(f"âœ… {etf_code} æ•°æ®æ¸…æ´—å®Œæˆï¼Œæœ‰æ•ˆæ•°æ® {len(df)} è¡Œ")
            return df
            
        except Exception as e:
            print(f"âŒ {etf_code} æ•°æ®æ¸…æ´—å¤±è´¥: {e}")
            return None
    
    def filter_qualified_etfs(self, threshold_type: str = "3000ä¸‡é—¨æ§›") -> List[str]:
        """
        ç­›é€‰ç¬¦åˆæ¡ä»¶çš„ETF
        
        Args:
            threshold_type: é—¨æ§›ç±»å‹ ("3000ä¸‡é—¨æ§›" æˆ– "5000ä¸‡é—¨æ§›")
            
        Returns:
            ç¬¦åˆæ¡ä»¶çš„ETFä»£ç åˆ—è¡¨
        """
        # ä¿®å¤ç­›é€‰æ–‡ä»¶è·¯å¾„è®¡ç®— - æ‰¾åˆ°é¡¹ç›®æ ¹ç›®å½•
        project_root = self.config.base_path
        while not os.path.basename(project_root) == 'data_clear':
            parent = os.path.dirname(project_root)
            if parent == project_root:  # å·²ç»åˆ°è¾¾æ ¹ç›®å½•
                break
            project_root = parent
        
        # è¯»å–ç­›é€‰åçš„ETFåˆ—è¡¨
        filter_file_path = os.path.join(
            project_root,
            "ETF_åˆç­›", "data", threshold_type, "é€šè¿‡ç­›é€‰ETF.txt"
        )
        
        if not os.path.exists(filter_file_path):
            print(f"âš ï¸ ç­›é€‰æ–‡ä»¶ä¸å­˜åœ¨: {filter_file_path}")
            # è¿”å›æ‰€æœ‰å¯ç”¨çš„ETFæ–‡ä»¶
            return self.get_available_etf_files()
        
        try:
            qualified_etfs = []
            with open(filter_file_path, 'r', encoding='utf-8') as f:
                for line in f:
                    line = line.strip()
                    # è·³è¿‡ç©ºè¡Œå’Œæ³¨é‡Šè¡Œï¼ˆä»¥#å¼€å¤´ï¼‰
                    if line and not line.startswith('#'):
                        qualified_etfs.append(line)
            
            print(f"ğŸ“‹ {threshold_type}: å‘ç° {len(qualified_etfs)} ä¸ªç¬¦åˆæ¡ä»¶çš„ETF")
            return qualified_etfs
            
        except Exception as e:
            print(f"âŒ è¯»å–ç­›é€‰æ–‡ä»¶å¤±è´¥: {e}")
            return self.get_available_etf_files()
    
    def batch_load_etf_data(self, etf_codes: List[str]) -> Dict[str, pd.DataFrame]:
        """
        æ‰¹é‡åŠ è½½ETFæ•°æ®
        
        Args:
            etf_codes: ETFä»£ç åˆ—è¡¨
            
        Returns:
            ETFä»£ç åˆ°æ•°æ®DataFrameçš„æ˜ å°„å­—å…¸
        """
        etf_data = {}
        
        print(f"ğŸ”„ å¼€å§‹æ‰¹é‡åŠ è½½ {len(etf_codes)} ä¸ªETFçš„æ•°æ®...")
        
        success_count = 0
        for i, etf_code in enumerate(etf_codes, 1):
            print(f"ğŸ“Š [{i}/{len(etf_codes)}] å¤„ç† {etf_code}...", end=" ")
            
            df = self.load_etf_data(etf_code)
            if df is not None:
                etf_data[etf_code] = df
                success_count += 1
                print("âœ…")
            else:
                print("âŒ")
        
        print(f"ğŸ¯ æ‰¹é‡åŠ è½½å®Œæˆ: {success_count}/{len(etf_codes)} ä¸ªETFåŠ è½½æˆåŠŸ")
        return etf_data
    
    def check_data_requirements_for_macd(self, df: pd.DataFrame) -> bool:
        """
        æ£€æŸ¥æ•°æ®æ˜¯å¦æ»¡è¶³MACDè®¡ç®—è¦æ±‚
        
        Args:
            df: ETFæ•°æ®DataFrame
            
        Returns:
            æ˜¯å¦æ»¡è¶³è¦æ±‚
        """
        fast_period, slow_period, signal_period = self.config.get_macd_periods()
        min_required = slow_period + signal_period + 10  # é¢å¤–çš„10ä¸ªæ•°æ®ç‚¹ç¡®ä¿ç¨³å®š
        
        if len(df) < min_required:
            return False
        
        # æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿçš„éç©ºæ”¶ç›˜ä»·
        valid_closes = df['Close'].dropna()
        if len(valid_closes) < min_required:
            return False
        
        return True
    
    def get_latest_trading_date(self, etf_code: str) -> Optional[str]:
        """
        è·å–ETFçš„æœ€æ–°äº¤æ˜“æ—¥æœŸ
        
        Args:
            etf_code: ETFä»£ç 
            
        Returns:
            æœ€æ–°äº¤æ˜“æ—¥æœŸå­—ç¬¦ä¸²ï¼Œæ ¼å¼ä¸ºYYYY-MM-DD
        """
        df = self.load_etf_data(etf_code)
        if df is not None and len(df) > 0:
            latest_date = df['Date'].max()
            return latest_date.strftime('%Y-%m-%d')
        return None
    
    def get_data_summary(self, etf_codes: List[str]) -> Dict:
        """
        è·å–æ•°æ®æ¦‚è¦ç»Ÿè®¡
        
        Args:
            etf_codes: ETFä»£ç åˆ—è¡¨
            
        Returns:
            æ•°æ®æ¦‚è¦å­—å…¸
        """
        summary = {
            'total_etfs': len(etf_codes),
            'valid_etfs': 0,
            'invalid_etfs': 0,
            'macd_ready_etfs': 0,
            'average_data_length': 0,
            'date_range': {'start': None, 'end': None},
            'failed_etfs': []
        }
        
        valid_lengths = []
        all_start_dates = []
        all_end_dates = []
        
        for etf_code in etf_codes:
            df = self.load_etf_data(etf_code)
            if df is not None:
                summary['valid_etfs'] += 1
                valid_lengths.append(len(df))
                
                all_start_dates.append(df['Date'].min())
                all_end_dates.append(df['Date'].max())
                
                if self.check_data_requirements_for_macd(df):
                    summary['macd_ready_etfs'] += 1
            else:
                summary['invalid_etfs'] += 1
                summary['failed_etfs'].append(etf_code)
        
        if valid_lengths:
            summary['average_data_length'] = int(np.mean(valid_lengths))
        
        if all_start_dates and all_end_dates:
            summary['date_range']['start'] = min(all_start_dates).strftime('%Y-%m-%d')
            summary['date_range']['end'] = max(all_end_dates).strftime('%Y-%m-%d')
        
        return summary
    
    def validate_etf_for_processing(self, etf_code: str) -> Tuple[bool, str]:
        """
        éªŒè¯ETFæ˜¯å¦å¯ä»¥è¿›è¡ŒMACDå¤„ç†
        
        Args:
            etf_code: ETFä»£ç 
            
        Returns:
            (æ˜¯å¦å¯ä»¥å¤„ç†, åŸå› è¯´æ˜)
        """
        df = self.load_etf_data(etf_code)
        
        if df is None:
            return False, "æ•°æ®åŠ è½½å¤±è´¥"
        
        if not self.check_data_requirements_for_macd(df):
            fast_period, slow_period, signal_period = self.config.get_macd_periods()
            min_required = slow_period + signal_period + 10
            return False, f"æ•°æ®é‡ä¸è¶³ï¼Œéœ€è¦è‡³å°‘{min_required}ä¸ªäº¤æ˜“æ—¥ï¼Œå½“å‰{len(df)}ä¸ª"
        
        # æ£€æŸ¥æœ€è¿‘æ•°æ®çš„å®Œæ•´æ€§
        recent_data = df.tail(50)  # æ£€æŸ¥æœ€è¿‘50ä¸ªäº¤æ˜“æ—¥
        missing_closes = recent_data['Close'].isna().sum()
        if missing_closes > 5:
            return False, f"æœ€è¿‘æ•°æ®è´¨é‡å·®ï¼Œ{missing_closes}ä¸ªç¼ºå¤±æ”¶ç›˜ä»·"
        
        return True, "æ•°æ®éªŒè¯é€šè¿‡" 