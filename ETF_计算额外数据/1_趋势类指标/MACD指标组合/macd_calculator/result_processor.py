#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
MACDç»“æœå¤„ç†å™¨ - å®¢è§‚æ•°æ®ä¸“ç‰ˆ
=========================

ğŸš« å·²ç®€åŒ–ï¼šåªä¿ç•™å®¢è§‚æ•°æ®å¤„ç†ï¼Œç§»é™¤ä¸»è§‚åˆ¤æ–­
è´Ÿè´£MACDè®¡ç®—ç»“æœçš„æ ¼å¼åŒ–ã€è¾“å‡ºå’Œç®¡ç†
ğŸ“Š åŠŸèƒ½: CSVç”Ÿæˆã€ç›®å½•ç®¡ç†ã€ç»“æœéªŒè¯ã€ç»Ÿè®¡æŠ¥å‘Š
ğŸ¯ è¾“å‡º: æ ‡å‡†åŒ–çš„MACDæŒ‡æ ‡æ•°æ®æ–‡ä»¶ï¼ˆçº¯å®¢è§‚æ•°æ®ï¼‰
ğŸš« å·²ç§»é™¤: äº¤æ˜“å»ºè®®ã€ä¿¡å·åˆ†æã€é‡‘å‰æ­»å‰ç­‰ä¸»è§‚åˆ¤æ–­

"""

import os
import pandas as pd
import numpy as np
from typing import Dict, List, Optional, Tuple
from datetime import datetime
from .config import MACDConfig


class MACDResultProcessor:
    """MACDç»“æœå¤„ç†å™¨ - å®¢è§‚æ•°æ®ä¸“ç‰ˆ"""
    
    def __init__(self, config: MACDConfig):
        """
        åˆå§‹åŒ–ç»“æœå¤„ç†å™¨
        
        Args:
            config: MACDé…ç½®å¯¹è±¡
        """
        self.config = config
        self.base_output_dir = config.get_output_base_dir()
        
        # åˆ›å»ºè¾“å‡ºç›®å½•ç»“æ„
        self._ensure_output_directories()
        
        print("ğŸ“ MACDç»“æœå¤„ç†å™¨åˆå§‹åŒ–å®Œæˆ (å®¢è§‚æ•°æ®ä¸“ç‰ˆ)")
        print(f"ğŸ“‚ è¾“å‡ºç›®å½•: {self.base_output_dir}")
        print("ğŸš« å·²ç§»é™¤: äº¤æ˜“å»ºè®®ã€ä¿¡å·åˆ†æç­‰ä¸»è§‚åˆ¤æ–­")
    
    def _ensure_output_directories(self):
        """ç¡®ä¿è¾“å‡ºç›®å½•ç»“æ„å­˜åœ¨"""
        try:
            # åˆ›å»ºä¸»è¾“å‡ºç›®å½•
            os.makedirs(self.base_output_dir, exist_ok=True)
            
            # åˆ›å»ºé—¨æ§›ç±»å‹ç›®å½•ï¼Œæ¯ä¸ªé—¨æ§›ä¸‹æŒ‰å‚æ•°ç±»å‹åˆ†å­ç›®å½•
            thresholds = ["3000ä¸‡é—¨æ§›", "5000ä¸‡é—¨æ§›"]
            parameter_types = ["æ ‡å‡†", "æ•æ„Ÿ", "å¹³æ»‘"]
            
            for threshold in thresholds:
                for param_type in parameter_types:
                    threshold_param_dir = os.path.join(self.base_output_dir, threshold, param_type)
                    os.makedirs(threshold_param_dir, exist_ok=True)
                    print(f"ğŸ“ ç¡®ä¿ç›®å½•å­˜åœ¨: {threshold_param_dir}")
                    
        except Exception as e:
            print(f"âŒ åˆ›å»ºè¾“å‡ºç›®å½•å¤±è´¥: {e}")
    
    def format_macd_results(self, df: pd.DataFrame, etf_code: str) -> pd.DataFrame:
        """
        æ ¼å¼åŒ–MACDè®¡ç®—ç»“æœ - å®¢è§‚æ•°æ®ä¸“ç‰ˆ
        
        Args:
            df: åŒ…å«MACDè®¡ç®—ç»“æœçš„DataFrame
            etf_code: ETFä»£ç 
            
        Returns:
            æ ¼å¼åŒ–åçš„DataFrame
        """
        try:
            if df.empty:
                print(f"âš ï¸ {etf_code}: ç©ºçš„MACDç»“æœ")
                return pd.DataFrame()
            
            # åˆ›å»ºæ ¼å¼åŒ–åçš„DataFrameï¼ŒæŒ‰ç”¨æˆ·è¦æ±‚çš„å­—æ®µé¡ºåº
            formatted_df = pd.DataFrame({
                'date': df['Date'].dt.strftime('%Y-%m-%d'),  # æ—¥æœŸæ ¼å¼åŒ–
                'code': etf_code,  # ETFä»£ç 
                'ema_fast': df['EMA_Fast'].round(6),  # å¿«çº¿EMA
                'ema_slow': df['EMA_Slow'].round(6),  # æ…¢çº¿EMA
                'dif': df['DIF'].round(6),  # ema_fast - ema_slow
                'dea': df['DEA'].round(6),  # DIFçš„ä¿¡å·çº¿EMA
                'macd_bar': df['MACD'].round(6),  # (dif - dea) * 2
                'calc_time': pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')  # è„šæœ¬æ›´æ–°æ—¶é—´
            })
            
            # æŒ‰æ—¥æœŸæ’åºï¼ˆæœ€æ–°æ—¥æœŸåœ¨å‰ï¼‰
            formatted_df = formatted_df.sort_values('date', ascending=False).reset_index(drop=True)
            
            print(f"âœ… {etf_code} MACDç»“æœæ ¼å¼åŒ–å®Œæˆï¼Œ{len(formatted_df)} è¡Œæ•°æ®")
            return formatted_df
            
        except Exception as e:
            print(f"âŒ {etf_code} MACDç»“æœæ ¼å¼åŒ–å¤±è´¥: {e}")
            return pd.DataFrame()
    

    
    def save_single_etf_result(self, result_df: pd.DataFrame, etf_code: str, 
                              threshold_type: str = "3000ä¸‡é—¨æ§›") -> bool:
        """
        ä¿å­˜å•ä¸ªETFçš„MACDç»“æœåˆ°å¯¹åº”å‚æ•°ç±»å‹çš„å­ç›®å½•
        
        Args:
            result_df: æ ¼å¼åŒ–çš„ç»“æœDataFrame
            etf_code: ETFä»£ç 
            threshold_type: é—¨æ§›ç±»å‹
            
        Returns:
            æ˜¯å¦ä¿å­˜æˆåŠŸ
        """
        try:
            # æ ¹æ®é…ç½®å‚æ•°ç±»å‹ç¡®å®šå­ç›®å½•
            parameter_mapping = {
                'standard': 'æ ‡å‡†',
                'sensitive': 'æ•æ„Ÿ', 
                'smooth': 'å¹³æ»‘'
            }
            
            param_type = parameter_mapping.get(self.config.parameter_set, 'æ ‡å‡†')
            
            # æ„å»ºä¿å­˜è·¯å¾„ï¼šé—¨æ§›ç±»å‹/å‚æ•°ç±»å‹/ETFæ–‡ä»¶
            output_subdir = os.path.join(self.base_output_dir, threshold_type, param_type)
            output_file = os.path.join(output_subdir, f"{etf_code}.csv")
            
            # ç¡®ä¿ç›®å½•å­˜åœ¨
            os.makedirs(output_subdir, exist_ok=True)
            
            # ä¿å­˜æ–‡ä»¶
            result_df.to_csv(output_file, index=False, encoding='utf-8-sig')
            
            print(f"ğŸ’¾ {etf_code} ç»“æœå·²ä¿å­˜: {output_file}")
            return True
            
        except Exception as e:
            print(f"âŒ {etf_code} ä¿å­˜å¤±è´¥: {e}")
            return False
    
    def batch_save_results(self, results_dict: Dict[str, pd.DataFrame], 
                          threshold_type: str = "3000ä¸‡é—¨æ§›") -> Dict[str, str]:
        """
        æ‰¹é‡ä¿å­˜ETFç»“æœ
        
        Args:
            results_dict: ETFä»£ç åˆ°ç»“æœDataFrameçš„æ˜ å°„
            threshold_type: é—¨æ§›ç±»å‹
            
        Returns:
            ä¿å­˜çŠ¶æ€å­—å…¸
        """
        save_status = {}
        success_count = 0
        
        print(f"ğŸ’¾ å¼€å§‹æ‰¹é‡ä¿å­˜ {len(results_dict)} ä¸ªETFçš„MACDç»“æœ...")
        
        for i, (etf_code, df) in enumerate(results_dict.items(), 1):
            print(f"ğŸ’¾ [{i}/{len(results_dict)}] ä¿å­˜ {etf_code}...", end=" ")
            
            if self.save_single_etf_result(df, etf_code, threshold_type):
                save_status[etf_code] = "æˆåŠŸ"
                success_count += 1
                print("âœ…")
            else:
                save_status[etf_code] = "å¤±è´¥"
                print("âŒ")
        
        print(f"ğŸ¯ æ‰¹é‡ä¿å­˜å®Œæˆ: {success_count}/{len(results_dict)} ä¸ªæ–‡ä»¶ä¿å­˜æˆåŠŸ")
        return save_status
    
    def generate_summary_report(self, results_dict: Dict[str, pd.DataFrame], 
                               save_status: Dict[str, str],
                               threshold_type: str = "3000ä¸‡é—¨æ§›") -> Dict:
        """
        ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š - å®¢è§‚æ•°æ®ä¸“ç‰ˆ
        
        Args:
            results_dict: ç»“æœæ•°æ®å­—å…¸
            save_status: ä¿å­˜çŠ¶æ€å­—å…¸
            threshold_type: é—¨æ§›ç±»å‹
            
        Returns:
            æ±‡æ€»æŠ¥å‘Šå­—å…¸ï¼ˆä»…å®¢è§‚ç»Ÿè®¡ï¼‰
        """
        report = {
            'processing_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'threshold_type': threshold_type,
            'parameter_set': self.config.parameter_set,
            'macd_periods': self.config.get_macd_periods(),
            'total_etfs': len(results_dict),
            'successful_saves': sum(1 for status in save_status.values() if status == "æˆåŠŸ"),
            'failed_saves': sum(1 for status in save_status.values() if status == "å¤±è´¥"),
            'average_data_length': 0,
            # ğŸš« å·²ç§»é™¤ä¸»è§‚åˆ¤æ–­ç»Ÿè®¡
            # 'signal_distribution': {},
            # 'latest_signals': {}
        }
        
        # è®¡ç®—å®¢è§‚ç»Ÿè®¡ä¿¡æ¯
        if results_dict:
            data_lengths = [len(df) for df in results_dict.values()]
            report['average_data_length'] = int(np.mean(data_lengths))
            
            # ğŸš« å·²ç§»é™¤ä¿¡å·åˆ†å¸ƒç»Ÿè®¡å’Œæœ€æ–°ä¿¡å·ç»Ÿè®¡
            # all_signals = []
            # latest_signals = {}
            # 
            # for etf_code, df in results_dict.items():
            #     if len(df) > 0:
            #         signals = df['MACDä¿¡å·æè¿°'].tolist()
            #         all_signals.extend(signals)
            #         
            #         # è®°å½•æœ€æ–°ä¿¡å·
            #         latest_signals[etf_code] = {
            #             'signal': df['MACDä¿¡å·æè¿°'].iloc[-1],
            #             'score': df['MACDä¿¡å·è¯„åˆ†'].iloc[-1],
            #             'date': df['æ—¥æœŸ'].iloc[-1]
            #         }
            # 
            # # ä¿¡å·åˆ†å¸ƒç»Ÿè®¡
            # from collections import Counter
            # signal_counts = Counter(all_signals)
            # report['signal_distribution'] = dict(signal_counts)
            # report['latest_signals'] = latest_signals
        
        return report
    
    def save_summary_report(self, report: Dict, threshold_type: str = "3000ä¸‡é—¨æ§›") -> bool:
        """
        ä¿å­˜æ±‡æ€»æŠ¥å‘Š - å®¢è§‚æ•°æ®ä¸“ç‰ˆ
        
        Args:
            report: æ±‡æ€»æŠ¥å‘Šå­—å…¸
            threshold_type: é—¨æ§›ç±»å‹
            
        Returns:
            æ˜¯å¦ä¿å­˜æˆåŠŸ
        """
        try:
            output_dir = os.path.join(self.base_output_dir, threshold_type)
            report_file = os.path.join(output_dir, "MACD_æ±‡æ€»æŠ¥å‘Š.txt")
            
            with open(report_file, 'w', encoding='utf-8') as f:
                f.write("=" * 60 + "\n")
                f.write("MACDæŒ‡æ ‡è®¡ç®—æ±‡æ€»æŠ¥å‘Š - å®¢è§‚æ•°æ®ä¸“ç‰ˆ\n")
                f.write("=" * 60 + "\n\n")
                
                f.write(f"è®¡ç®—æ—¶é—´: {report['processing_time']}\n")
                f.write(f"é—¨æ§›ç±»å‹: {report['threshold_type']}\n")
                f.write(f"å‚æ•°é…ç½®: {report['parameter_set']}\n")
                f.write(f"MACDå‚æ•°: EMA({report['macd_periods'][0]}, {report['macd_periods'][1]}, {report['macd_periods'][2]})\n\n")
                
                f.write(f"å¤„ç†ç»Ÿè®¡:\n")
                f.write(f"- æ€»ETFæ•°é‡: {report['total_etfs']}\n")
                f.write(f"- æˆåŠŸä¿å­˜: {report['successful_saves']}\n")
                f.write(f"- å¤±è´¥ä¿å­˜: {report['failed_saves']}\n")
                f.write(f"- å¹³å‡æ•°æ®é•¿åº¦: {report['average_data_length']} å¤©\n\n")
                
                # ğŸš« å·²ç§»é™¤ä¸»è§‚åˆ¤æ–­ç»Ÿè®¡
                # f.write("ä¿¡å·åˆ†å¸ƒç»Ÿè®¡:\n")
                # for signal, count in report['signal_distribution'].items():
                #     f.write(f"- {signal}: {count} æ¬¡\n")
                # 
                # f.write("\næœ€æ–°ä¿¡å·å‰10ä¸ªETF:\n")
                # sorted_signals = sorted(report['latest_signals'].items(), 
                #                       key=lambda x: x[1]['score'], reverse=True)
                # for i, (etf_code, signal_info) in enumerate(sorted_signals[:10], 1):
                #     f.write(f"{i:2d}. {etf_code}: {signal_info['signal']} "
                #            f"(è¯„åˆ†: {signal_info['score']:.3f}, æ—¥æœŸ: {signal_info['date']})\n")
                
                f.write("è¯´æ˜:\n")
                f.write("ğŸš« å·²ç§»é™¤ä¸»è§‚åˆ¤æ–­å†…å®¹ï¼šä¿¡å·åˆ†æã€äº¤æ˜“å»ºè®®ã€é‡‘å‰æ­»å‰ç­‰\n")
                f.write("ğŸ“Š åªä¿ç•™å®¢è§‚æ•°æ®ï¼šDIFã€DEAã€MACDç­‰æŠ€æœ¯æŒ‡æ ‡æ•°å€¼\n")
            
            print(f"ğŸ“Š æ±‡æ€»æŠ¥å‘Šå·²ä¿å­˜: {report_file}")
            return True
            
        except Exception as e:
            print(f"âŒ æ±‡æ€»æŠ¥å‘Šä¿å­˜å¤±è´¥: {e}")
            return False
    
    def validate_output_files(self, threshold_type: str = "3000ä¸‡é—¨æ§›") -> Dict[str, bool]:
        """
        éªŒè¯è¾“å‡ºæ–‡ä»¶ - å®¢è§‚æ•°æ®ä¸“ç‰ˆ
        
        Args:
            threshold_type: é—¨æ§›ç±»å‹
            
        Returns:
            æ–‡ä»¶éªŒè¯ç»“æœå­—å…¸
        """
        output_dir = os.path.join(self.base_output_dir, threshold_type)
        validation_results = {}
        
        if not os.path.exists(output_dir):
            print(f"âŒ è¾“å‡ºç›®å½•ä¸å­˜åœ¨: {output_dir}")
            return validation_results
        
        csv_files = [f for f in os.listdir(output_dir) if f.endswith('.csv')]
        
        for csv_file in csv_files:
            file_path = os.path.join(output_dir, csv_file)
            etf_code = csv_file.replace('.csv', '')
            
            try:
                # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å¯è¯»
                df = pd.read_csv(file_path)
                
                # æ£€æŸ¥å¿…è¦åˆ—ï¼ˆå®¢è§‚æ•°æ®ï¼‰
                required_columns = ['date', 'code', 'dif', 'dea', 'macd_bar']
                has_required_columns = all(col in df.columns for col in required_columns)
                
                # æ£€æŸ¥æ•°æ®è´¨é‡
                has_valid_data = len(df) > 0 and not df['dif'].isna().all()
                
                validation_results[etf_code] = has_required_columns and has_valid_data
                
            except Exception as e:
                print(f"âŒ éªŒè¯æ–‡ä»¶å¤±è´¥ {csv_file}: {e}")
                validation_results[etf_code] = False
        
        valid_files = sum(validation_results.values())
        total_files = len(validation_results)
        print(f"ğŸ“Š æ–‡ä»¶éªŒè¯å®Œæˆ: {valid_files}/{total_files} ä¸ªæ–‡ä»¶éªŒè¯é€šè¿‡")
        
        return validation_results 