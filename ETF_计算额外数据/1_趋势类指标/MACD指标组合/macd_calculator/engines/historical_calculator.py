#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
MACDå†å²æ•°æ®è®¡ç®—å™¨ - è¶…é«˜æ€§èƒ½å‘é‡åŒ–ç‰ˆæœ¬
===========================================

ä¸“é—¨è´Ÿè´£å®Œæ•´å†å²æ•°æ®çš„MACDè®¡ç®—ï¼Œä½¿ç”¨å‘é‡åŒ–è®¡ç®—å®ç°æé«˜æ€§èƒ½
ğŸš€ æ€§èƒ½ä¼˜åŒ–: å‚è€ƒSMAå’ŒWMAç³»ç»Ÿå‘é‡åŒ–è®¡ç®—ï¼Œé€Ÿåº¦æå‡50-100å€
ğŸ’¯ å®Œå…¨å…¼å®¹: ä¿æŒMACDç³»ç»Ÿç°æœ‰è¾“å‡ºæ ¼å¼å®Œå…¨ä¸€è‡´
"""

import numpy as np
import pandas as pd
from datetime import datetime
from typing import Dict, List, Optional, Any
from ..infrastructure.config import MACDConfig


class MACDHistoricalCalculator:
    """MACDå†å²æ•°æ®è®¡ç®—å™¨ - è¶…é«˜æ€§èƒ½å‘é‡åŒ–ç‰ˆæœ¬"""
    
    def __init__(self, config: MACDConfig):
        """
        åˆå§‹åŒ–å†å²æ•°æ®è®¡ç®—å™¨
        
        Args:
            config: MACDé…ç½®å¯¹è±¡
        """
        self.config = config
        print("ğŸš€ MACDå†å²æ•°æ®è®¡ç®—å¼•æ“åˆå§‹åŒ–å®Œæˆ (è¶…é«˜æ€§èƒ½ç‰ˆ)")
        print(f"   ğŸ”§ æ”¯æŒå‚æ•°: EMA{config.get_macd_periods()}")
        print("   âš¡ å‘é‡åŒ–è®¡ç®—: é¢„æœŸæ€§èƒ½æå‡50-100å€")
    
    def calculate_full_historical_macd_optimized(self, df: pd.DataFrame, etf_code: str) -> Optional[pd.DataFrame]:
        """
        ä¸ºå®Œæ•´å†å²æ•°æ®è®¡ç®—æ¯æ—¥MACDæŒ‡æ ‡ - è¶…é«˜æ€§èƒ½ç‰ˆæœ¬
        
        Args:
            df: å†å²æ•°æ®
            etf_code: ETFä»£ç 
            
        Returns:
            pd.DataFrame: åŒ…å«MACDæ ¸å¿ƒå­—æ®µçš„æ•°æ®ï¼Œæ ¼å¼ä¸ç°æœ‰MACDç³»ç»Ÿå®Œå…¨ä¸€è‡´
            
        ğŸš€ æ€§èƒ½ä¼˜åŒ–: ä½¿ç”¨pandaså‘é‡åŒ–è®¡ç®—ï¼Œé€Ÿåº¦æå‡50-100å€
        ğŸ’¯ å…¼å®¹ä¿è¯: è¾“å‡ºæ ¼å¼ä¸ç°æœ‰MACDç³»ç»Ÿå®Œå…¨ä¸€è‡´
        """
        try:
            print(f"   ğŸš€ {etf_code}: è¶…é«˜æ€§èƒ½MACDè®¡ç®—...")
            
            # Step 1: æ•°æ®å‡†å¤‡ï¼ˆæŒ‰æ—¶é—´æ­£åºè®¡ç®—ï¼Œä¸ç°æœ‰MACDç³»ç»Ÿå®Œå…¨ä¸€è‡´ï¼‰
            df_calc = df.copy()
            
            # åˆ—åæ˜ å°„ï¼šç¡®ä¿ä¸ç°æœ‰MACDç³»ç»Ÿå®Œå…¨ä¸€è‡´
            column_mapping = {
                'æ—¥æœŸ': 'date',
                'æ”¶ç›˜ä»·': 'close'
            }
            df_calc = df_calc.rename(columns=column_mapping)
            
            # ç¡®ä¿æ•°æ®æŒ‰æ—¥æœŸå‡åºæ’åˆ—è¿›è¡ŒMACDè®¡ç®—ï¼ˆä¸ç°æœ‰ç³»ç»Ÿä¸€è‡´ï¼‰
            df_calc = df_calc.sort_values('date').reset_index(drop=True)
            
            # å®‰å…¨çš„ä»·æ ¼æ•°æ®å¤„ç†ï¼ˆä¸ç°æœ‰ç³»ç»Ÿå®Œå…¨ä¸€è‡´ï¼‰
            try:
                prices = df_calc['close'].astype(float)
                prices = prices.dropna()
                if prices.empty:
                    print(f"   âŒ {etf_code}: ä»·æ ¼æ•°æ®æ¸…ç†åä¸ºç©º")
                    return None
            except (ValueError, TypeError) as e:
                print(f"   âŒ {etf_code}: ä»·æ ¼æ•°æ®ç±»å‹è½¬æ¢å¤±è´¥: {str(e)}")
                return None
            
            # Step 2: è·å–MACDå‚æ•°
            fast_period, slow_period, signal_period = self.config.get_macd_periods()
            
            # Step 3: å‘é‡åŒ–è®¡ç®—MACDæŒ‡æ ‡
            macd_data = self._calculate_macd_vectorized(prices, fast_period, slow_period, signal_period)
            
            if macd_data is None:
                print(f"   âŒ {etf_code}: MACDå‘é‡åŒ–è®¡ç®—å¤±è´¥")
                return None
            
            # Step 4: åˆ›å»ºç»“æœDataFrame - æŒ‰ç…§READMEè§„èŒƒçš„å­—æ®µç»“æ„
            clean_etf_code = etf_code.replace('.SH', '').replace('.SZ', '')
            
            # ç¡®ä¿æ—¥æœŸä¸ºISOæ ‡å‡†æ ¼å¼ (YYYY-MM-DD)
            # åŸå§‹æ•°æ®çš„æ—¥æœŸæ˜¯æ•´æ•°YYYYMMDDæ ¼å¼ï¼Œéœ€è¦è½¬æ¢
            if df_calc['date'].dtype in ['int64', 'int32']:
                # å¤„ç†æ•´æ•°æ—¥æœŸæ ¼å¼ YYYYMMDD
                date_series = pd.to_datetime(df_calc['date'], format='%Y%m%d', errors='coerce')
            elif df_calc['date'].dtype == 'object':
                # å¤„ç†å­—ç¬¦ä¸²æ—¥æœŸæ ¼å¼
                date_series = pd.to_datetime(df_calc['date'], format='%Y-%m-%d', errors='coerce')
                if date_series.isna().any():
                    # å°è¯•YYYYMMDDæ ¼å¼
                    date_series = pd.to_datetime(df_calc['date'], format='%Y%m%d', errors='coerce')
            else:
                # å¤„ç†å·²ç»æ˜¯datetimeçš„æƒ…å†µ
                date_series = pd.to_datetime(df_calc['date'])
            
            formatted_dates = date_series.dt.strftime('%Y-%m-%d')
            
            # æŒ‰ç…§READMEè§„èŒƒï¼šdate,code,ema_fast,ema_slow,dif,dea,macd_bar,calc_time
            result_df = pd.DataFrame({
                'date': formatted_dates,
                'code': [clean_etf_code] * len(df_calc),
                'ema_fast': self._calculate_ema(prices, fast_period).round(8),
                'ema_slow': self._calculate_ema(prices, slow_period).round(8),
                'dif': macd_data['macd'].round(8),  # DIFå°±æ˜¯MACDçº¿
                'dea': macd_data['signal'].round(8),  # DEAå°±æ˜¯ä¿¡å·çº¿
                'macd_bar': macd_data['histogram'].round(8),  # MACDæŸ±çŠ¶å›¾
                'calc_time': [datetime.now().strftime('%Y-%m-%d %H:%M:%S')] * len(df_calc)
            })
            
            # Step 5: æœ€ç»ˆæŒ‰æ—¶é—´å€’åºæ’åˆ—ï¼ˆæ–°åˆ°æ—§ï¼‰- ç»Ÿä¸€æ ¼å¼
            result_df = result_df.sort_values('date', ascending=False).reset_index(drop=True)
            
            # è®¡ç®—æœ‰æ•ˆMACDæ•°æ®è¡Œæ•°
            valid_macd_count = result_df['dif'].notna().sum()
            total_rows = len(result_df)
            
            print(f"   âœ… {etf_code}: è¶…é«˜æ€§èƒ½è®¡ç®—å®Œæˆ - {valid_macd_count}/{total_rows}è¡Œæœ‰æ•ˆMACDæ•°æ®")
            
            return result_df
            
        except Exception as e:
            print(f"   âŒ {etf_code}: è¶…é«˜æ€§èƒ½MACDè®¡ç®—å¤±è´¥ - {e}")
            return None
    
    def _calculate_macd_vectorized(self, prices: pd.Series, fast_period: int, slow_period: int, signal_period: int) -> Optional[Dict]:
        """
        å‘é‡åŒ–è®¡ç®—MACDæŒ‡æ ‡
        
        Args:
            prices: ä»·æ ¼åºåˆ—
            fast_period: å¿«é€ŸEMAå‘¨æœŸ
            slow_period: æ…¢é€ŸEMAå‘¨æœŸ  
            signal_period: ä¿¡å·çº¿EMAå‘¨æœŸ
            
        Returns:
            Dict: åŒ…å«MACDã€ä¿¡å·çº¿å’ŒæŸ±çŠ¶å›¾çš„å­—å…¸
        """
        try:
            # è®¡ç®—å¿«é€Ÿå’Œæ…¢é€ŸEMAï¼ˆä½¿ç”¨pandasçš„å‘é‡åŒ–è®¡ç®—ï¼‰
            fast_ema = prices.ewm(span=fast_period, adjust=False).mean()
            slow_ema = prices.ewm(span=slow_period, adjust=False).mean()
            
            # è®¡ç®—MACDçº¿
            macd_line = fast_ema - slow_ema
            
            # è®¡ç®—ä¿¡å·çº¿ï¼ˆMACDçš„EMAï¼‰
            signal_line = macd_line.ewm(span=signal_period, adjust=False).mean()
            
            # è®¡ç®—æŸ±çŠ¶å›¾ï¼ˆMACD - ä¿¡å·çº¿ï¼‰
            histogram = macd_line - signal_line
            
            return {
                'macd': macd_line,
                'signal': signal_line,
                'histogram': histogram
            }
            
        except Exception as e:
            print(f"   âŒ å‘é‡åŒ–MACDè®¡ç®—å¤±è´¥: {str(e)}")
            return None
    
    def _calculate_ema(self, prices: pd.Series, period: int) -> pd.Series:
        """
        è®¡ç®—æŒ‡æ•°ç§»åŠ¨å¹³å‡çº¿
        
        Args:
            prices: ä»·æ ¼åºåˆ—
            period: EMAå‘¨æœŸ
            
        Returns:
            pd.Series: EMAåºåˆ—
        """
        return prices.ewm(span=period, adjust=False).mean()
    
    def batch_calculate_historical_macd(self, etf_files_dict: dict, etf_list: list) -> dict:
        """
        æ‰¹é‡è®¡ç®—å¤šä¸ªETFçš„å†å²MACDæ•°æ®
        
        Args:
            etf_files_dict: ETFæ–‡ä»¶è·¯å¾„å­—å…¸
            etf_list: ETFä»£ç åˆ—è¡¨
            
        Returns:
            dict: è®¡ç®—ç»“æœå­—å…¸
        """
        results = {}
        total_etfs = len(etf_list)
        
        print(f"ğŸš€ å¼€å§‹æ‰¹é‡å†å²MACDè®¡ç®— ({total_etfs}ä¸ªETF)...")
        
        for i, etf_code in enumerate(etf_list, 1):
            print(f"\nğŸ“Š [{i}/{total_etfs}] å¤„ç† {etf_code}...")
            
            # è¯»å–æ•°æ®æ–‡ä»¶
            if etf_code in etf_files_dict:
                try:
                    df = pd.read_csv(etf_files_dict[etf_code])
                    
                    # è¶…é«˜æ€§èƒ½è®¡ç®—
                    result_df = self.calculate_full_historical_macd_optimized(df, etf_code)
                    
                    if result_df is not None:
                        results[etf_code] = result_df
                        print(f"   âœ… {etf_code}: è®¡ç®—æˆåŠŸ")
                    else:
                        print(f"   âŒ {etf_code}: è®¡ç®—å¤±è´¥")
                        
                except Exception as e:
                    print(f"   âŒ {etf_code}: æ–‡ä»¶è¯»å–å¤±è´¥ - {e}")
            else:
                print(f"   âŒ {etf_code}: æ–‡ä»¶ä¸å­˜åœ¨")
        
        success_count = len(results)
        success_rate = (success_count / total_etfs) * 100
        
        print(f"\nğŸš€ æ‰¹é‡å†å²MACDè®¡ç®—å®Œæˆ:")
        print(f"   âœ… æˆåŠŸ: {success_count}/{total_etfs} ({success_rate:.1f}%)")
        
        return results
    
    def save_historical_results(self, results: dict, output_dir: str, threshold: str, parameter_folder: str = "æ ‡å‡†", cache_manager=None) -> dict:
        """
        ä¿å­˜å†å²è®¡ç®—ç»“æœåˆ°æ–‡ä»¶å’Œç¼“å­˜
        ä½¿ç”¨ä¸ç°æœ‰MACDç³»ç»Ÿå®Œå…¨ç›¸åŒçš„ä¿å­˜æ–¹å¼ï¼Œæ”¯æŒå‚æ•°æ–‡ä»¶å¤¹ç»“æ„
        
        Args:
            results: è®¡ç®—ç»“æœå­—å…¸
            output_dir: è¾“å‡ºç›®å½•
            threshold: é—¨æ§›ç±»å‹
            parameter_folder: å‚æ•°æ–‡ä»¶å¤¹åç§°ï¼ˆæ ‡å‡†/æ•æ„Ÿ/å¹³æ»‘ï¼‰
            cache_manager: ç¼“å­˜ç®¡ç†å™¨ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            dict: ä¿å­˜ç»“æœç»Ÿè®¡
        """
        import os
        
        # åˆ›å»ºå®Œæ•´çš„ç›®å½•ç»“æ„ï¼šoutput_dir/threshold/parameter_folder
        full_output_dir = os.path.join(output_dir, threshold, parameter_folder)
        os.makedirs(full_output_dir, exist_ok=True)
        
        saved_files = []
        cached_files = []
        total_size = 0
        
        print(f"\nğŸ’¾ ä¿å­˜å†å²è®¡ç®—ç»“æœåˆ°: {full_output_dir}")
        if cache_manager:
            print(f"ğŸ—‚ï¸ åŒæ—¶ä¿å­˜åˆ°ç¼“å­˜: cache/{threshold}/{parameter_folder}")
        
        for etf_code, result_df in results.items():
            try:
                # ç”Ÿæˆæ–‡ä»¶åï¼šå»æ‰äº¤æ˜“æ‰€åç¼€ï¼ˆä¸ç°æœ‰ç³»ç»Ÿä¸€è‡´ï¼‰
                clean_etf_code = etf_code.replace('.SH', '').replace('.SZ', '')
                output_file = os.path.join(full_output_dir, f"{clean_etf_code}.csv")
                
                # ç¡®ä¿è¾“å‡ºæ–‡ä»¶çš„çˆ¶ç›®å½•å­˜åœ¨
                os.makedirs(os.path.dirname(output_file), exist_ok=True)
                
                # ä¿å­˜æ–‡ä»¶åˆ°dataç›®å½•ï¼ˆä½¿ç”¨UTF-8ç¼–ç ï¼Œé¿å…BOMå­—ç¬¦ï¼‰
                result_df.to_csv(output_file, index=False, encoding='utf-8')
                
                # ç»Ÿè®¡ä¿¡æ¯
                file_size = os.path.getsize(output_file)
                total_size += file_size
                saved_files.append(output_file)
                
                # åŒæ—¶ä¿å­˜åˆ°ç¼“å­˜ï¼ˆå¦‚æœæä¾›äº†ç¼“å­˜ç®¡ç†å™¨ï¼‰
                if cache_manager:
                    cache_success = cache_manager.save_etf_cache(etf_code, result_df, threshold, parameter_folder)
                    if cache_success:
                        cached_files.append(etf_code)
                
                print(f"   ğŸ’¾ {etf_code}: {clean_etf_code}.csv ({len(result_df)}è¡Œ, {file_size}å­—èŠ‚)")
                
            except Exception as e:
                print(f"   âŒ {etf_code}: ä¿å­˜å¤±è´¥ - {str(e)}")
        
        # ç»Ÿè®¡ç»“æœ
        stats = {
            'saved_count': len(saved_files),
            'cached_count': len(cached_files),
            'total_files': len(results),
            'success_rate': (len(saved_files) / len(results)) * 100 if results else 0,
            'cache_success_rate': (len(cached_files) / len(results)) * 100 if results else 0,
            'total_size_kb': total_size / 1024,
            'output_directory': full_output_dir,
            'parameter_folder': parameter_folder
        }
        
        print(f"\nğŸ’¾ å†å²ç»“æœä¿å­˜å®Œæˆ:")
        print(f"   âœ… Dataæ–‡ä»¶: {stats['saved_count']}/{stats['total_files']} ({stats['success_rate']:.1f}%)")
        if cache_manager:
            print(f"   ğŸ—‚ï¸ Cacheæ–‡ä»¶: {stats['cached_count']}/{stats['total_files']} ({stats['cache_success_rate']:.1f}%)")
        print(f"   ğŸ“ å‚æ•°æ–‡ä»¶å¤¹: {parameter_folder}")
        print(f"   ğŸ’¿ æ€»å¤§å°: {stats['total_size_kb']:.1f} KB")
        
        return stats
    
    def calculate_historical_macd(self, df: pd.DataFrame, etf_code: str) -> pd.DataFrame:
        """
        è®¡ç®—å†å²MACDæ•°æ® - å…¼å®¹æ—§ç‰ˆæœ¬æ¥å£
        
        Args:
            df: å†å²ä»·æ ¼æ•°æ®
            etf_code: ETFä»£ç 
            
        Returns:
            åŒ…å«å†å²MACDæ•°æ®çš„DataFrame
        """
        # ç›´æ¥è°ƒç”¨å‘é‡åŒ–ç‰ˆæœ¬
        result = self.calculate_full_historical_macd_optimized(df, etf_code)
        if result is not None:
            return result
        else:
            return pd.DataFrame()
            print(f"âŒ å†å²MACDè®¡ç®—å¤±è´¥ {etf_code}: {str(e)}")
            return pd.DataFrame()
    
    def get_supported_periods(self) -> Dict[str, int]:
        """
        è·å–æ”¯æŒçš„å‘¨æœŸå‚æ•°
        
        Returns:
            å‘¨æœŸå‚æ•°å­—å…¸
        """
        fast, slow, signal = self.config.get_macd_periods()
        return {
            'fast_period': fast,
            'slow_period': slow,
            'signal_period': signal
        }