#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
EMAæ‰¹é‡å¤„ç†å™¨ - é‡æ„ç‰ˆ
====================

å‚ç…§WMA/SMAç³»ç»Ÿçš„æ‰¹é‡å¤„ç†æ¶æ„
æ”¯æŒæ™ºèƒ½ç¼“å­˜ã€å¢é‡æ›´æ–°å’Œæ‰¹é‡ç»“æœä¿å­˜
"""

import os
from datetime import datetime
from typing import Dict, List, Optional, Any
from concurrent.futures import ThreadPoolExecutor, as_completed
from ..infrastructure.config import EMAConfig
from ..infrastructure.cache_manager import EMACacheManager
from .etf_processor import EMAETFProcessor


class EMABatchProcessor:
    """EMAæ‰¹é‡å¤„ç†å™¨ - é‡æ„ç‰ˆï¼ˆä¸WMA/SMAä¿æŒä¸€è‡´ï¼‰"""
    
    def __init__(self, etf_processor: EMAETFProcessor, cache_manager: Optional[EMACacheManager], 
                 config: EMAConfig, enable_cache: bool = True):
        """
        åˆå§‹åŒ–æ‰¹é‡å¤„ç†å™¨
        
        Args:
            etf_processor: ETFå¤„ç†å™¨
            cache_manager: ç¼“å­˜ç®¡ç†å™¨
            config: é…ç½®å¯¹è±¡
            enable_cache: æ˜¯å¦å¯ç”¨ç¼“å­˜
        """
        self.etf_processor = etf_processor
        self.cache_manager = cache_manager
        self.config = config
        self.enable_cache = enable_cache
        
        if not config.performance_mode:
            print("ğŸ“Š EMAæ‰¹é‡å¤„ç†å™¨åˆå§‹åŒ–å®Œæˆ")
            print(f"   ğŸ—‚ï¸ ç¼“å­˜çŠ¶æ€: {'å¯ç”¨' if enable_cache else 'ç¦ç”¨'}")
    
    def process_etf_list(self, etf_codes: List[str], threshold: Optional[str] = None, 
                        include_advanced_analysis: bool = False, max_workers: int = 4) -> List[Dict]:
        """
        æ‰¹é‡å¤„ç†ETFåˆ—è¡¨
        
        Args:
            etf_codes: ETFä»£ç åˆ—è¡¨
            threshold: é—¨æ§›ç±»å‹ï¼ˆç”¨äºç¼“å­˜ç®¡ç†ï¼‰
            include_advanced_analysis: æ˜¯å¦åŒ…å«é«˜çº§åˆ†æ
            max_workers: æœ€å¤§å¹¶è¡Œå·¥ä½œçº¿ç¨‹æ•°
            
        Returns:
            List[Dict]: å¤„ç†ç»“æœåˆ—è¡¨
        """
        try:
            if not self.config.performance_mode:
                print(f"ğŸ“Š å¼€å§‹æ‰¹é‡å¤„ç† {len(etf_codes)} ä¸ªETF...")
            
            results = []
            processing_stats = {
                'cache_hits': 0,
                'incremental_updates': 0,
                'new_calculations': 0,
                'failed_count': 0,
                'cache_hit_rate': 0.0
            }
            
            # å¦‚æœå¯ç”¨ç¼“å­˜ä¸”æœ‰é—¨æ§›ä¿¡æ¯ï¼Œè¿›è¡Œæ™ºèƒ½å¤„ç†
            if self.enable_cache and self.cache_manager and threshold:
                results, processing_stats = self._process_with_cache(
                    etf_codes, threshold, include_advanced_analysis
                )
            else:
                # ä¸ä½¿ç”¨ç¼“å­˜çš„ç›´æ¥å¤„ç†ï¼ˆæ”¯æŒå¹¶è¡Œï¼‰
                results = self._process_without_cache(etf_codes, include_advanced_analysis, max_workers)
                processing_stats['new_calculations'] = len([r for r in results if r.get('success', False)])
                processing_stats['failed_count'] = len([r for r in results if not r.get('success', False)])
            
            # è®¡ç®—ç¼“å­˜å‘½ä¸­ç‡
            total_processed = len(etf_codes)
            if total_processed > 0:
                processing_stats['cache_hit_rate'] = processing_stats['cache_hits'] / total_processed
            
            # æ›´æ–°å¤„ç†ç»Ÿè®¡
            if self.enable_cache and self.cache_manager and threshold:
                self.cache_manager.update_processing_stats(threshold, processing_stats)
            
            if not self.config.performance_mode:
                print(f"âœ… æ‰¹é‡å¤„ç†å®Œæˆ: {len(results)} ä¸ªç»“æœ")
                if self.enable_cache:
                    print(f"   ğŸ’¾ ç¼“å­˜å‘½ä¸­: {processing_stats['cache_hits']}")
                    print(f"   âš¡ å¢é‡æ›´æ–°: {processing_stats['incremental_updates']}")
                    print(f"   ğŸ”„ æ–°è®¡ç®—: {processing_stats['new_calculations']}")
                    print(f"   ğŸ“Š å‘½ä¸­ç‡: {processing_stats['cache_hit_rate']:.1%}")
            
            return results
            
        except Exception as e:
            print(f"âŒ æ‰¹é‡å¤„ç†å¤±è´¥: {str(e)}")
            return []
    
    def _process_with_cache(self, etf_codes: List[str], threshold: str, 
                          include_advanced_analysis: bool) -> tuple[List[Dict], Dict]:
        """
        ä½¿ç”¨ç¼“å­˜çš„æ‰¹é‡å¤„ç†
        
        Args:
            etf_codes: ETFä»£ç åˆ—è¡¨
            threshold: é—¨æ§›ç±»å‹
            include_advanced_analysis: æ˜¯å¦åŒ…å«é«˜çº§åˆ†æ
            
        Returns:
            tuple: (å¤„ç†ç»“æœåˆ—è¡¨, å¤„ç†ç»Ÿè®¡)
        """
        results = []
        processing_stats = {
            'cache_hits': 0,
            'incremental_updates': 0,
            'new_calculations': 0,
            'failed_count': 0
        }
        
        # åˆ†æETFå˜åŒ–æƒ…å†µ
        analysis = self.cache_manager.analyze_etf_changes(etf_codes, threshold)
        
        # å¤„ç†ç›¸åŒçš„ETFï¼ˆæ£€æŸ¥ç¼“å­˜æœ‰æ•ˆæ€§ï¼‰
        for etf_code in analysis['same_etfs']:
            if self._is_cache_valid(etf_code, threshold):
                # ç¼“å­˜å‘½ä¸­
                cached_result = self._load_from_cache(etf_code, threshold)
                if cached_result:
                    results.append(cached_result)
                    processing_stats['cache_hits'] += 1
                    continue
            
            # ç¼“å­˜å¤±æ•ˆï¼Œé‡æ–°è®¡ç®—
            result = self.etf_processor.process_single_etf(etf_code, include_advanced_analysis)
            if result:
                if result.get('success', False):
                    # ä¿å­˜åˆ°ç¼“å­˜
                    self._save_to_cache(etf_code, result, threshold)
                    processing_stats['incremental_updates'] += 1
                else:
                    processing_stats['failed_count'] += 1
                results.append(result)
        
        # å¤„ç†æ–°å¢çš„ETFï¼ˆå…¨é‡è®¡ç®—ï¼‰
        for etf_code in analysis['new_etfs']:
            result = self.etf_processor.process_single_etf(etf_code, include_advanced_analysis)
            if result:
                if result.get('success', False):
                    # ä¿å­˜åˆ°ç¼“å­˜
                    self._save_to_cache(etf_code, result, threshold)
                    processing_stats['new_calculations'] += 1
                else:
                    processing_stats['failed_count'] += 1
                results.append(result)
        
        # æ›´æ–°å¤„ç†ç»Ÿè®¡ä¿¡æ¯
        if self.cache_manager and threshold:
            self.cache_manager.update_processing_stats(threshold, processing_stats)
        
        return results, processing_stats
    
    def _process_without_cache(self, etf_codes: List[str], 
                             include_advanced_analysis: bool, max_workers: int = 4) -> List[Dict]:
        """
        ä¸ä½¿ç”¨ç¼“å­˜çš„æ‰¹é‡å¤„ç†ï¼ˆå¹¶è¡Œä¼˜åŒ–ç‰ˆï¼‰
        
        Args:
            etf_codes: ETFä»£ç åˆ—è¡¨
            include_advanced_analysis: æ˜¯å¦åŒ…å«é«˜çº§åˆ†æ
            max_workers: æœ€å¤§å¹¶è¡Œå·¥ä½œçº¿ç¨‹æ•°
            
        Returns:
            List[Dict]: å¤„ç†ç»“æœåˆ—è¡¨
        """
        results = []
        
        # å¦‚æœETFæ•°é‡è¾ƒå°‘æˆ–ç¦ç”¨æ€§èƒ½æ¨¡å¼ï¼Œä½¿ç”¨ä¸²è¡Œå¤„ç†
        if len(etf_codes) < 10 or not self.config.performance_mode:
            for i, etf_code in enumerate(etf_codes, 1):
                if not self.config.performance_mode:
                    print(f"ğŸ“Š è¿›åº¦: {i}/{len(etf_codes)} - {etf_code}")
                
                result = self.etf_processor.process_single_etf(etf_code, include_advanced_analysis)
                if result:
                    results.append(result)
            return results
        
        # å¹¶è¡Œå¤„ç†ï¼ˆé€‚ç”¨äºå¤§æ‰¹é‡æ•°æ®ï¼‰
        if not self.config.performance_mode:
            print(f"ğŸš€ å¯ç”¨å¹¶è¡Œå¤„ç†: {max_workers} ä¸ªå·¥ä½œçº¿ç¨‹")
        
        completed_count = 0
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_etf = {
                executor.submit(self._process_single_etf_safe, etf_code, include_advanced_analysis): etf_code 
                for etf_code in etf_codes
            }
            
            # æ”¶é›†ç»“æœ
            for future in as_completed(future_to_etf):
                etf_code = future_to_etf[future]
                completed_count += 1
                
                try:
                    result = future.result()
                    if result:
                        results.append(result)
                    
                    if not self.config.performance_mode and completed_count % 10 == 0:
                        print(f"âš¡ å¹¶è¡Œè¿›åº¦: {completed_count}/{len(etf_codes)}")
                        
                except Exception as e:
                    if not self.config.performance_mode:
                        print(f"âŒ {etf_code} å¹¶è¡Œå¤„ç†å¤±è´¥: {str(e)}")
        
        if not self.config.performance_mode:
            print(f"âœ… å¹¶è¡Œå¤„ç†å®Œæˆ: {len(results)}/{len(etf_codes)}")
        
        return results
    
    def _process_single_etf_safe(self, etf_code: str, include_advanced_analysis: bool) -> Optional[Dict]:
        """
        å®‰å…¨çš„å•ETFå¤„ç†ï¼ˆç”¨äºå¹¶è¡Œè°ƒç”¨ï¼‰
        
        Args:
            etf_code: ETFä»£ç 
            include_advanced_analysis: æ˜¯å¦åŒ…å«é«˜çº§åˆ†æ
            
        Returns:
            Optional[Dict]: å¤„ç†ç»“æœ
        """
        try:
            return self.etf_processor.process_single_etf(etf_code, include_advanced_analysis)
        except Exception as e:
            return {
                'etf_code': etf_code,
                'success': False,
                'error': str(e),
                'timestamp': datetime.now().isoformat()
            }
    
    def _is_cache_valid(self, etf_code: str, threshold: str) -> bool:
        """
        æ£€æŸ¥ç¼“å­˜æ˜¯å¦æœ‰æ•ˆ
        
        Args:
            etf_code: ETFä»£ç 
            threshold: é—¨æ§›ç±»å‹
            
        Returns:
            bool: ç¼“å­˜æ˜¯å¦æœ‰æ•ˆ
        """
        try:
            if not self.cache_manager:
                return False
            
            # è·å–æºæ–‡ä»¶è·¯å¾„
            source_file_path = self.config.get_etf_file_path(etf_code)
            
            # ä½¿ç”¨ç¼“å­˜ç®¡ç†å™¨çš„éªŒè¯æ–¹æ³•
            return self.cache_manager.is_cache_valid(etf_code, threshold, source_file_path)
            
        except Exception as e:
            if not self.config.performance_mode:
                print(f"âš ï¸ {etf_code} ç¼“å­˜æœ‰æ•ˆæ€§æ£€æŸ¥å¤±è´¥: {str(e)}")
            return False
    
    def _load_from_cache(self, etf_code: str, threshold: str) -> Optional[Dict]:
        """
        ä»ç¼“å­˜åŠ è½½ETFç»“æœ
        
        Args:
            etf_code: ETFä»£ç 
            threshold: é—¨æ§›ç±»å‹
            
        Returns:
            Optional[Dict]: ç¼“å­˜çš„ç»“æœæˆ–None
        """
        try:
            if not self.cache_manager:
                return None
            
            cached_df = self.cache_manager.load_cached_etf_data(etf_code, threshold)
            if cached_df is None or cached_df.empty:
                return None
            
            # ä»ç¼“å­˜æ•°æ®é‡æ„ç»“æœ
            latest_row = cached_df.iloc[0]  # ç¼“å­˜æ•°æ®æŒ‰æ—¶é—´å€’åºï¼Œç¬¬ä¸€è¡Œæ˜¯æœ€æ–°çš„
            
            # æå–EMAå€¼
            ema_values = {}
            for period in self.config.ema_periods:
                ema_col = f'EMA{period}'
                if ema_col in cached_df.columns:
                    ema_values[f'ema_{period}'] = float(latest_row[ema_col])
            
            # ä»æºæ–‡ä»¶è·å–ä»·æ ¼ä¿¡æ¯ï¼ˆç¼“å­˜æ–‡ä»¶åªåŒ…å«EMAè®¡ç®—å­—æ®µï¼‰
            try:
                source_data = self.etf_processor.data_reader.read_etf_data(etf_code)
                if source_data:
                    source_df, _ = source_data
                    latest_source_row = source_df.iloc[0]  # æœ€æ–°æ•°æ®
                    price_info = {
                        'latest_date': str(latest_row['date']),
                        'latest_price': float(latest_source_row['æ”¶ç›˜ä»·']),
                        'volume': int(latest_source_row['æˆäº¤é‡']) if 'æˆäº¤é‡' in source_df.columns else 0,
                        'high': float(latest_source_row['æœ€é«˜ä»·']) if 'æœ€é«˜ä»·' in source_df.columns else 0,
                        'low': float(latest_source_row['æœ€ä½ä»·']) if 'æœ€ä½ä»·' in source_df.columns else 0,
                        'open': float(latest_source_row['å¼€ç›˜ä»·']) if 'å¼€ç›˜ä»·' in source_df.columns else 0
                    }
                else:
                    # å¦‚æœæ— æ³•è¯»å–æºæ–‡ä»¶ï¼Œä½¿ç”¨é»˜è®¤å€¼
                    price_info = {
                        'latest_date': str(latest_row['date']),
                        'latest_price': 0.0,
                        'volume': 0,
                        'high': 0.0,
                        'low': 0.0,
                        'open': 0.0
                    }
            except Exception as e:
                # å¦‚æœå‡ºé”™ï¼Œä½¿ç”¨é»˜è®¤å€¼
                price_info = {
                    'latest_date': str(latest_row['date']),
                    'latest_price': 0.0,
                    'volume': 0,
                    'high': 0.0,
                    'low': 0.0,
                    'open': 0.0
                }
            
            # æ„å»ºç»“æœ
            result = {
                'etf_code': etf_code,
                'success': True,
                'price_info': price_info,
                'ema_values': ema_values,
                'signals': {'status': 'cached'},
                'total_rows': len(cached_df),
                'data_source': 'cache'
            }
            
            if not self.config.performance_mode:
                print(f"ğŸ’¾ {etf_code}: ä»ç¼“å­˜åŠ è½½")
            
            return result
            
        except Exception as e:
            if not self.config.performance_mode:
                print(f"âŒ {etf_code} ç¼“å­˜åŠ è½½å¤±è´¥: {str(e)}")
            return None
    
    def _save_to_cache(self, etf_code: str, result: Dict, threshold: str) -> bool:
        """
        ä¿å­˜ç»“æœåˆ°ç¼“å­˜
        
        Args:
            etf_code: ETFä»£ç 
            result: å¤„ç†ç»“æœ
            threshold: é—¨æ§›ç±»å‹
            
        Returns:
            bool: æ˜¯å¦ä¿å­˜æˆåŠŸ
        """
        try:
            if not self.cache_manager or not result.get('success', False):
                return False
            
            # è¯»å–å®Œæ•´å†å²æ•°æ®å¹¶è®¡ç®—EMA
            data_result = self.etf_processor.data_reader.read_etf_data(etf_code)
            if not data_result:
                return False
            
            df, _ = data_result
            
            # ä½¿ç”¨EMAå¼•æ“è®¡ç®—å®Œæ•´å†å²æ•°æ®
            full_ema_df = self.etf_processor.ema_engine.calculate_full_historical_ema(df, etf_code)
            if full_ema_df is None:
                return False
            
            # ä¿å­˜åˆ°ç¼“å­˜
            return self.cache_manager.save_etf_cache(etf_code, full_ema_df, threshold)
            
        except Exception as e:
            if not self.config.performance_mode:
                print(f"âŒ {etf_code} ç¼“å­˜ä¿å­˜å¤±è´¥: {str(e)}")
            return False
    
    def save_results_to_files(self, results: List[Dict], output_base_dir: str, 
                            threshold: Optional[str] = None) -> Dict[str, Any]:
        """
        ä¿å­˜æ‰¹é‡å¤„ç†ç»“æœåˆ°æ–‡ä»¶
        
        Args:
            results: å¤„ç†ç»“æœåˆ—è¡¨
            output_base_dir: è¾“å‡ºåŸºç¡€ç›®å½•
            threshold: é—¨æ§›ç±»å‹
            
        Returns:
            Dict[str, Any]: ä¿å­˜ç»Ÿè®¡ä¿¡æ¯
        """
        try:
            if not results or not threshold:
                return {
                    'files_saved': 0,
                    'total_size': 0,
                    'failed_saves': 0
                }
            
            # åˆ›å»ºè¾“å‡ºç›®å½•
            output_dir = os.path.join(output_base_dir, threshold)
            os.makedirs(output_dir, exist_ok=True)
            
            save_stats = {
                'files_saved': 0,
                'total_size': 0,
                'failed_saves': 0,
                'saved_files': []
            }
            
            for result in results:
                if not result.get('success', False):
                    continue
                
                etf_code = result['etf_code']
                
                try:
                    # ç”Ÿæˆå®Œæ•´å†å²æ–‡ä»¶
                    saved_file = self._save_historical_file(etf_code, result, output_dir)
                    
                    if saved_file:
                        file_size = os.path.getsize(saved_file)
                        save_stats['files_saved'] += 1
                        save_stats['total_size'] += file_size
                        save_stats['saved_files'].append(os.path.basename(saved_file))
                        
                        if not self.config.performance_mode:
                            print(f"ğŸ’¾ {etf_code}: å†å²æ–‡ä»¶å·²ä¿å­˜")
                    else:
                        save_stats['failed_saves'] += 1
                        
                except Exception as e:
                    save_stats['failed_saves'] += 1
                    if not self.config.performance_mode:
                        print(f"âŒ {etf_code}: æ–‡ä»¶ä¿å­˜å¤±è´¥ - {str(e)}")
            
            return save_stats
            
        except Exception as e:
            print(f"âŒ æ‰¹é‡æ–‡ä»¶ä¿å­˜å¤±è´¥: {str(e)}")
            return {
                'files_saved': 0,
                'total_size': 0,
                'failed_saves': len(results),
                'error': str(e)
            }
    
    def _save_historical_file(self, etf_code: str, result: Dict, output_dir: str) -> Optional[str]:
        """
        ä¿å­˜å•ä¸ªETFçš„å†å²æ–‡ä»¶
        
        Args:
            etf_code: ETFä»£ç 
            result: å¤„ç†ç»“æœ
            output_dir: è¾“å‡ºç›®å½•
            
        Returns:
            Optional[str]: ä¿å­˜çš„æ–‡ä»¶è·¯å¾„æˆ–None
        """
        try:
            # è¯»å–å®Œæ•´å†å²æ•°æ®
            data_result = self.etf_processor.data_reader.read_etf_data(etf_code)
            if not data_result:
                return None
            
            df, _ = data_result
            
            # è®¡ç®—å®Œæ•´å†å²EMA
            full_ema_df = self.etf_processor.ema_engine.calculate_full_historical_ema(df, etf_code)
            if full_ema_df is None:
                return None
            
            # ä¿å­˜æ–‡ä»¶
            clean_etf_code = etf_code.replace('.SH', '').replace('.SZ', '')
            filename = f"{clean_etf_code}.csv"
            file_path = os.path.join(output_dir, filename)
            
            full_ema_df.to_csv(file_path, index=False, encoding='utf-8')
            
            return file_path
            
        except Exception as e:
            if not self.config.performance_mode:
                print(f"âŒ {etf_code} å†å²æ–‡ä»¶ç”Ÿæˆå¤±è´¥: {str(e)}")
            return None