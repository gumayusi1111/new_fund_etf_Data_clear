#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
EMAç¼“å­˜ç®¡ç†å™¨ - é‡æ„ç‰ˆ
==================

å‚ç…§WMA/SMAç³»ç»Ÿçš„æ™ºèƒ½ç¼“å­˜æ¶æ„
æ”¯æŒå¢é‡æ›´æ–°ã€Metaæ–‡ä»¶ç®¡ç†å’Œæ€§èƒ½ä¼˜åŒ–
"""

import os
import json
import pandas as pd
import numpy as np
from datetime import datetime
from typing import Dict, Optional, List, Any, Set
from .config import EMAConfig
from .utils import normalize_date_format, compare_dates_safely


class EMACacheManager:
    """EMAæ™ºèƒ½ç¼“å­˜ç®¡ç†å™¨ - é‡æ„ç‰ˆï¼ˆä¸WMA/SMAä¿æŒä¸€è‡´ï¼‰"""
    
    def __init__(self, config: Optional[EMAConfig] = None):
        """
        åˆå§‹åŒ–ç¼“å­˜ç®¡ç†å™¨
        
        Args:
            config: EMAé…ç½®å¯¹è±¡
        """
        self.config = config
        
        # ç¼“å­˜ç›®å½•è®¾ç½® - ä¸WMA/SMAä¿æŒä¸€è‡´çš„ç»“æ„
        current_dir = os.path.dirname(__file__)
        self.cache_base_dir = os.path.join(current_dir, "..", "..", "cache")
        self.meta_dir = os.path.join(self.cache_base_dir, "meta")
        
        # ç¡®ä¿ç¼“å­˜ç›®å½•å­˜åœ¨
        self._ensure_cache_directories()
        
        if not (config and config.performance_mode):
            print("ğŸ—‚ï¸ EMAæ™ºèƒ½ç¼“å­˜ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")
            print(f"   ğŸ“ ç¼“å­˜ç›®å½•: {self.cache_base_dir}")
            print(f"   ğŸ“Š Metaç›®å½•: {self.meta_dir}")
    
    def _ensure_cache_directories(self) -> None:
        """ç¡®ä¿ç¼“å­˜ç›®å½•ç»“æ„å­˜åœ¨"""
        directories = [
            self.cache_base_dir,
            self.meta_dir,
            os.path.join(self.cache_base_dir, "3000ä¸‡é—¨æ§›"),
            os.path.join(self.cache_base_dir, "5000ä¸‡é—¨æ§›")
        ]
        
        for directory in directories:
            if not os.path.exists(directory):
                os.makedirs(directory)
    
    def get_cache_dir(self, threshold: str) -> str:
        """è·å–æŒ‡å®šé—¨æ§›çš„ç¼“å­˜ç›®å½•"""
        cache_dir = os.path.join(self.cache_base_dir, threshold)
        os.makedirs(cache_dir, exist_ok=True)
        return cache_dir
    
    def get_meta_file(self, threshold: Optional[str] = None) -> str:
        """è·å–Metaæ–‡ä»¶è·¯å¾„"""
        if threshold:
            return os.path.join(self.meta_dir, f"{threshold}_meta.json")
        else:
            return os.path.join(self.meta_dir, "cache_global_meta.json")
    
    def load_meta(self, threshold: Optional[str] = None) -> Dict:
        """åŠ è½½Metaä¿¡æ¯"""
        meta_file = self.get_meta_file(threshold)
        
        if os.path.exists(meta_file):
            try:
                with open(meta_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception as e:
                print(f"âš ï¸ åŠ è½½Metaå¤±è´¥: {str(e)}")
        
        return self._get_default_meta(threshold)
    
    def _get_default_meta(self, threshold: Optional[str] = None) -> Dict:
        """è·å–é»˜è®¤Metaç»“æ„"""
        if threshold:
            return {
                "threshold": threshold,
                "last_update": "",
                "total_etfs": 0,
                "cached_etfs": [],
                "cache_created": datetime.now().isoformat(),
                "update_history": []
            }
        else:
            return {
                "cache_version": "2.0.0",
                "last_global_update": "",
                "total_cache_size_mb": 0,
                "total_cached_etfs": 0,
                "thresholds": ["3000ä¸‡é—¨æ§›", "5000ä¸‡é—¨æ§›"]
            }
    
    def save_meta(self, meta_data: Dict, threshold: Optional[str] = None) -> bool:
        """ä¿å­˜Metaä¿¡æ¯"""
        try:
            meta_file = self.get_meta_file(threshold)
            with open(meta_file, 'w', encoding='utf-8') as f:
                json.dump(meta_data, f, ensure_ascii=False, indent=2)
            return True
        except Exception as e:
            print(f"âŒ ä¿å­˜Metaå¤±è´¥: {str(e)}")
            return False
    
    def get_cached_etfs(self, threshold: str) -> Set[str]:
        """è·å–å·²ç¼“å­˜çš„ETFä»£ç åˆ—è¡¨"""
        cache_dir = self.get_cache_dir(threshold)
        
        if not os.path.exists(cache_dir):
            return set()
        
        csv_files = [f for f in os.listdir(cache_dir) if f.endswith('.csv')]
        etf_codes = set()
        
        for csv_file in csv_files:
            etf_code = csv_file.replace('.csv', '')
            # æ™ºèƒ½æ·»åŠ äº¤æ˜“æ‰€åç¼€ä»¥åŒ¹é…ç­›é€‰ç»“æœæ ¼å¼
            if not etf_code.endswith(('.SH', '.SZ')):
                if etf_code.startswith('5'):
                    etf_code += '.SH'
                elif etf_code.startswith('1'):
                    etf_code += '.SZ'
            etf_codes.add(etf_code)
        
        return etf_codes
    
    def analyze_etf_changes(self, current_etfs: List[str], threshold: str) -> Dict[str, Set[str]]:
        """åˆ†æETFå˜åŒ–æƒ…å†µ"""
        current_set = set(current_etfs)
        cached_set = self.get_cached_etfs(threshold)
        
        analysis = {
            'same_etfs': current_set & cached_set,     # ç›¸åŒETF - å¢é‡è®¡ç®—
            'new_etfs': current_set - cached_set,      # æ–°å¢ETF - å…¨é‡è®¡ç®—
            'old_etfs': cached_set - current_set       # æ—§ETF - ä¿æŒä¸åŠ¨
        }
        
        if not (self.config and self.config.performance_mode):
            print(f"ğŸ“Š {threshold} ETFå˜åŒ–åˆ†æ:")
            print(f"   ğŸ”„ ç›¸åŒETF: {len(analysis['same_etfs'])} ä¸ª (å¢é‡è®¡ç®—)")
            print(f"   ğŸ†• æ–°å¢ETF: {len(analysis['new_etfs'])} ä¸ª (å…¨é‡è®¡ç®—)")
            print(f"   ğŸ“¦ ä¿ç•™ETF: {len(analysis['old_etfs'])} ä¸ª (ä¿æŒä¸åŠ¨)")
        
        return analysis
    
    def save_etf_cache(self, etf_code: str, df: pd.DataFrame, threshold: str) -> bool:
        """ä¿å­˜ETFç¼“å­˜æ•°æ®"""
        try:
            cache_dir = self.get_cache_dir(threshold)
            clean_etf_code = etf_code.replace('.SH', '').replace('.SZ', '')
            cache_file = os.path.join(cache_dir, f"{clean_etf_code}.csv")
            
            # ç¡®ä¿æ•°æ®æŒ‰æ—¶é—´å€’åºæ’åˆ—ï¼ˆä¸dataè¾“å‡ºä¿æŒä¸€è‡´ï¼‰
            if 'æ—¥æœŸ' in df.columns:
                df = df.sort_values('æ—¥æœŸ', ascending=False).reset_index(drop=True)
            
            df.to_csv(cache_file, index=False, encoding='utf-8')
            
            file_size = os.path.getsize(cache_file)
            if not (self.config and self.config.performance_mode):
                print(f"ğŸ’¾ {etf_code}: ç¼“å­˜å·²ä¿å­˜ ({len(df)}è¡Œ, {file_size} å­—èŠ‚)")
            
            return True
            
        except Exception as e:
            if not (self.config and self.config.performance_mode):
                print(f"âŒ ä¿å­˜{etf_code}ç¼“å­˜å¤±è´¥: {str(e)}")
            return False
    
    def get_cached_etf_latest_date(self, etf_code: str, threshold: str) -> Optional[str]:
        """
        è·å–ç¼“å­˜ä¸­ETFçš„æœ€æ–°æ—¥æœŸ
        
        Args:
            etf_code: ETFä»£ç 
            threshold: é—¨æ§›ç±»å‹
            
        Returns:
            Optional[str]: æœ€æ–°æ—¥æœŸå­—ç¬¦ä¸²(YYYYMMDDæ ¼å¼)ï¼Œæœªæ‰¾åˆ°è¿”å›None
        """
        try:
            cache_dir = self.get_cache_dir(threshold)
            clean_etf_code = etf_code.replace('.SH', '').replace('.SZ', '')
            cache_file = os.path.join(cache_dir, f"{clean_etf_code}.csv")
            
            if not os.path.exists(cache_file):
                return None
            
            # è¯»å–ç¼“å­˜æ–‡ä»¶çš„ç¬¬ä¸€è¡Œï¼ˆé™¤äº†headerï¼‰ï¼Œå› ä¸ºæ˜¯æŒ‰æ—¶é—´å€’åº
            df = pd.read_csv(cache_file, encoding='utf-8', nrows=1)
            
            if df.empty:
                return None
            
            # è·å–ç¬¬ä¸€è¡Œçš„æ—¥æœŸï¼ˆæœ€æ–°æ—¥æœŸï¼‰- å…¼å®¹æ€§æ£€æµ‹
            if 'date' in df.columns:
                latest_date = df.iloc[0]['date']
            elif 'æ—¥æœŸ' in df.columns:
                latest_date = df.iloc[0]['æ—¥æœŸ']
            else:
                raise KeyError("ç¼“å­˜æ–‡ä»¶ä¸­æœªæ‰¾åˆ°æ—¥æœŸå­—æ®µ ('date' æˆ– 'æ—¥æœŸ')")
            
            # å¤„ç†æ—¥æœŸæ ¼å¼è½¬æ¢
            if pd.isna(latest_date):
                return None
            
            # è½¬æ¢ä¸ºå­—ç¬¦ä¸²
            latest_date_str = str(latest_date)
            
            # ä½¿ç”¨ç»Ÿä¸€çš„æ—¥æœŸæ ¼å¼åŒ–å‡½æ•°
            return normalize_date_format(latest_date)
            
        except Exception as e:
            if not (self.config and self.config.performance_mode):
                print(f"âš ï¸ è·å–{etf_code}æœ€æ–°æ—¥æœŸå¤±è´¥: {str(e)}")
            return None

    def load_cached_etf_data(self, etf_code: str, threshold: str) -> Optional[pd.DataFrame]:
        """åŠ è½½ETFçš„ç¼“å­˜æ•°æ®"""
        try:
            cache_dir = self.get_cache_dir(threshold)
            clean_etf_code = etf_code.replace('.SH', '').replace('.SZ', '')
            cache_file = os.path.join(cache_dir, f"{clean_etf_code}.csv")
            
            if not os.path.exists(cache_file):
                return None
            
            df = pd.read_csv(cache_file, encoding='utf-8')
            if df.empty:
                return None
            
            # å­—æ®µåå…¼å®¹æ€§å¤„ç†ï¼šæ ‡å‡†åŒ–ä¸ºè‹±æ–‡å­—æ®µå
            if 'æ—¥æœŸ' in df.columns and 'date' not in df.columns:
                df = df.rename(columns={'æ—¥æœŸ': 'date'})
            
            return df
            
        except Exception as e:
            print(f"âŒ åŠ è½½{etf_code}ç¼“å­˜æ•°æ®å¤±è´¥: {str(e)}")
            return None
    
    def is_cache_valid_optimized(self, etf_code: str, threshold: str, source_file_path: str) -> bool:
        """
        ä¼˜åŒ–çš„ç¼“å­˜æœ‰æ•ˆæ€§æ£€æŸ¥ - æ”¯æŒå¢é‡æ›´æ–°
        
        Args:
            etf_code: ETFä»£ç 
            threshold: é—¨æ§›ç±»å‹
            source_file_path: æºæ–‡ä»¶è·¯å¾„
            
        Returns:
            bool: ç¼“å­˜æ˜¯å¦æœ‰æ•ˆ
        """
        try:
            cache_dir = self.get_cache_dir(threshold)
            clean_etf_code = etf_code.replace('.SH', '').replace('.SZ', '')
            cache_file_path = os.path.join(cache_dir, f"{clean_etf_code}.csv")
            
            # æ£€æŸ¥ç¼“å­˜æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not os.path.exists(cache_file_path):
                return False
            
            if not os.path.exists(source_file_path):
                return False
            
            # æ£€æŸ¥ç¼“å­˜æ•°æ®å®Œæ•´æ€§
            try:
                cache_df = pd.read_csv(cache_file_path)
                if cache_df.empty:
                    return False
                
                # æ£€æŸ¥å¿…è¦çš„EMAåˆ—æ˜¯å¦å­˜åœ¨
                required_ema_columns = [f'EMA{period}' for period in (self.config.ema_periods if self.config else [12, 26])]
                ema_columns = [col for col in cache_df.columns if col.startswith('EMA')]
                
                if len(ema_columns) == 0:
                    return False
                
                # æ£€æŸ¥ç¼“å­˜ä¸­çš„æœ€æ–°æ•°æ®æ—¥æœŸ
                cache_latest_date = self.get_cached_etf_latest_date(etf_code, threshold)
                if not cache_latest_date:
                    return False
                
                # æ£€æŸ¥æºæ–‡ä»¶çš„æœ€æ–°æ—¥æœŸ
                source_df = pd.read_csv(source_file_path, nrows=2)  # åªè¯»å–å‰2è¡Œæé«˜æ€§èƒ½
                if source_df.empty:
                    return False
                    
                # æºæ–‡ä»¶æ˜¯æŒ‰æ—¶é—´å€’åºæ’åˆ—ï¼Œæœ€æ–°æ•°æ®åœ¨ç¬¬ä¸€è¡Œï¼ˆé™¤äº†headerï¼‰
                source_latest_date = source_df.iloc[0]['æ—¥æœŸ']
                
                # ä½¿ç”¨ç»Ÿä¸€çš„æ—¥æœŸæ¯”è¾ƒå‡½æ•°
                return compare_dates_safely(cache_latest_date, source_latest_date)
                
            except Exception as e:
                if not (self.config and self.config.performance_mode):
                    print(f"âš ï¸ ç¼“å­˜éªŒè¯è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {etf_code} - {str(e)}")
                return False
            
        except Exception as e:
            if not (self.config and self.config.performance_mode):
                print(f"âš ï¸ ç¼“å­˜æœ‰æ•ˆæ€§æ£€æŸ¥å¤±è´¥: {etf_code} - {str(e)}")
            return False

    def is_cache_valid(self, etf_code: str, threshold: str, source_file_path: str) -> bool:
        """æ£€æŸ¥ç¼“å­˜æ˜¯å¦æœ‰æ•ˆ - ä½¿ç”¨ä¼˜åŒ–ç‰ˆæœ¬"""
        return self.is_cache_valid_optimized(etf_code, threshold, source_file_path)
    
    def get_cache_file_path(self, etf_code: str, threshold: str) -> str:
        """è·å–ç¼“å­˜æ–‡ä»¶è·¯å¾„"""
        cache_dir = self.get_cache_dir(threshold)
        clean_etf_code = etf_code.replace('.SH', '').replace('.SZ', '')
        return os.path.join(cache_dir, f"{clean_etf_code}.csv")
    
    def update_processing_stats(self, threshold: str, stats: Dict) -> None:
        """æ›´æ–°å¤„ç†ç»Ÿè®¡ä¿¡æ¯"""
        try:
            meta = self.load_meta(threshold)
            
            if "processing_stats" not in meta:
                meta["processing_stats"] = {}
            
            meta["processing_stats"].update(stats)
            meta["last_update"] = datetime.now().isoformat()
            
            update_record = {
                "timestamp": datetime.now().isoformat(),
                "processing_stats": stats.copy()
            }
            
            if "update_history" not in meta:
                meta["update_history"] = []
            
            meta["update_history"].append(update_record)
            
            if len(meta["update_history"]) > 10:
                meta["update_history"] = meta["update_history"][-10:]
            
            self.save_meta(meta, threshold)
            
            # è‡ªåŠ¨æ›´æ–°å…¨å±€ç¼“å­˜å…ƒæ•°æ®
            self._update_global_cache_meta()
            
        except Exception as e:
            print(f"âŒ ç»Ÿè®¡ä¿¡æ¯æ›´æ–°å¤±è´¥: {str(e)}")
    
    def _update_global_cache_meta(self) -> None:
        """è‡ªåŠ¨æ›´æ–°å…¨å±€ç¼“å­˜å…ƒæ•°æ®"""
        try:
            # è®¡ç®—æ€»ç¼“å­˜å¤§å°å’ŒETFæ•°é‡
            total_size_bytes = 0
            total_etfs = 0
            
            for threshold in ["3000ä¸‡é—¨æ§›", "5000ä¸‡é—¨æ§›"]:
                cache_dir = self.get_cache_dir(threshold)
                if os.path.exists(cache_dir):
                    for file in os.listdir(cache_dir):
                        if file.endswith('.csv'):
                            file_path = os.path.join(cache_dir, file)
                            total_size_bytes += os.path.getsize(file_path)
                            total_etfs += 1
            
            # æ›´æ–°å…¨å±€å…ƒæ•°æ®
            global_meta = {
                "cache_version": "2.0.0",
                "last_global_update": datetime.now().isoformat(),
                "total_cache_size_mb": round(total_size_bytes / 1024 / 1024, 2),
                "total_cached_etfs": total_etfs,
                "thresholds": ["3000ä¸‡é—¨æ§›", "5000ä¸‡é—¨æ§›"]
            }
            
            self.save_meta(global_meta, None)
            
        except Exception as e:
            print(f"âš ï¸ å…¨å±€ç¼“å­˜å…ƒæ•°æ®æ›´æ–°å¤±è´¥: {str(e)}")