#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ‰¹é‡å¤„ç†å™¨
=========

è´Ÿè´£ETFæ‰¹é‡å¤„ç†å’Œæ™ºèƒ½ç¼“å­˜é€»è¾‘
"""

import os
import pandas as pd
from datetime import datetime
from typing import Dict, List, Optional, Set
from .etf_processor import ETFProcessor
from ..infrastructure.cache_manager import SMACacheManager
from ..outputs.csv_handler import CSVOutputHandler


class BatchProcessor:
    """æ‰¹é‡å¤„ç†å™¨ - è´Ÿè´£ETFæ‰¹é‡å¤„ç†å’Œç¼“å­˜ç®¡ç†"""
    
    def __init__(self, etf_processor: ETFProcessor, cache_manager: Optional[SMACacheManager] = None, 
                 csv_handler: Optional[CSVOutputHandler] = None, enable_cache: bool = True):
        """
        åˆå§‹åŒ–æ‰¹é‡å¤„ç†å™¨
        
        Args:
            etf_processor: ETFå¤„ç†å™¨
            cache_manager: ç¼“å­˜ç®¡ç†å™¨
            csv_handler: CSVå¤„ç†å™¨
            enable_cache: æ˜¯å¦å¯ç”¨ç¼“å­˜
        """
        self.etf_processor = etf_processor
        self.cache_manager = cache_manager
        self.csv_handler = csv_handler
        self.enable_cache = enable_cache
    
    def process_etf_list(self, etf_codes: List[str], threshold: str, 
                        include_advanced_analysis: bool = False) -> List[Dict]:
        """
        æ‰¹é‡å¤„ç†ETFåˆ—è¡¨
        
        Args:
            etf_codes: ETFä»£ç åˆ—è¡¨
            threshold: é—¨æ§›ç±»å‹
            include_advanced_analysis: æ˜¯å¦åŒ…å«é«˜çº§åˆ†æ
            
        Returns:
            List[Dict]: å¤„ç†ç»“æœåˆ—è¡¨
        """
        if self.enable_cache and self.cache_manager:
            return self._process_with_cache(etf_codes, threshold, include_advanced_analysis)
        else:
            return self._process_without_cache(etf_codes, include_advanced_analysis)
    
    def _process_with_cache(self, etf_codes: List[str], threshold: str, 
                           include_advanced_analysis: bool) -> List[Dict]:
        """ç¼“å­˜æ¨¡å¼å¤„ç†"""
        print(f"\n============================================================")
        print(f"ğŸ”„ å¤„ç†{threshold}ç­›é€‰ç»“æœ (æ™ºèƒ½ç¼“å­˜æ¨¡å¼)")
        print(f"============================================================")
        
        # åˆ†æETFå˜åŒ–
        analysis = self.cache_manager.analyze_etf_changes(etf_codes, threshold)
        
        results = []
        processing_stats = {
            'total_processed': len(etf_codes),
            'cache_hits': 0,
            'incremental_updates': 0,
            'new_calculations': 0,
            'success_count': 0,
            'failed_count': 0,
            'cache_hit_rate': 0
        }
        
        # å¤„ç†ç›¸åŒETFï¼ˆå¢é‡è®¡ç®—ï¼‰
        if analysis['same_etfs']:
            print(f"\nğŸ”„ å¢é‡å¤„ç† {len(analysis['same_etfs'])} ä¸ªç›¸åŒETF...")
            for etf_code in analysis['same_etfs']:
                result = self._process_cached_etf(etf_code, threshold)
                if result:
                    results.append(result)
                    processing_stats['success_count'] += 1
                    if result.get('data_source') == 'cache':
                        processing_stats['cache_hits'] += 1
                    else:
                        processing_stats['incremental_updates'] += 1
                else:
                    processing_stats['failed_count'] += 1
        
        # å¤„ç†æ–°å¢ETFï¼ˆå…¨é‡è®¡ç®—ï¼‰
        if analysis['new_etfs']:
            print(f"\nğŸ†• å…¨é‡å¤„ç† {len(analysis['new_etfs'])} ä¸ªæ–°å¢ETF...")
            for etf_code in analysis['new_etfs']:
                result = self._process_new_etf(etf_code, threshold, include_advanced_analysis)
                if result:
                    results.append(result)
                    processing_stats['success_count'] += 1
                    processing_stats['new_calculations'] += 1
                else:
                    processing_stats['failed_count'] += 1
        
        # è®¡ç®—ç¼“å­˜å‘½ä¸­ç‡ï¼ˆå®‰å…¨é™¤æ³•ï¼‰
        total_processed = processing_stats['total_processed']
        cache_hits = processing_stats['cache_hits']
        
        if total_processed > 0 and cache_hits >= 0:
            processing_stats['cache_hit_rate'] = cache_hits / total_processed
        else:
            processing_stats['cache_hit_rate'] = 0.0
        
        # æ›´æ–°é—¨æ§›Meta
        self.cache_manager.update_threshold_meta(threshold, analysis, processing_stats)
        
        print(f"\nğŸ“Š å¤„ç†ç»Ÿè®¡:")
        print(f"   ğŸ’¾ ç¼“å­˜å‘½ä¸­: {processing_stats['cache_hits']} ä¸ª")
        print(f"   âš¡ å¢é‡æ›´æ–°: {processing_stats['incremental_updates']} ä¸ª") 
        print(f"   ğŸ†• æ–°å¢è®¡ç®—: {processing_stats['new_calculations']} ä¸ª")
        print(f"   âœ… æˆåŠŸ: {processing_stats['success_count']} ä¸ª")
        print(f"   âŒ å¤±è´¥: {processing_stats['failed_count']} ä¸ª")
        print(f"   ğŸ“ˆ ç¼“å­˜å‘½ä¸­ç‡: {processing_stats['cache_hit_rate']:.1%}")
        
        return results
    
    def _process_without_cache(self, etf_codes: List[str], include_advanced_analysis: bool) -> List[Dict]:
        """æ— ç¼“å­˜æ¨¡å¼å¤„ç†"""
        print(f"\nğŸ”„ å¤„ç† {len(etf_codes)} ä¸ªETF (æ— ç¼“å­˜æ¨¡å¼)...")
        
        results = []
        for i, etf_code in enumerate(etf_codes, 1):
            print(f"   [{i}/{len(etf_codes)}] ğŸ”„ {etf_code}: è®¡ç®—ä¸­...")
            
            result = self.etf_processor.process_single_etf(etf_code, include_advanced_analysis)
            if result:
                results.append(result)
                print(f"   [{i}/{len(etf_codes)}] âœ… {etf_code}: è®¡ç®—å®Œæˆ")
            else:
                print(f"   [{i}/{len(etf_codes)}] âŒ {etf_code}: è®¡ç®—å¤±è´¥")
        
        return results
    
    def _process_cached_etf(self, etf_code: str, threshold: str) -> Optional[Dict]:
        """å¤„ç†ç¼“å­˜ä¸­çš„ETF"""
        try:
            # å°è¯•ä»ç¼“å­˜åŠ è½½
            cached_result = self._load_from_cache(etf_code, threshold)
            if cached_result:
                latest_date = self.cache_manager.get_cached_etf_latest_date(etf_code, threshold)
                print(f"   ğŸ’¾ {etf_code}: ä½¿ç”¨ç¼“å­˜ (æœ€æ–°: {latest_date})")
                return cached_result
            
            # ç¼“å­˜å¤±æ•ˆï¼Œè¿›è¡Œå¢é‡æ›´æ–°
            result = self._process_incremental_etf(etf_code, threshold)
            if result:
                print(f"   âš¡ {etf_code}: å¢é‡æ›´æ–°å®Œæˆ")
                return result
            
            return None
            
        except Exception as e:
            print(f"   âŒ {etf_code}: ç¼“å­˜å¤„ç†å¤±è´¥: {str(e)}")
            return None
    
    def _process_new_etf(self, etf_code: str, threshold: str, include_advanced_analysis: bool) -> Optional[Dict]:
        """å¤„ç†æ–°ETF"""
        try:
            # å…¨é‡è®¡ç®—
            result = self.etf_processor.process_single_etf(etf_code, include_advanced_analysis)
            
            if result and result.get('historical_data') is not None:
                # ä¿å­˜åˆ°ç¼“å­˜
                historical_data = result['historical_data']
                success = self.cache_manager.save_etf_cache(etf_code, historical_data, threshold)
                if not success:
                    print(f"   âš ï¸ {etf_code}: ç¼“å­˜ä¿å­˜å¤±è´¥")
            
            return result
            
        except Exception as e:
            print(f"   âŒ {etf_code}: æ–°ETFå¤„ç†å¤±è´¥: {str(e)}")
            return None
    
    def _process_incremental_etf(self, etf_code: str, threshold: str) -> Optional[Dict]:
        """å¢é‡æ›´æ–°ETF"""
        try:
            # æ­£å¸¸è®¡ç®—SMA
            result = self.etf_processor.process_single_etf(etf_code)
            
            if result and result.get('historical_data') is not None:
                # å¢é‡æ›´æ–°ç¼“å­˜
                historical_data = result['historical_data']
                success = self.cache_manager.save_etf_cache(etf_code, historical_data, threshold)
                if not success:
                    print(f"   âš ï¸ {etf_code}: ç¼“å­˜æ›´æ–°å¤±è´¥")
            
            return result
            
        except Exception as e:
            print(f"   âŒ {etf_code}: å¢é‡æ›´æ–°å¤±è´¥: {str(e)}")
            return None
    
    def _load_from_cache(self, etf_code: str, threshold: str) -> Optional[Dict]:
        """ä»ç¼“å­˜åŠ è½½ETFç»“æœ"""
        try:
            cached_df = self.cache_manager.load_cached_etf_data(etf_code, threshold)
            
            if cached_df is None or cached_df.empty:
                return None
            
            # ä»ç¼“å­˜æ•°æ®æ„å»ºç»“æœå¯¹è±¡ï¼ˆå®‰å…¨è®¿é—®ï¼‰
            if len(cached_df) == 0:
                return None
                
            latest_row = cached_df.iloc[0]  # ç¬¬ä¸€è¡Œæ˜¯æœ€æ–°æ•°æ®
            
            # æ„å»ºæœ€æ–°ä»·æ ¼ä¿¡æ¯
            latest_price = {
                'date': str(latest_row['date']),
                'close': float(latest_row['SMA_5']) if pd.notna(latest_row['SMA_5']) else 0.0,
                'change_pct': 0.0  # ä»ç¼“å­˜æš‚æ—¶æ— æ³•è®¡ç®—æ¶¨è·Œå¹…
            }
            
            # æ„å»ºSMAå€¼
            sma_values = {}
            for period in self.etf_processor.config.sma_periods:
                sma_col = f'SMA_{period}'
                if sma_col in cached_df.columns:
                    sma_val = latest_row[sma_col]
                    if pd.notna(sma_val):
                        sma_values[f'SMA_{period}'] = float(sma_val)
            
            # å·®å€¼æŒ‡æ ‡
            diff_cols = {
                'SMA_DIFF_5_20': 'SMA_DIFF_5_20',
                'SMA_DIFF_5_10': 'SMA_DIFF_5_10', 
                'SMA_DIFF_5_20_PCT': 'SMA_DIFF_5_20_PCT'
            }
            
            for cache_col, result_key in diff_cols.items():
                if cache_col in cached_df.columns:
                    diff_val = latest_row[cache_col]
                    if pd.notna(diff_val):
                        sma_values[result_key] = float(diff_val)
            
            # æ„å»ºç»“æœå¯¹è±¡
            result = {
                'etf_code': etf_code,
                'adj_type': self.etf_processor.config.adj_type,
                'latest_price': latest_price,
                'sma_values': sma_values,
                'signals': {'status': 'from_cache'},
                'processing_time': datetime.now().isoformat(),
                'data_source': 'cache',
                'historical_data': cached_df
            }
            
            return result
            
        except Exception as e:
            print(f"   âŒ {etf_code}: ç¼“å­˜åŠ è½½å¤±è´¥: {str(e)}")
            return None
    
    def save_results_to_files(self, results: List[Dict], output_dir: str, threshold: str) -> Dict:
        """ä¿å­˜ç»“æœåˆ°æ–‡ä»¶"""
        save_stats = {
            'files_saved': 0,
            'total_size': 0,
            'failed_saves': 0
        }
        
        print(f"\nğŸ“ ä¿å­˜{threshold}ç»“æœ...")
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        threshold_dir = os.path.join(output_dir, threshold)
        os.makedirs(threshold_dir, exist_ok=True)
        
        # ä¸ºæ¯ä¸ªETFä¿å­˜å†å²æ•°æ®æ–‡ä»¶
        for result in results:
            etf_code = result['etf_code']
            
            # æ£€æŸ¥æ˜¯å¦æœ‰å†å²æ•°æ®
            if 'historical_data' in result and result['historical_data'] is not None:
                historical_data = result['historical_data']
                
                # ç”ŸæˆCSVæ–‡ä»¶
                clean_etf_code = etf_code.replace('.SH', '').replace('.SZ', '')
                output_file = os.path.join(threshold_dir, f"{clean_etf_code}.csv")
                
                try:
                    # ä¿å­˜å†å²æ•°æ®æ–‡ä»¶
                    historical_data.to_csv(output_file, index=False, encoding='utf-8-sig')
                    
                    file_size = os.path.getsize(output_file)
                    save_stats['files_saved'] += 1
                    save_stats['total_size'] += file_size
                    
                    rows_count = len(historical_data)
                    print(f"   ğŸ’¾ {etf_code}: {clean_etf_code}.csv ({rows_count}è¡Œ, {file_size} å­—èŠ‚)")
                    
                except Exception as e:
                    print(f"   âŒ {etf_code}: ä¿å­˜å¤±è´¥ - {str(e)}")
                    save_stats['failed_saves'] += 1
            else:
                print(f"   âŒ {etf_code}: æ— å†å²æ•°æ®")
                save_stats['failed_saves'] += 1
        
        return save_stats 