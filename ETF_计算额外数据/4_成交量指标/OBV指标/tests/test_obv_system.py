#!/usr/bin/env python3
"""
OBVæŒ‡æ ‡ç³»ç»Ÿæµ‹è¯•å¥—ä»¶
=================

å…¨é¢çš„å•å…ƒæµ‹è¯•å’Œé›†æˆæµ‹è¯•
éªŒè¯ç³»ç»Ÿå„ç»„ä»¶åŠŸèƒ½æ­£ç¡®æ€§å’Œæ€§èƒ½æŒ‡æ ‡

æµ‹è¯•è¦†ç›–:
- OBVè®¡ç®—å¼•æ“Žæµ‹è¯•
- ç¼“å­˜ç®¡ç†å™¨æµ‹è¯•  
- æ•°æ®è¯»å–å™¨æµ‹è¯•
- ä¸»æŽ§åˆ¶å™¨æµ‹è¯•
- ç³»ç»Ÿé›†æˆæµ‹è¯•

è¿è¡Œæµ‹è¯•:
    python test_obv_system.py
    python test_obv_system.py --verbose
    python test_obv_system.py --component engine
"""

import unittest
import sys
import tempfile
import shutil
from pathlib import Path
from datetime import datetime, timedelta
import pandas as pd
import numpy as np
import argparse
import logging

# æ·»åŠ é¡¹ç›®è·¯å¾„
current_dir = Path(__file__).parent
project_dir = current_dir.parent
sys.path.insert(0, str(project_dir))

from obv_calculator.engines.obv_engine import OBVEngine
from obv_calculator.infrastructure.cache_manager import OBVCacheManager, CacheMetadata
from obv_calculator.infrastructure.data_reader import OBVDataReader
from obv_calculator.infrastructure.config import OBVConfig
from obv_calculator.controllers.main_controller import OBVController
from obv_calculator.outputs.csv_handler import OBVCSVHandler

class TestOBVEngine(unittest.TestCase):
    """OBVè®¡ç®—å¼•æ“Žæµ‹è¯•"""
    
    def setUp(self):
        """æµ‹è¯•å‰å‡†å¤‡"""
        self.engine = OBVEngine(precision=8)
        self.sample_data = self._create_sample_data()
    
    def _create_sample_data(self) -> pd.DataFrame:
        """åˆ›å»ºæµ‹è¯•ç”¨æ ·æœ¬æ•°æ®"""
        dates = pd.date_range('2025-01-01', periods=30, freq='D')
        np.random.seed(42)  # å›ºå®šéšæœºç§å­ç¡®ä¿æµ‹è¯•ç»“æžœä¸€è‡´
        
        # æ¨¡æ‹ŸETFä»·æ ¼å’Œæˆäº¤é‡æ•°æ®
        base_price = 10.0
        prices = []
        volumes = []
        
        for i in range(30):
            # ä»·æ ¼éšæœºæ¸¸èµ°
            change = np.random.normal(0, 0.02)  # 2%æ ‡å‡†å·®
            price = base_price * (1 + change)
            base_price = price
            prices.append(round(price, 2))
            
            # æˆäº¤é‡éšæœºç”Ÿæˆ
            volume = np.random.randint(10000, 100000)
            volumes.append(volume)
        
        return pd.DataFrame({
            'ä»£ç ': ['159001'] * 30,
            'æ—¥æœŸ': dates.strftime('%Y-%m-%d'),
            'æ”¶ç›˜ä»·': prices,
            'æˆäº¤é‡(æ‰‹æ•°)': volumes,
            'æˆäº¤é¢(åƒå…ƒ)': [p * v / 100 for p, v in zip(prices, volumes)]
        })
    
    def test_obv_calculation_basic(self):
        """æµ‹è¯•åŸºæœ¬OBVè®¡ç®—"""
        result = self.engine.calculate_obv_batch(self.sample_data)
        
        self.assertTrue(result['success'], "OBVè®¡ç®—åº”è¯¥æˆåŠŸ")
        self.assertIn('data', result, "ç»“æžœåº”åŒ…å«æ•°æ®")
        
        data = result['data']
        self.assertFalse(data.empty, "è®¡ç®—ç»“æžœä¸åº”ä¸ºç©º")
        self.assertEqual(len(data), len(self.sample_data), "è¾“å‡ºè®°å½•æ•°åº”ä¸Žè¾“å…¥ä¸€è‡´")
        
        # éªŒè¯å­—æ®µå­˜åœ¨
        required_fields = ['code', 'date', 'obv', 'obv_ma10', 'obv_change_5', 'obv_change_20']
        for field in required_fields:
            self.assertIn(field, data.columns, f"åº”åŒ…å«å­—æ®µ: {field}")
    
    def test_obv_calculation_precision(self):
        """æµ‹è¯•OBVè®¡ç®—ç²¾åº¦"""
        result = self.engine.calculate_obv_batch(self.sample_data)
        data = result['data']
        
        # æ£€æŸ¥æ•°å€¼ç²¾åº¦
        for _, row in data.iterrows():
            obv_str = f"{row['obv']:.8f}"
            self.assertEqual(len(obv_str.split('.')[-1]), 8, "OBVç²¾åº¦åº”ä¸º8ä½å°æ•°")
    
    def test_obv_calculation_logic(self):
        """æµ‹è¯•OBVè®¡ç®—é€»è¾‘æ­£ç¡®æ€§"""
        # åˆ›å»ºç®€å•çš„æµ‹è¯•æ•°æ®
        simple_data = pd.DataFrame({
            'ä»£ç ': ['TEST'] * 5,
            'æ—¥æœŸ': ['2025-01-01', '2025-01-02', '2025-01-03', '2025-01-04', '2025-01-05'],
            'æ”¶ç›˜ä»·': [10.0, 10.5, 10.2, 10.8, 10.1],  # ä¸Šæ¶¨ã€ä¸‹è·Œã€ä¸Šæ¶¨ã€ä¸‹è·Œ
            'æˆäº¤é‡(æ‰‹æ•°)': [1000, 2000, 1500, 2500, 1200],
            'æˆäº¤é¢(åƒå…ƒ)': [100, 210, 153, 270, 121.2]
        })
        
        result = self.engine.calculate_obv_batch(simple_data)
        data = result['data']
        
        # éªŒè¯OBVé€»è¾‘
        # ç¬¬ä¸€å¤©: OBV = 1000 (åˆå§‹å€¼)
        # ç¬¬äºŒå¤©: ä»·æ ¼ä¸Šæ¶¨, OBV = 1000 + 2000 = 3000
        # ç¬¬ä¸‰å¤©: ä»·æ ¼ä¸‹è·Œ, OBV = 3000 - 1500 = 1500
        # ç¬¬å››å¤©: ä»·æ ¼ä¸Šæ¶¨, OBV = 1500 + 2500 = 4000
        # ç¬¬äº”å¤©: ä»·æ ¼ä¸‹è·Œ, OBV = 4000 - 1200 = 2800
        
        expected_obvs = [1000, 3000, 1500, 4000, 2800]
        actual_obvs = data['obv'].tolist()
        
        for i, (expected, actual) in enumerate(zip(expected_obvs, actual_obvs)):
            self.assertAlmostEqual(actual, expected, places=2, 
                                 msg=f"ç¬¬{i+1}å¤©OBVè®¡ç®—é”™è¯¯")
    
    def test_incremental_calculation(self):
        """æµ‹è¯•å¢žé‡è®¡ç®—åŠŸèƒ½"""
        # åˆ†å‰²æ•°æ®æµ‹è¯•å¢žé‡è®¡ç®—
        historical_data = self.sample_data[:20]
        new_data = self.sample_data[20:]
        
        # å…ˆè®¡ç®—åŽ†å²æ•°æ®
        historical_result = self.engine.calculate_obv_batch(historical_data)
        self.assertTrue(historical_result['success'])
        
        # å¢žé‡è®¡ç®—æ–°æ•°æ®
        incremental_result = self.engine.calculate_obv_incremental(
            historical_result['data'], new_data
        )
        
        self.assertTrue(incremental_result['success'], "å¢žé‡è®¡ç®—åº”è¯¥æˆåŠŸ")
        self.assertTrue(incremental_result.get('incremental', False), "åº”æ ‡è®°ä¸ºå¢žé‡è®¡ç®—")
    
    def test_data_validation(self):
        """æµ‹è¯•æ•°æ®éªŒè¯åŠŸèƒ½"""
        # æµ‹è¯•ç©ºæ•°æ®
        empty_data = pd.DataFrame()
        validation = self.engine.validate_input_data(empty_data)
        self.assertFalse(validation['valid'], "ç©ºæ•°æ®åº”éªŒè¯å¤±è´¥")
        
        # æµ‹è¯•ç¼ºå°‘å­—æ®µ
        incomplete_data = self.sample_data.drop('æ”¶ç›˜ä»·', axis=1)
        validation = self.engine.validate_input_data(incomplete_data)
        self.assertFalse(validation['valid'], "ç¼ºå°‘å¿…éœ€å­—æ®µåº”éªŒè¯å¤±è´¥")
        
        # æµ‹è¯•æ­£å¸¸æ•°æ®
        validation = self.engine.validate_input_data(self.sample_data)
        self.assertTrue(validation['valid'], "æ­£å¸¸æ•°æ®åº”éªŒè¯é€šè¿‡")

class TestCacheManager(unittest.TestCase):
    """ç¼“å­˜ç®¡ç†å™¨æµ‹è¯•"""
    
    def setUp(self):
        """æµ‹è¯•å‰å‡†å¤‡"""
        self.temp_dir = Path(tempfile.mkdtemp())
        self.cache_dir = self.temp_dir / "cache"
        self.meta_dir = self.temp_dir / "meta"
        
        self.cache_manager = OBVCacheManager(
            cache_dir=self.cache_dir,
            meta_dir=self.meta_dir,
            expire_days=30
        )
        
        self.test_data = pd.DataFrame({
            'code': ['159001'] * 3,
            'date': ['2025-01-01', '2025-01-02', '2025-01-03'],
            'obv': [1000.12345678, 2000.87654321, 1500.55555555],
            'obv_ma10': [1000.0, 1500.0, 1833.33],
            'obv_change_5': [0.0, 100.0, -25.0],
            'obv_change_20': [0.0, 50.0, 12.5],
            'calc_time': ['2025-07-27 12:00:00'] * 3
        })
    
    def tearDown(self):
        """æµ‹è¯•åŽæ¸…ç†"""
        shutil.rmtree(self.temp_dir, ignore_errors=True)
    
    def test_save_and_load_cache(self):
        """æµ‹è¯•ç¼“å­˜ä¿å­˜å’ŒåŠ è½½"""
        etf_code = "159001"
        threshold = "3000ä¸‡é—¨æ§›"
        
        # ä¿å­˜ç¼“å­˜
        success = self.cache_manager.save_cache(etf_code, threshold, self.test_data)
        self.assertTrue(success, "ç¼“å­˜ä¿å­˜åº”è¯¥æˆåŠŸ")
        
        # åŠ è½½ç¼“å­˜
        loaded_data = self.cache_manager.load_cache(etf_code, threshold)
        self.assertIsNotNone(loaded_data, "åº”è¯¥èƒ½åŠ è½½ç¼“å­˜æ•°æ®")
        self.assertEqual(len(loaded_data), len(self.test_data), "åŠ è½½çš„æ•°æ®é•¿åº¦åº”ä¸€è‡´")
        
        # éªŒè¯æ•°æ®å†…å®¹
        pd.testing.assert_frame_equal(loaded_data, self.test_data, "ç¼“å­˜æ•°æ®åº”ä¸ŽåŽŸæ•°æ®ä¸€è‡´")
    
    def test_cache_validation(self):
        """æµ‹è¯•ç¼“å­˜æœ‰æ•ˆæ€§éªŒè¯"""
        etf_code = "159001"
        threshold = "3000ä¸‡é—¨æ§›"
        
        # ä¿å­˜ç¼“å­˜
        self.cache_manager.save_cache(etf_code, threshold, self.test_data)
        
        # éªŒè¯æœ‰æ•ˆæ€§
        is_valid = self.cache_manager.is_cache_valid(etf_code, threshold)
        self.assertTrue(is_valid, "æ–°ä¿å­˜çš„ç¼“å­˜åº”è¯¥æœ‰æ•ˆ")
        
        # æµ‹è¯•æ•°æ®æ—¥æœŸæ›´æ–°
        is_valid_with_newer_date = self.cache_manager.is_cache_valid(
            etf_code, threshold, "2025-01-04"
        )
        self.assertFalse(is_valid_with_newer_date, "æœ‰æ›´æ–°æ•°æ®æ—¶ç¼“å­˜åº”è¯¥æ— æ•ˆ")
    
    def test_incremental_update(self):
        """æµ‹è¯•å¢žé‡æ›´æ–°"""
        etf_code = "159001"
        threshold = "3000ä¸‡é—¨æ§›"
        
        # ä¿å­˜åˆå§‹ç¼“å­˜
        self.cache_manager.save_cache(etf_code, threshold, self.test_data)
        
        # åˆ›å»ºæ–°å¢žæ•°æ®
        new_data = pd.DataFrame({
            'code': ['159001'] * 2,
            'date': ['2025-01-04', '2025-01-05'],
            'obv': [1800.11111111, 2200.99999999],
            'obv_ma10': [1900.0, 2000.0],
            'obv_change_5': [20.0, 22.2],
            'obv_change_20': [15.0, 18.5],
            'calc_time': ['2025-07-27 13:00:00'] * 2
        })
        
        # å¢žé‡æ›´æ–°
        success = self.cache_manager.update_cache_incremental(etf_code, threshold, new_data)
        self.assertTrue(success, "å¢žé‡æ›´æ–°åº”è¯¥æˆåŠŸ")
        
        # éªŒè¯æ›´æ–°åŽçš„æ•°æ®
        updated_data = self.cache_manager.load_cache(etf_code, threshold)
        self.assertEqual(len(updated_data), 5, "æ›´æ–°åŽåº”æœ‰5æ¡è®°å½•")
    
    def test_cache_statistics(self):
        """æµ‹è¯•ç¼“å­˜ç»Ÿè®¡åŠŸèƒ½"""
        # ä¿å­˜ä¸€äº›æµ‹è¯•ç¼“å­˜
        for i in range(3):
            etf_code = f"15900{i+1}"
            self.cache_manager.save_cache(etf_code, "3000ä¸‡é—¨æ§›", self.test_data)
        
        # èŽ·å–ç»Ÿè®¡ä¿¡æ¯
        stats = self.cache_manager.get_cache_statistics()
        
        self.assertNotIn('error', stats, "èŽ·å–ç»Ÿè®¡ä¿¡æ¯ä¸åº”å‡ºé”™")
        self.assertIn('performance', stats, "åº”åŒ…å«æ€§èƒ½ç»Ÿè®¡")
        self.assertIn('storage', stats, "åº”åŒ…å«å­˜å‚¨ç»Ÿè®¡")
        
        # éªŒè¯æ–‡ä»¶æ•°é‡
        storage = stats['storage']
        self.assertEqual(storage['cache_files'], 3, "åº”æœ‰3ä¸ªç¼“å­˜æ–‡ä»¶")

class TestDataReader(unittest.TestCase):
    """æ•°æ®è¯»å–å™¨æµ‹è¯•"""
    
    def setUp(self):
        """æµ‹è¯•å‰å‡†å¤‡"""
        self.temp_dir = Path(tempfile.mkdtemp())
        self.data_reader = OBVDataReader(source_dir=self.temp_dir)
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®æ–‡ä»¶
        self._create_test_files()
    
    def tearDown(self):
        """æµ‹è¯•åŽæ¸…ç†"""
        shutil.rmtree(self.temp_dir, ignore_errors=True)
    
    def _create_test_files(self):
        """åˆ›å»ºæµ‹è¯•ç”¨çš„CSVæ–‡ä»¶"""
        # åˆ›å»ºETFæ•°æ®æ–‡ä»¶
        test_etfs = ['159001', '159002', '159003']
        
        for etf_code in test_etfs:
            data = pd.DataFrame({
                'ä»£ç ': [etf_code] * 25,
                'æ—¥æœŸ': pd.date_range('2025-01-01', periods=25, freq='D').strftime('%Y-%m-%d'),
                'å¼€ç›˜ä»·': np.random.uniform(9.5, 10.5, 25),
                'æœ€é«˜ä»·': np.random.uniform(10.0, 11.0, 25),
                'æœ€ä½Žä»·': np.random.uniform(9.0, 10.0, 25),
                'æ”¶ç›˜ä»·': np.random.uniform(9.5, 10.5, 25),
                'æˆäº¤é‡(æ‰‹æ•°)': np.random.randint(10000, 100000, 25),
                'æˆäº¤é¢(åƒå…ƒ)': np.random.uniform(5000, 50000, 25)
            })
            
            file_path = self.temp_dir / f"{etf_code}.csv"
            data.to_csv(file_path, index=False, encoding='utf-8')
    
    def test_read_single_etf(self):
        """æµ‹è¯•è¯»å–å•ä¸ªETFæ•°æ®"""
        etf_code = "159001"
        data = self.data_reader.read_etf_data(etf_code)
        
        self.assertIsNotNone(data, "åº”è¯¥èƒ½è¯»å–åˆ°æ•°æ®")
        self.assertFalse(data.empty, "æ•°æ®ä¸åº”ä¸ºç©º")
        self.assertEqual(len(data), 25, "åº”æœ‰25æ¡è®°å½•")
        
        # éªŒè¯å¿…éœ€å­—æ®µ
        required_fields = ['ä»£ç ', 'æ—¥æœŸ', 'æ”¶ç›˜ä»·', 'æˆäº¤é‡(æ‰‹æ•°)']
        for field in required_fields:
            self.assertIn(field, data.columns, f"åº”åŒ…å«å­—æ®µ: {field}")
    
    def test_batch_read(self):
        """æµ‹è¯•æ‰¹é‡è¯»å–åŠŸèƒ½"""
        etf_codes = ['159001', '159002']
        data = self.data_reader.read_batch_etf_data(etf_codes)
        
        self.assertFalse(data.empty, "æ‰¹é‡è¯»å–ç»“æžœä¸åº”ä¸ºç©º")
        self.assertEqual(len(data), 50, "åº”æœ‰50æ¡è®°å½•(2ä¸ªETF Ã— 25æ¡)")
        
        # éªŒè¯æ•°æ®åŒ…å«æŒ‡å®šçš„ETF
        unique_codes = data['ä»£ç '].unique()
        self.assertEqual(len(unique_codes), 2, "åº”åŒ…å«2ä¸ªETF")
        for code in etf_codes:
            self.assertIn(code, unique_codes, f"åº”åŒ…å«ETF: {code}")
    
    def test_data_availability_check(self):
        """æµ‹è¯•æ•°æ®å¯ç”¨æ€§æ£€æŸ¥"""
        etf_codes = ['159001', '159002', '999999']  # æœ€åŽä¸€ä¸ªä¸å­˜åœ¨
        availability = self.data_reader.check_data_availability(etf_codes)
        
        self.assertEqual(availability['total_codes'], 3, "æ€»ä»£ç æ•°åº”ä¸º3")
        self.assertEqual(availability['available_count'], 2, "å¯ç”¨ä»£ç æ•°åº”ä¸º2")
        self.assertEqual(len(availability['missing_codes']), 1, "ç¼ºå¤±ä»£ç æ•°åº”ä¸º1")
        self.assertIn('999999', availability['missing_codes'], "999999åº”åœ¨ç¼ºå¤±åˆ—è¡¨ä¸­")
    
    def test_date_filtering(self):
        """æµ‹è¯•æ—¥æœŸè¿‡æ»¤åŠŸèƒ½"""
        etf_code = "159001"
        data = self.data_reader.read_etf_data(
            etf_code, 
            start_date='2025-01-10', 
            end_date='2025-01-15'
        )
        
        self.assertIsNotNone(data, "åº”è¯¥èƒ½è¯»å–åˆ°è¿‡æ»¤åŽçš„æ•°æ®")
        self.assertEqual(len(data), 6, "åº”æœ‰6æ¡è®°å½•(2025-01-10åˆ°2025-01-15)")
        
        # éªŒè¯æ—¥æœŸèŒƒå›´
        min_date = data['æ—¥æœŸ'].min()
        max_date = data['æ—¥æœŸ'].max()
        self.assertGreaterEqual(min_date, '2025-01-10', "æœ€å°æ—¥æœŸåº”>=å¼€å§‹æ—¥æœŸ")
        self.assertLessEqual(max_date, '2025-01-15', "æœ€å¤§æ—¥æœŸåº”<=ç»“æŸæ—¥æœŸ")

class TestMainController(unittest.TestCase):
    """ä¸»æŽ§åˆ¶å™¨æµ‹è¯•"""
    
    def setUp(self):
        """æµ‹è¯•å‰å‡†å¤‡"""
        # åˆ›å»ºä¸´æ—¶æµ‹è¯•çŽ¯å¢ƒ
        self.temp_dir = Path(tempfile.mkdtemp())
        
        # åˆ›å»ºè‡ªå®šä¹‰é…ç½®
        self.config = OBVConfig()
        self.config.BASE_DIR = self.temp_dir
        self.config.DATA_DIR = self.temp_dir / "data"
        self.config.CACHE_DIR = self.temp_dir / "cache"
        self.config.LOGS_DIR = self.temp_dir / "logs"
        self.config.CACHE_META_DIR = self.temp_dir / "cache" / "meta"
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®æº
        self.source_dir = self.temp_dir / "source"
        self.source_dir.mkdir(parents=True)
        self.config.ETF_SOURCE_DIR = self.source_dir
        
        # åˆ›å»ºæµ‹è¯•ETFæ•°æ®
        self._create_test_source_data()
        
        # åˆå§‹åŒ–æŽ§åˆ¶å™¨
        self.controller = OBVController(self.config)
    
    def tearDown(self):
        """æµ‹è¯•åŽæ¸…ç†"""
        shutil.rmtree(self.temp_dir, ignore_errors=True)
    
    def _create_test_source_data(self):
        """åˆ›å»ºæµ‹è¯•ç”¨çš„æºæ•°æ®"""
        etf_code = "159001"
        data = pd.DataFrame({
            'ä»£ç ': [etf_code] * 30,
            'æ—¥æœŸ': pd.date_range('2025-01-01', periods=30, freq='D').strftime('%Y-%m-%d'),
            'æ”¶ç›˜ä»·': np.random.uniform(9.5, 10.5, 30),
            'æˆäº¤é‡(æ‰‹æ•°)': np.random.randint(10000, 100000, 30),
            'æˆäº¤é¢(åƒå…ƒ)': np.random.uniform(30000, 80000, 30)  # ç¡®ä¿æ»¡è¶³é—¨æ§›è¦æ±‚
        })
        
        file_path = self.source_dir / f"{etf_code}.csv"
        data.to_csv(file_path, index=False, encoding='utf-8')
    
    def test_single_etf_calculation(self):
        """æµ‹è¯•å•ETFè®¡ç®—"""
        etf_code = "159001"
        threshold = "3000ä¸‡é—¨æ§›"
        
        result = self.controller.calculate_single_etf(etf_code, threshold)
        
        self.assertTrue(result['success'], f"å•ETFè®¡ç®—åº”è¯¥æˆåŠŸ: {result.get('error', '')}")
        self.assertEqual(result['etf_code'], etf_code, "è¿”å›žçš„ETFä»£ç åº”ä¸€è‡´")
        self.assertEqual(result['threshold'], threshold, "è¿”å›žçš„é—¨æ§›ç±»åž‹åº”ä¸€è‡´")
        self.assertGreater(result['data_points'], 0, "åº”æœ‰æ•°æ®ç‚¹")
        self.assertGreater(result['processing_time'], 0, "å¤„ç†æ—¶é—´åº”å¤§äºŽ0")
    
    def test_cache_functionality(self):
        """æµ‹è¯•ç¼“å­˜åŠŸèƒ½"""
        etf_code = "159001"
        threshold = "3000ä¸‡é—¨æ§›"
        
        # ç¬¬ä¸€æ¬¡è®¡ç®—(æ— ç¼“å­˜)
        result1 = self.controller.calculate_single_etf(etf_code, threshold)
        self.assertTrue(result1['success'])
        self.assertFalse(result1.get('cache_hit', True), "ç¬¬ä¸€æ¬¡è®¡ç®—ä¸åº”å‘½ä¸­ç¼“å­˜")
        
        # ç¬¬äºŒæ¬¡è®¡ç®—(åº”å‘½ä¸­ç¼“å­˜)
        result2 = self.controller.calculate_single_etf(etf_code, threshold)
        self.assertTrue(result2['success'])
        self.assertTrue(result2.get('cache_hit', False), "ç¬¬äºŒæ¬¡è®¡ç®—åº”å‘½ä¸­ç¼“å­˜")
        
        # å¼ºåˆ¶é‡æ–°è®¡ç®—
        result3 = self.controller.calculate_single_etf(etf_code, threshold, force_recalculate=True)
        self.assertTrue(result3['success'])
        self.assertFalse(result3.get('cache_hit', True), "å¼ºåˆ¶é‡æ–°è®¡ç®—ä¸åº”å‘½ä¸­ç¼“å­˜")
    
    def test_system_status(self):
        """æµ‹è¯•ç³»ç»ŸçŠ¶æ€èŽ·å–"""
        status = self.controller.get_system_status()
        
        self.assertNotIn('error', status, "èŽ·å–ç³»ç»ŸçŠ¶æ€ä¸åº”å‡ºé”™")
        self.assertIn('system_info', status, "åº”åŒ…å«ç³»ç»Ÿä¿¡æ¯")
        self.assertIn('performance', status, "åº”åŒ…å«æ€§èƒ½ä¿¡æ¯")
        self.assertIn('components', status, "åº”åŒ…å«ç»„ä»¶ä¿¡æ¯")
        
        # éªŒè¯ç³»ç»Ÿä¿¡æ¯
        system_info = status['system_info']
        self.assertEqual(system_info['name'], 'OBVæŒ‡æ ‡è®¡ç®—ç³»ç»Ÿ', "ç³»ç»Ÿåç§°åº”æ­£ç¡®")
        self.assertEqual(system_info['status'], 'RUNNING', "ç³»ç»ŸçŠ¶æ€åº”ä¸ºè¿è¡Œä¸­")
    
    def test_system_testing(self):
        """æµ‹è¯•ç³»ç»Ÿè‡ªæµ‹åŠŸèƒ½"""
        test_results = self.controller.test_system(sample_size=1)
        
        self.assertIn('success', test_results, "æµ‹è¯•ç»“æžœåº”åŒ…å«æˆåŠŸæ ‡å¿—")
        self.assertIn('tests', test_results, "åº”åŒ…å«å…·ä½“æµ‹è¯•é¡¹")
        self.assertIn('summary', test_results, "åº”åŒ…å«æµ‹è¯•æ‘˜è¦")
        
        # éªŒè¯æµ‹è¯•æ‘˜è¦
        summary = test_results['summary']
        self.assertIn('total_tests', summary, "æ‘˜è¦åº”åŒ…å«æ€»æµ‹è¯•æ•°")
        self.assertIn('passed_tests', summary, "æ‘˜è¦åº”åŒ…å«é€šè¿‡æµ‹è¯•æ•°")

class TestSystemIntegration(unittest.TestCase):
    """ç³»ç»Ÿé›†æˆæµ‹è¯•"""
    
    def setUp(self):
        """æµ‹è¯•å‰å‡†å¤‡"""
        self.temp_dir = Path(tempfile.mkdtemp())
        
        # åˆ›å»ºå®Œæ•´çš„æµ‹è¯•çŽ¯å¢ƒ
        self.config = OBVConfig()
        self.config.BASE_DIR = self.temp_dir
        self.config.init_directories()
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®æº
        self.source_dir = self.temp_dir / "source"
        self.source_dir.mkdir(parents=True)
        self.config.ETF_SOURCE_DIR = self.source_dir
        
        self._create_comprehensive_test_data()
        
        self.controller = OBVController(self.config)
    
    def tearDown(self):
        """æµ‹è¯•åŽæ¸…ç†"""
        shutil.rmtree(self.temp_dir, ignore_errors=True)
    
    def _create_comprehensive_test_data(self):
        """åˆ›å»ºç»¼åˆæµ‹è¯•æ•°æ®"""
        etf_codes = ['159001', '159002', '159003']
        
        for etf_code in etf_codes:
            # åˆ›å»ºä¸åŒç‰¹å¾çš„æ•°æ®
            if etf_code == '159001':
                # å¤§æˆäº¤é¢ETF
                amounts = np.random.uniform(50000, 100000, 25)
            elif etf_code == '159002':
                # ä¸­ç­‰æˆäº¤é¢ETF
                amounts = np.random.uniform(25000, 60000, 25)
            else:
                # å°æˆäº¤é¢ETF(ä¸æ»¡è¶³5000ä¸‡é—¨æ§›)
                amounts = np.random.uniform(10000, 40000, 25)
            
            data = pd.DataFrame({
                'ä»£ç ': [etf_code] * 25,
                'æ—¥æœŸ': pd.date_range('2025-01-01', periods=25, freq='D').strftime('%Y-%m-%d'),
                'æ”¶ç›˜ä»·': np.random.uniform(9.5, 10.5, 25),
                'æˆäº¤é‡(æ‰‹æ•°)': np.random.randint(10000, 100000, 25),
                'æˆäº¤é¢(åƒå…ƒ)': amounts
            })
            
            file_path = self.source_dir / f"{etf_code}.csv"
            data.to_csv(file_path, index=False, encoding='utf-8')
    
    def test_complete_workflow(self):
        """æµ‹è¯•å®Œæ•´å·¥ä½œæµç¨‹"""
        # 1. ç³»ç»Ÿåˆå§‹åŒ–æµ‹è¯•
        status = self.controller.get_system_status()
        self.assertEqual(status['system_info']['status'], 'RUNNING')
        
        # 2. å•ETFè®¡ç®—æµ‹è¯•(3000ä¸‡é—¨æ§›)
        result_3000 = self.controller.calculate_single_etf('159001', '3000ä¸‡é—¨æ§›')
        self.assertTrue(result_3000['success'])
        
        # 3. å•ETFè®¡ç®—æµ‹è¯•(5000ä¸‡é—¨æ§›)
        result_5000 = self.controller.calculate_single_etf('159001', '5000ä¸‡é—¨æ§›')
        self.assertTrue(result_5000['success'])
        
        # 4. éªŒè¯é—¨æ§›ç­›é€‰æ•ˆæžœ
        # 159003çš„æˆäº¤é¢è¾ƒå°ï¼Œå¯èƒ½ä¸æ»¡è¶³5000ä¸‡é—¨æ§›
        result_small = self.controller.calculate_single_etf('159003', '5000ä¸‡é—¨æ§›')
        # ç»“æžœå¯èƒ½æˆåŠŸä¹Ÿå¯èƒ½å¤±è´¥ï¼Œå–å†³äºŽéšæœºç”Ÿæˆçš„æ•°æ®
        
        # 5. ç¼“å­˜æµ‹è¯•
        result_cached = self.controller.calculate_single_etf('159001', '3000ä¸‡é—¨æ§›')
        self.assertTrue(result_cached['success'])
        self.assertTrue(result_cached.get('cache_hit', False))
        
        # 6. ç³»ç»Ÿæ¸…ç†æµ‹è¯•
        cleanup_result = self.controller.cleanup_system()
        self.assertTrue(cleanup_result['success'])
    
    def test_error_handling(self):
        """æµ‹è¯•é”™è¯¯å¤„ç†"""
        # æµ‹è¯•ä¸å­˜åœ¨çš„ETF
        result = self.controller.calculate_single_etf('999999', '3000ä¸‡é—¨æ§›')
        self.assertFalse(result['success'])
        self.assertIn('error', result)
        
        # æµ‹è¯•æ— æ•ˆé—¨æ§›
        result = self.controller.calculate_single_etf('159001', 'æ— æ•ˆé—¨æ§›')
        self.assertFalse(result['success'])
        
        # æµ‹è¯•ç©ºETFä»£ç 
        result = self.controller.calculate_single_etf('', '3000ä¸‡é—¨æ§›')
        self.assertFalse(result['success'])
    
    def test_performance_benchmark(self):
        """æµ‹è¯•æ€§èƒ½åŸºå‡†"""
        import time
        
        start_time = time.time()
        
        # æ‰§è¡Œå¤šä¸ªè®¡ç®—ä»»åŠ¡
        results = []
        for etf_code in ['159001', '159002']:
            for threshold in ['3000ä¸‡é—¨æ§›', '5000ä¸‡é—¨æ§›']:
                result = self.controller.calculate_single_etf(etf_code, threshold)
                results.append(result)
        
        end_time = time.time()
        total_time = end_time - start_time
        
        # æ€§èƒ½è¦æ±‚: 4ä¸ªä»»åŠ¡åº”åœ¨10ç§’å†…å®Œæˆ
        self.assertLess(total_time, 10.0, "æ€§èƒ½æµ‹è¯•: 4ä¸ªä»»åŠ¡åº”åœ¨10ç§’å†…å®Œæˆ")
        
        # æˆåŠŸçŽ‡è¦æ±‚: è‡³å°‘50%ä»»åŠ¡æˆåŠŸ
        success_count = sum(1 for r in results if r.get('success', False))
        success_rate = success_count / len(results)
        self.assertGreaterEqual(success_rate, 0.5, "è‡³å°‘50%çš„ä»»åŠ¡åº”è¯¥æˆåŠŸ")

def run_tests(component=None, verbose=False):
    """è¿è¡Œæµ‹è¯•å¥—ä»¶"""
    # è®¾ç½®æ—¥å¿—çº§åˆ«
    if verbose:
        logging.basicConfig(level=logging.DEBUG)
    else:
        logging.basicConfig(level=logging.WARNING)
    
    # åˆ›å»ºæµ‹è¯•å¥—ä»¶
    loader = unittest.TestLoader()
    suite = unittest.TestSuite()
    
    # æ ¹æ®å‚æ•°åŠ è½½æµ‹è¯•
    if component:
        component_map = {
            'engine': TestOBVEngine,
            'cache': TestCacheManager,
            'reader': TestDataReader,
            'controller': TestMainController,
            'integration': TestSystemIntegration
        }
        
        if component in component_map:
            suite.addTests(loader.loadTestsFromTestCase(component_map[component]))
        else:
            print(f"âŒ æœªçŸ¥ç»„ä»¶: {component}")
            print(f"å¯ç”¨ç»„ä»¶: {', '.join(component_map.keys())}")
            return False
    else:
        # åŠ è½½æ‰€æœ‰æµ‹è¯•
        test_classes = [
            TestOBVEngine,
            TestCacheManager, 
            TestDataReader,
            TestMainController,
            TestSystemIntegration
        ]
        
        for test_class in test_classes:
            suite.addTests(loader.loadTestsFromTestCase(test_class))
    
    # è¿è¡Œæµ‹è¯•
    runner = unittest.TextTestRunner(
        verbosity=2 if verbose else 1,
        stream=sys.stdout,
        buffer=True
    )
    
    print("ðŸš€ å¯åŠ¨OBVæŒ‡æ ‡ç³»ç»Ÿæµ‹è¯•...")
    print("=" * 60)
    
    result = runner.run(suite)
    
    # è¾“å‡ºæµ‹è¯•æ€»ç»“
    print("\n" + "=" * 60)
    print("ðŸ“‹ æµ‹è¯•æ€»ç»“:")
    print(f"  è¿è¡Œæµ‹è¯•: {result.testsRun}")
    print(f"  æˆåŠŸ: {result.testsRun - len(result.failures) - len(result.errors)}")
    print(f"  å¤±è´¥: {len(result.failures)}")
    print(f"  é”™è¯¯: {len(result.errors)}")
    
    if result.failures:
        print(f"\nâŒ å¤±è´¥çš„æµ‹è¯•:")
        for test, traceback in result.failures:
            print(f"  - {test}: {traceback.split('AssertionError: ')[-1].split('\\n')[0]}")
    
    if result.errors:
        print(f"\nðŸ”¥ é”™è¯¯çš„æµ‹è¯•:")
        for test, traceback in result.errors:
            print(f"  - {test}: {traceback.split('\\n')[-2]}")
    
    success = len(result.failures) == 0 and len(result.errors) == 0
    
    if success:
        print(f"\nâœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡!")
    else:
        print(f"\nâŒ å­˜åœ¨æµ‹è¯•å¤±è´¥!")
    
    return success

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='OBVæŒ‡æ ‡ç³»ç»Ÿæµ‹è¯•å¥—ä»¶')
    parser.add_argument('--component', '-c', 
                       choices=['engine', 'cache', 'reader', 'controller', 'integration'],
                       help='æŒ‡å®šè¦æµ‹è¯•çš„ç»„ä»¶')
    parser.add_argument('--verbose', '-v', action='store_true', help='è¯¦ç»†è¾“å‡º')
    
    args = parser.parse_args()
    
    success = run_tests(component=args.component, verbose=args.verbose)
    sys.exit(0 if success else 1)

if __name__ == '__main__':
    main()