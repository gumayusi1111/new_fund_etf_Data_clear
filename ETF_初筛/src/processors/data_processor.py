#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ETFæ•°æ®å¤„ç†å™¨
è´Ÿè´£åè°ƒæ•´ä¸ªç­›é€‰æµç¨‹ï¼Œç®¡ç†ç­›é€‰å™¨é“¾ï¼Œå¤„ç†ç­›é€‰ç»“æœ
"""

import pandas as pd
from typing import Dict, List, Any, Optional
from datetime import datetime

from ..data_loader import ETFDataLoader
from ..filters import VolumeFilter, QualityFilter, FilterResult
from ..utils.config import get_config
from ..utils.logger import get_logger, ProcessTimer


class ETFDataProcessor:
    """ETFæ•°æ®å¤„ç†å™¨ä¸»ç±»"""
    
    def __init__(self, threshold_name: str = "5000ä¸‡é—¨æ§›"):
        self.config = get_config()
        self.logger = get_logger()
        self.data_loader = ETFDataLoader()
        self.threshold_name = threshold_name
        
        # åˆå§‹åŒ–ç­›é€‰å™¨
        self._init_filters()
        
    def _init_filters(self):
        """åˆå§‹åŒ–ç­›é€‰å™¨é“¾"""
        # æ„å»ºæ–°çš„é…ç½®ç»“æ„
        filter_config_data = {
            "æµåŠ¨æ€§é—¨æ§›": self.config.get_liquidity_thresholds(),
            "ä»·æ ¼è´¨é‡æ ‡å‡†": self.config.get_price_quality_standards(),
            "æ•°æ®è´¨é‡è¦æ±‚": self.config.get_data_quality_requirements(),
            "å¼‚å¸¸æ³¢åŠ¨é˜ˆå€¼": self.config.get_volatility_thresholds(),
            "ç­›é€‰é…ç½®": self.config.get_filter_config()
        }
        
        self.filters = {
            "ä»·æ ¼è´¨é‡": QualityFilter(filter_config_data),
            "æµåŠ¨æ€§é—¨æ§›": VolumeFilter(filter_config_data, self.threshold_name)
        }
        
        self.logger.info(f"âœ… åˆå§‹åŒ– {len(self.filters)} ä¸ªç­›é€‰å™¨")
    
    def process_all_etfs(self, fuquan_type: str = "0_ETFæ—¥K(å‰å¤æƒ)", 
                        days_back: int = None, fast_mode: bool = False,
                        max_workers: int = None) -> Dict[str, Any]:
        """
        å¤„ç†æ‰€æœ‰ETFæ•°æ®çš„å®Œæ•´ç­›é€‰æµç¨‹
        
        Args:
            fuquan_type: å¤æƒç±»å‹
            days_back: åŠ è½½æœ€è¿‘Nå¤©çš„æ•°æ®
            fast_mode: å¯ç”¨å¿«é€Ÿæ¨¡å¼ï¼ˆå¹¶è¡ŒåŠ è½½ï¼‰
            max_workers: æœ€å¤§å¹¶è¡Œå·¥ä½œæ•°
        
        Returns:
            å®Œæ•´çš„å¤„ç†ç»“æœ
        """
        with ProcessTimer("ETFåˆç­›å¤„ç†", self.logger):
            # 1. åŠ è½½æ•°æ®
            etf_codes = self.data_loader.get_available_etf_codes(fuquan_type)
            
            if not etf_codes:
                self.logger.error(f"âŒ æœªå‘ç°å¯ç”¨çš„ETFæ•°æ®")
                return {"error": "æ— å¯ç”¨æ•°æ®"}
            
            self.logger.info(f"ğŸ“Š å‘ç° {len(etf_codes)} ä¸ªETFï¼Œå¼€å§‹åŠ è½½æ•°æ®...")
            
            # æ ¹æ®å¿«é€Ÿæ¨¡å¼é€‰æ‹©åŠ è½½æ–¹å¼
            if fast_mode:
                etf_data = self.data_loader.load_multiple_etfs(
                    etf_codes, fuquan_type, days_back, max_workers=max_workers
                )
            else:
                etf_data = self.data_loader.load_multiple_etfs(
                    etf_codes, fuquan_type, days_back, max_workers=1
                )
            
            if not etf_data:
                self.logger.error(f"âŒ æ•°æ®åŠ è½½å¤±è´¥")
                return {"error": "æ•°æ®åŠ è½½å¤±è´¥"}
            
            # 2. æ‰§è¡Œç­›é€‰
            filter_results = self._run_filter_chain(etf_data)
            
            # 3. ç”Ÿæˆæœ€ç»ˆç»“æœ
            final_results = self._generate_final_results(filter_results)
            
            # 4. ç»Ÿè®¡æ‘˜è¦
            process_summary = self._generate_process_summary(etf_codes, etf_data, filter_results, final_results)
            
            return {
                "å¤æƒç±»å‹": fuquan_type,
                "å¤„ç†æ—¶é—´": datetime.now().isoformat(),
                "å¤„ç†æ‘˜è¦": process_summary,
                "ç­›é€‰ç»“æœ": filter_results,
                "æœ€ç»ˆç»“æœ": final_results,
                "é€šè¿‡ETF": final_results["é€šè¿‡ETFåˆ—è¡¨"]
            }
    
    def _run_filter_chain(self, etf_data: Dict[str, pd.DataFrame]) -> Dict[str, Dict[str, FilterResult]]:
        """
        è¿è¡Œç­›é€‰å™¨é“¾
        
        Args:
            etf_data: ETFæ•°æ®å­—å…¸
        
        Returns:
            å„ç­›é€‰å™¨çš„ç»“æœ
        """
        filter_results = {}
        
        for filter_name, filter_obj in self.filters.items():
            self.logger.info(f"ğŸ” æ‰§è¡Œç­›é€‰å™¨: {filter_name}")
            try:
                results = filter_obj.filter_multiple_etfs(etf_data)
                filter_results[filter_name] = results
                
                # è®°å½•ç­›é€‰å™¨ç»Ÿè®¡
                stats = filter_obj.get_summary_stats(results)
                self.logger.log_stats(f"{filter_name}ç»Ÿè®¡", stats)
                
            except Exception as e:
                self.logger.error(f"âŒ ç­›é€‰å™¨ {filter_name} æ‰§è¡Œå¤±è´¥: {e}")
                filter_results[filter_name] = {}
        
        return filter_results
    
    def _generate_final_results(self, filter_results: Dict[str, Dict[str, FilterResult]]) -> Dict[str, Any]:
        """
        ç”Ÿæˆæœ€ç»ˆç­›é€‰ç»“æœ
        
        Args:
            filter_results: å„ç­›é€‰å™¨çš„ç»“æœ
        
        Returns:
            æœ€ç»ˆç»“æœå­—å…¸
        """
        if not filter_results:
            return {"é€šè¿‡ETFåˆ—è¡¨": [], "ç»¼åˆè¯„åˆ†": {}}
        
        # è·å–æ‰€æœ‰ETFä»£ç 
        all_etf_codes = set()
        for results in filter_results.values():
            all_etf_codes.update(results.keys())
        
        # è®¡ç®—ç»¼åˆè¯„åˆ†å’Œé€šè¿‡æƒ…å†µ
        comprehensive_scores = {}
        pass_statistics = {}
        
        for etf_code in all_etf_codes:
            etf_scores = {}
            etf_passed = {}
            
            for filter_name, results in filter_results.items():
                if etf_code in results:
                    result = results[etf_code]
                    etf_scores[filter_name] = result.score
                    etf_passed[filter_name] = result.passed
                else:
                    etf_scores[filter_name] = 0.0
                    etf_passed[filter_name] = False
            
            # è®¡ç®—åŠ æƒç»¼åˆå¾—åˆ†
            weighted_score = self._calculate_weighted_score(etf_scores)
            passed_filter_count = sum(etf_passed.values())
            
            comprehensive_scores[etf_code] = {
                "ç»¼åˆå¾—åˆ†": weighted_score,
                "å„ç­›é€‰å™¨å¾—åˆ†": etf_scores,
                "é€šè¿‡ç­›é€‰å™¨æ•°": passed_filter_count,
                "æ€»ç­›é€‰å™¨æ•°": len(self.filters),
                "é€šè¿‡ç‡": passed_filter_count / len(self.filters) * 100,
                "å„ç­›é€‰å™¨é€šè¿‡æƒ…å†µ": etf_passed
            }
            
            pass_statistics[etf_code] = passed_filter_count
        
        # ç¡®å®šæœ€ç»ˆé€šè¿‡çš„ETFï¼ˆéœ€è¦é€šè¿‡æ‰€æœ‰ç­›é€‰å™¨ï¼‰
        passed_etf_list = [
            etf_code for etf_code, count in pass_statistics.items() 
            if count == len(self.filters)
        ]
        
        # æŒ‰ç»¼åˆå¾—åˆ†æ’åº
        passed_etf_list.sort(key=lambda x: comprehensive_scores[x]["ç»¼åˆå¾—åˆ†"], reverse=True)
        
        return {
            "é€šè¿‡ETFåˆ—è¡¨": passed_etf_list,
            "å€™é€‰ETFåˆ—è¡¨": self._get_candidate_etfs(pass_statistics),
            "ç»¼åˆè¯„åˆ†": comprehensive_scores,
            "ç­›é€‰ç»Ÿè®¡": {
                "å®Œå…¨é€šè¿‡": len(passed_etf_list),
                "éƒ¨åˆ†é€šè¿‡": len([k for k, v in pass_statistics.items() if 0 < v < len(self.filters)]),
                "å®Œå…¨æœªé€šè¿‡": len([k for k, v in pass_statistics.items() if v == 0]),
                "æ€»ETFæ•°": len(all_etf_codes)
            }
        }
    
    def _calculate_weighted_score(self, scores: Dict[str, float]) -> float:
        """
        è®¡ç®—åŠ æƒç»¼åˆå¾—åˆ†
        
        Args:
            scores: å„ç­›é€‰å™¨å¾—åˆ†
        
        Returns:
            åŠ æƒç»¼åˆå¾—åˆ†
        """
        # ä»é…ç½®æ–‡ä»¶è¯»å–æƒé‡è®¾ç½®
        weights = self.config.get_filter_weights()
        
        weighted_score = 0.0
        total_weight = 0.0
        
        for filter_name, score in scores.items():
            weight = weights.get(filter_name, 0.33)  # é»˜è®¤æƒé‡
            weighted_score += score * weight
            total_weight += weight
        
        return weighted_score / total_weight if total_weight > 0 else 0.0
    
    def _get_candidate_etfs(self, pass_statistics: Dict[str, int]) -> List[str]:
        """
        è·å–å€™é€‰ETFåˆ—è¡¨ï¼ˆé€šè¿‡1ä¸ªç­›é€‰å™¨ä½†ä¸æ˜¯å…¨éƒ¨é€šè¿‡ï¼‰
        
        Args:
            pass_statistics: ETFé€šè¿‡ç­›é€‰å™¨æ•°é‡ç»Ÿè®¡
        
        Returns:
            å€™é€‰ETFåˆ—è¡¨
        """
        candidate_etfs = [
            etf_code for etf_code, count in pass_statistics.items()
            if count >= 1 and count < len(self.filters)
        ]
        
        return sorted(candidate_etfs)
    
    def _generate_process_summary(self, all_etf_codes: List[str], 
                                etf_data: Dict[str, pd.DataFrame],
                                filter_results: Dict[str, Dict[str, FilterResult]],
                                final_results: Dict[str, Any]) -> Dict[str, Any]:
        """
        ç”Ÿæˆå¤„ç†æ‘˜è¦
        
        Args:
            all_etf_codes: æ‰€æœ‰ETFä»£ç 
            etf_data: åŠ è½½çš„ETFæ•°æ®
            filter_results: ç­›é€‰ç»“æœ
            final_results: æœ€ç»ˆç»“æœ
        
        Returns:
            å¤„ç†æ‘˜è¦
        """
        return {
            "æ•°æ®åŠ è½½": {
                "å‘ç°ETFæ€»æ•°": len(all_etf_codes),
                "æˆåŠŸåŠ è½½æ•°": len(etf_data),
                "åŠ è½½æˆåŠŸç‡": len(etf_data) / len(all_etf_codes) * 100 if all_etf_codes else 0
            },
            "ç­›é€‰å™¨æ‰§è¡Œ": {
                "ç­›é€‰å™¨æ€»æ•°": len(self.filters),
                "æ‰§è¡ŒæˆåŠŸæ•°": len(filter_results),
                "ç­›é€‰å™¨åˆ—è¡¨": list(self.filters.keys())
            },
            "ç­›é€‰ç»“æœ": final_results["ç­›é€‰ç»Ÿè®¡"],
            "æ•°æ®è´¨é‡": {
                "æ•°æ®å®Œæ•´æ€§": "è‰¯å¥½" if len(etf_data) / len(all_etf_codes) > 0.9 else "ä¸€èˆ¬",
                "æ•°æ®æ—¶æ•ˆæ€§": "å½“æ—¥" if datetime.now().hour < 16 else "æœ€æ–°"
            }
        }
    
    def get_filter_descriptions(self) -> Dict[str, Any]:
        """è·å–æ‰€æœ‰ç­›é€‰å™¨çš„è¯´æ˜"""
        descriptions = {}
        for name, filter_obj in self.filters.items():
            if hasattr(filter_obj, 'get_filter_description'):
                descriptions[name] = filter_obj.get_filter_description()
        return descriptions
    
    def process_specific_etfs(self, etf_codes: List[str], 
                            fuquan_type: str = "0_ETFæ—¥K(å‰å¤æƒ)",
                            days_back: int = None, fast_mode: bool = False,
                            max_workers: int = None) -> Dict[str, Any]:
        """
        å¤„ç†æŒ‡å®šçš„ETFåˆ—è¡¨
        
        Args:
            etf_codes: æŒ‡å®šçš„ETFä»£ç åˆ—è¡¨
            fuquan_type: å¤æƒç±»å‹
            days_back: åŠ è½½æœ€è¿‘Nå¤©çš„æ•°æ®
            fast_mode: å¯ç”¨å¿«é€Ÿæ¨¡å¼ï¼ˆå¹¶è¡ŒåŠ è½½ï¼‰
            max_workers: æœ€å¤§å¹¶è¡Œå·¥ä½œæ•°
        
        Returns:
            å¤„ç†ç»“æœ
        """
        self.logger.info(f"ğŸ¯ å¼€å§‹å¤„ç†æŒ‡å®šçš„ {len(etf_codes)} ä¸ªETF")
        
        # æ ¹æ®å¿«é€Ÿæ¨¡å¼é€‰æ‹©åŠ è½½æ–¹å¼
        if fast_mode:
            etf_data = self.data_loader.load_multiple_etfs(
                etf_codes, fuquan_type, days_back, max_workers=max_workers
            )
        else:
            etf_data = self.data_loader.load_multiple_etfs(
                etf_codes, fuquan_type, days_back, max_workers=1
            )
        
        if not etf_data:
            return {"error": "æŒ‡å®šETFæ•°æ®åŠ è½½å¤±è´¥"}
        
        # æ‰§è¡Œç­›é€‰
        filter_results = self._run_filter_chain(etf_data)
        final_results = self._generate_final_results(filter_results)
        process_summary = self._generate_process_summary(etf_codes, etf_data, filter_results, final_results)
        
        return {
            "å¤æƒç±»å‹": fuquan_type,
            "å¤„ç†æ—¶é—´": datetime.now().isoformat(),
            "å¤„ç†æ‘˜è¦": process_summary,
            "ç­›é€‰ç»“æœ": filter_results,
            "æœ€ç»ˆç»“æœ": final_results,
            "é€šè¿‡ETF": final_results["é€šè¿‡ETFåˆ—è¡¨"]
        }
    
    def process_loaded_etfs(self, etf_data: Dict[str, pd.DataFrame], 
                           fuquan_type: str = "0_ETFæ—¥K(å‰å¤æƒ)") -> Dict[str, Any]:
        """
        å¤„ç†å·²åŠ è½½çš„ETFæ•°æ®ï¼ˆä¼˜åŒ–ç‰ˆï¼Œé¿å…é‡å¤åŠ è½½ï¼‰
        
        Args:
            etf_data: å·²åŠ è½½çš„ETFæ•°æ®å­—å…¸
            fuquan_type: å¤æƒç±»å‹ï¼ˆä»…ç”¨äºç»“æœè®°å½•ï¼‰
        
        Returns:
            å®Œæ•´çš„å¤„ç†ç»“æœ
        """
        with ProcessTimer("ETFåˆç­›å¤„ç†", self.logger):
            if not etf_data:
                self.logger.error(f"âŒ ä¼ å…¥çš„ETFæ•°æ®ä¸ºç©º")
                return {"error": "ETFæ•°æ®ä¸ºç©º"}
            
            self.logger.info(f"ğŸ“Š å¼€å§‹å¤„ç†å·²åŠ è½½çš„ {len(etf_data)} ä¸ªETFæ•°æ®...")
            
            # 1. æ‰§è¡Œç­›é€‰
            filter_results = self._run_filter_chain(etf_data)
            
            # 2. ç”Ÿæˆæœ€ç»ˆç»“æœ
            final_results = self._generate_final_results(filter_results)
            
            # 3. ç»Ÿè®¡æ‘˜è¦
            all_etf_codes = list(etf_data.keys())
            process_summary = self._generate_process_summary(all_etf_codes, etf_data, filter_results, final_results)
            
            return {
                "å¤æƒç±»å‹": fuquan_type,
                "å¤„ç†æ—¶é—´": datetime.now().isoformat(),
                "å¤„ç†æ‘˜è¦": process_summary,
                "ç­›é€‰ç»“æœ": filter_results,
                "æœ€ç»ˆç»“æœ": final_results,
                "é€šè¿‡ETF": final_results["é€šè¿‡ETFåˆ—è¡¨"]
            } 