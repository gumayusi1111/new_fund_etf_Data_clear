#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ETFæ•°æ®åŠ è½½å™¨
è´Ÿè´£ä»æ—¥æ›´æ•°æ®ä¸­åªè¯»åŠ è½½ETFæ•°æ®ï¼Œä¸¥æ ¼ä¸ä¿®æ”¹æºæ•°æ®
"""

import pandas as pd
from pathlib import Path
from typing import Dict, List, Optional, Tuple
import os
from datetime import datetime, timedelta
from concurrent.futures import ThreadPoolExecutor, as_completed
import multiprocessing as mp

from .utils.config import get_config
from .utils.logger import get_logger


class ETFDataLoader:
    """
    ETFæ•°æ®åŠ è½½å™¨
    ä¸¥æ ¼éµå¾ªåªè¯»åŸåˆ™ï¼Œä¸ä¿®æ”¹æ—¥æ›´æ•°æ®
    """
    
    def __init__(self):
        self.config = get_config()
        self.logger = get_logger()
        self.daily_source = self.config.get_daily_data_source()
        
        # éªŒè¯æ•°æ®æº
        if not self.daily_source.exists():
            raise FileNotFoundError(f"æ—¥æ›´æ•°æ®æºä¸å­˜åœ¨: {self.daily_source}")
    
    def get_available_etf_codes(self, fuquan_type: str = "0_ETFæ—¥K(å‰å¤æƒ)") -> List[str]:
        """
        è·å–å¯ç”¨çš„ETFä»£ç åˆ—è¡¨
        
        Args:
            fuquan_type: å¤æƒç±»å‹ç›®å½•å
        
        Returns:
            ETFä»£ç åˆ—è¡¨
        """
        try:
            fuquan_dir = self.daily_source / fuquan_type
            if not fuquan_dir.exists():
                self.logger.warning(f"å¤æƒç›®å½•ä¸å­˜åœ¨: {fuquan_dir}")
                return []
            
            # è·å–æ‰€æœ‰CSVæ–‡ä»¶
            csv_files = list(fuquan_dir.glob("*.csv"))
            
            # æå–ETFä»£ç ï¼ˆæ–‡ä»¶åå»æ‰.csvåç¼€ï¼‰
            etf_codes = []
            for csv_file in csv_files:
                code = csv_file.stem  # æ–‡ä»¶åä¸å«æ‰©å±•å
                if self._is_valid_etf_code(code):
                    etf_codes.append(code)
            
            etf_codes.sort()
            self.logger.info(f"ğŸ“Š ä» {fuquan_type} å‘ç° {len(etf_codes)} ä¸ªETF")
            return etf_codes
            
        except Exception as e:
            self.logger.error(f"è·å–ETFä»£ç å¤±è´¥: {e}")
            return []
    
    def _is_valid_etf_code(self, code: str) -> bool:
        """
        éªŒè¯ETFä»£ç æœ‰æ•ˆæ€§
        
        Args:
            code: ETFä»£ç ï¼ˆå¯èƒ½åŒ…å«.SZæˆ–.SHåç¼€ï¼‰
        
        Returns:
            æ˜¯å¦æœ‰æ•ˆ
        """
        # ç§»é™¤å¯èƒ½çš„äº¤æ˜“æ‰€åç¼€
        clean_code = code
        if '.' in code:
            clean_code = code.split('.')[0]
        
        # åŸºæœ¬æ ¼å¼æ£€æŸ¥ï¼ˆ6ä½æ•°å­—ï¼‰
        if not clean_code.isdigit() or len(clean_code) != 6:
            return False
        
        # ETFä»£ç é€šå¸¸ä»¥1ã€5å¼€å¤´
        if not clean_code.startswith(('1', '5')):
            return False
            
        return True
    
    def load_etf_data(self, etf_code: str, fuquan_type: str, 
                     days_back: int = None) -> Optional[pd.DataFrame]:
        """
        åŠ è½½å•ä¸ªETFçš„æ•°æ®
        
        Args:
            etf_code: ETFä»£ç 
            fuquan_type: å¤æƒç±»å‹
            days_back: åŠ è½½æœ€è¿‘Nå¤©çš„æ•°æ®ï¼ŒNoneè¡¨ç¤ºåŠ è½½å…¨éƒ¨
        
        Returns:
            ETFæ•°æ®DataFrameï¼Œå¤±è´¥è¿”å›None
        """
        try:
            fuquan_dir = self.daily_source / fuquan_type
            csv_file = fuquan_dir / f"{etf_code}.csv"
            
            if not csv_file.exists():
                self.logger.warning(f"ETFæ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {csv_file}")
                return None
            
            # åªè¯»æ–¹å¼åŠ è½½æ•°æ®
            df = pd.read_csv(csv_file, encoding='utf-8')
            
            # éªŒè¯æ•°æ®æ ¼å¼
            if not self._validate_dataframe(df):
                self.logger.warning(f"ETFæ•°æ®æ ¼å¼æ— æ•ˆ: {etf_code}")
                return None
            
            # æ•°æ®é¢„å¤„ç†
            df = self._preprocess_dataframe(df)
            
            # æŒ‰æ—¥æœŸé™åˆ¶æ•°æ®
            if days_back is not None:
                df = self._limit_recent_days(df, days_back)
            
            self.logger.debug(f"âœ… åŠ è½½ETFæ•°æ®: {etf_code}, å…± {len(df)} è¡Œ")
            return df
            
        except Exception as e:
            self.logger.error(f"åŠ è½½ETFæ•°æ®å¤±è´¥ {etf_code}: {e}")
            return None
    
    def _validate_dataframe(self, df: pd.DataFrame) -> bool:
        """
        éªŒè¯DataFrameæ ¼å¼
        
        Args:
            df: æ•°æ®DataFrame
        
        Returns:
            æ˜¯å¦æœ‰æ•ˆ
        """
        # æœŸæœ›çš„11ä¸ªå­—æ®µ
        expected_columns = [
            'ä»£ç ', 'æ—¥æœŸ', 'å¼€ç›˜ä»·', 'æœ€é«˜ä»·', 'æœ€ä½ä»·', 'æ”¶ç›˜ä»·',
            'ä¸Šæ—¥æ”¶ç›˜', 'æ¶¨è·Œ', 'æ¶¨å¹…%', 'æˆäº¤é‡(æ‰‹æ•°)', 'æˆäº¤é¢(åƒå…ƒ)'
        ]
        
        # æ£€æŸ¥å¿…è¦å­—æ®µ
        missing_columns = [col for col in expected_columns if col not in df.columns]
        if missing_columns:
            self.logger.warning(f"ç¼ºå°‘å¿…è¦å­—æ®µ: {missing_columns}")
            return False
        
        # æ£€æŸ¥æ•°æ®éç©º
        if df.empty:
            self.logger.warning("æ•°æ®ä¸ºç©º")
            return False
        
        return True
    
    def _preprocess_dataframe(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        é¢„å¤„ç†DataFrameï¼ˆä¸ä¿®æ”¹åŸå§‹æ•°æ®ï¼‰
        
        Args:
            df: åŸå§‹æ•°æ®
        
        Returns:
            å¤„ç†åçš„æ•°æ®å‰¯æœ¬
        """
        # åˆ›å»ºå‰¯æœ¬é¿å…ä¿®æ”¹åŸå§‹æ•°æ®
        df_processed = df.copy()
        
        # æ—¥æœŸå¤„ç†
        if 'æ—¥æœŸ' in df_processed.columns:
            df_processed['æ—¥æœŸ'] = pd.to_datetime(df_processed['æ—¥æœŸ'], errors='coerce')
            # æŒ‰æ—¥æœŸæ’åº
            df_processed = df_processed.sort_values('æ—¥æœŸ').reset_index(drop=True)
        
        # æ•°å€¼ç±»å‹è½¬æ¢
        numeric_columns = [
            'å¼€ç›˜ä»·', 'æœ€é«˜ä»·', 'æœ€ä½ä»·', 'æ”¶ç›˜ä»·', 'ä¸Šæ—¥æ”¶ç›˜', 'æ¶¨è·Œ', 
            'æ¶¨å¹…%', 'æˆäº¤é‡(æ‰‹æ•°)', 'æˆäº¤é¢(åƒå…ƒ)'
        ]
        
        for col in numeric_columns:
            if col in df_processed.columns:
                df_processed[col] = pd.to_numeric(df_processed[col], errors='coerce')
        
        # åˆ é™¤æ— æ•ˆè¡Œ
        df_processed = df_processed.dropna(subset=['æ—¥æœŸ', 'æ”¶ç›˜ä»·'])
        
        return df_processed
    
    def _limit_recent_days(self, df: pd.DataFrame, days_back: int) -> pd.DataFrame:
        """
        é™åˆ¶ä¸ºæœ€è¿‘Nå¤©çš„æ•°æ®
        
        Args:
            df: æ•°æ®DataFrame
            days_back: å¤©æ•°
        
        Returns:
            é™åˆ¶åçš„æ•°æ®
        """
        if df.empty or 'æ—¥æœŸ' not in df.columns:
            return df
        
        # è·å–æœ€æ–°æ—¥æœŸ
        latest_date = df['æ—¥æœŸ'].max()
        start_date = latest_date - timedelta(days=days_back)
        
        # è¿‡æ»¤æ•°æ®
        recent_df = df[df['æ—¥æœŸ'] >= start_date].copy()
        
        return recent_df
    
    def load_multiple_etfs(self, etf_codes: List[str], fuquan_type: str,
                          days_back: int = None, max_workers: int = None) -> Dict[str, pd.DataFrame]:
        """
        æ‰¹é‡åŠ è½½å¤šä¸ªETFçš„æ•°æ®ï¼ˆå¹¶è¡Œä¼˜åŒ–ç‰ˆï¼‰
        
        Args:
            etf_codes: ETFä»£ç åˆ—è¡¨
            fuquan_type: å¤æƒç±»å‹
            days_back: åŠ è½½æœ€è¿‘Nå¤©çš„æ•°æ®
            max_workers: æœ€å¤§å¹¶è¡Œå·¥ä½œæ•°ï¼ŒNoneè¡¨ç¤ºè‡ªåŠ¨è®¾ç½®
        
        Returns:
            ETFä»£ç åˆ°DataFrameçš„å­—å…¸
        """
        if not etf_codes:
            return {}
        
        # è‡ªåŠ¨è®¾ç½®å¹¶è¡Œæ•°
        if max_workers is None:
            max_workers = min(32, (os.cpu_count() or 1) * 4)  # é™åˆ¶æœ€å¤§32ä¸ªçº¿ç¨‹
        
        etf_data = {}
        
        # ä½¿ç”¨ThreadPoolExecutorå¹¶è¡ŒåŠ è½½
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_code = {
                executor.submit(self.load_etf_data, etf_code, fuquan_type, days_back): etf_code
                for etf_code in etf_codes
            }
            
            # æ”¶é›†ç»“æœ
            for future in as_completed(future_to_code):
                etf_code = future_to_code[future]
                try:
                    df = future.result()
                    if df is not None and not df.empty:
                        etf_data[etf_code] = df
                except Exception as e:
                    self.logger.error(f"å¹¶è¡ŒåŠ è½½ETFæ•°æ®å¤±è´¥ {etf_code}: {e}")
        
        self.logger.info(f"ğŸ“Š æˆåŠŸåŠ è½½ {len(etf_data)}/{len(etf_codes)} ä¸ªETFæ•°æ®")
        return etf_data
    
    def load_multiple_etfs_batch(self, etf_codes: List[str], fuquan_type: str,
                                days_back: int = None, batch_size: int = 100) -> Dict[str, pd.DataFrame]:
        """
        æ‰¹é‡åŠ è½½å¤šä¸ªETFçš„æ•°æ®ï¼ˆåˆ†æ‰¹å¤„ç†ç‰ˆï¼‰
        
        Args:
            etf_codes: ETFä»£ç åˆ—è¡¨
            fuquan_type: å¤æƒç±»å‹
            days_back: åŠ è½½æœ€è¿‘Nå¤©çš„æ•°æ®
            batch_size: æ‰¹å¤„ç†å¤§å°
        
        Returns:
            ETFä»£ç åˆ°DataFrameçš„å­—å…¸
        """
        if not etf_codes:
            return {}
        
        etf_data = {}
        total_codes = len(etf_codes)
        
        # åˆ†æ‰¹å¤„ç†
        for i in range(0, total_codes, batch_size):
            batch_codes = etf_codes[i:i + batch_size]
            batch_data = self.load_multiple_etfs(batch_codes, fuquan_type, days_back)
            etf_data.update(batch_data)
            
            self.logger.info(f"ğŸ“Š æ‰¹å¤„ç†è¿›åº¦: {min(i + batch_size, total_codes)}/{total_codes}")
        
        return etf_data
    
    def get_data_summary(self, fuquan_type: str = None) -> Dict[str, any]:
        """
        è·å–æ•°æ®æºæ‘˜è¦ä¿¡æ¯
        
        Args:
            fuquan_type: å¤æƒç±»å‹ï¼ŒNoneè¡¨ç¤ºæ‰€æœ‰ç±»å‹
        
        Returns:
            æ‘˜è¦ä¿¡æ¯å­—å…¸
        """
        summary = {
            "æ•°æ®æºè·¯å¾„": str(self.daily_source),
            "å¤æƒç±»å‹ç»Ÿè®¡": {}
        }
        
        fuquan_type_list = [fuquan_type] if fuquan_type else self.config.get_fuquan_types()
        
        for fuquan in fuquan_type_list:
            fuquan_dir = self.daily_source / fuquan
            if fuquan_dir.exists():
                csv_files = list(fuquan_dir.glob("*.csv"))
                etf_count = len([f for f in csv_files if self._is_valid_etf_code(f.stem)])
                
                summary["å¤æƒç±»å‹ç»Ÿè®¡"][fuquan] = {
                    "ETFæ•°é‡": etf_count,
                    "ç›®å½•å­˜åœ¨": True
                }
            else:
                summary["å¤æƒç±»å‹ç»Ÿè®¡"][fuquan] = {
                    "ETFæ•°é‡": 0,
                    "ç›®å½•å­˜åœ¨": False
                }
        
        return summary
    
    def validate_data_source(self) -> bool:
        """
        éªŒè¯æ•°æ®æºå®Œæ•´æ€§
        
        Returns:
            æ•°æ®æºæ˜¯å¦æœ‰æ•ˆ
        """
        try:
            summary = self.get_data_summary()
            
            self.logger.info("ğŸ” æ•°æ®æºéªŒè¯ç»“æœ:")
            self.logger.info(f"  æ•°æ®æºè·¯å¾„: {summary['æ•°æ®æºè·¯å¾„']}")
            
            total_etfs = 0
            for fuquan_type, stats in summary["å¤æƒç±»å‹ç»Ÿè®¡"].items():
                etf_count = stats["ETFæ•°é‡"]
                exists = stats["ç›®å½•å­˜åœ¨"]
                status = "âœ…" if exists and etf_count > 0 else "âŒ"
                self.logger.info(f"  {status} {fuquan_type}: {etf_count} ä¸ªETF")
                
                if exists and etf_count > 0:
                    total_etfs = max(total_etfs, etf_count)
            
            if total_etfs == 0:
                self.logger.error("âŒ æœªå‘ç°ä»»ä½•æœ‰æ•ˆçš„ETFæ•°æ®")
                return False
            
            self.logger.info(f"âœ… æ•°æ®æºéªŒè¯é€šè¿‡ï¼Œå‘ç° {total_etfs} ä¸ªETF")
            return True
            
        except Exception as e:
            self.logger.error(f"æ•°æ®æºéªŒè¯å¤±è´¥: {e}")
            return False 